---
title: "<think>...</think> QwQ-Max-Preview"
date: 2025-02-25T02:00:04+08:00
weight: 1
# aliases: ["/first"]
# tags: ["Research"]
# draft: true
# comments: false
# description: "Desc Text."
# disable_share: false
# hide_meta: false
# hide_summary: false # to hide summary in list
# hide_footer: false
math: true
# search_hidden: false # to hide from search page
show_reading_time: true
show_bread_crumbs: true
show_post_nav_links: false # the prev/next after the content
show_code_copy_buttons: true
show_word_count: true
# use_hugo_toc: true
# show_toc: true
# toc_open: true # default expand all
# cover:
#     image: "path"
#     # can also paste direct link from external site
#     # ex. https://i.ibb.co/K0HVPBd/paper-mod-profilemode.png
#     alt: "<alt text>"
#     caption: "<text>"
#     relative: true # To use relative path for cover image, used in hugo Page-bundles
#     responsive_images: true
#     hidden: false
# header:
#   background: "" # background css value
#   background_image: ""
#   gradient: false
#   blur: false
---


{{< figure src="https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/qwq-banner-zh.jpg" width="100%">}}


{{< button href="https://chat.qwen.ai" label="QWEN CHAT" external=true >}}
{{< button href="https://discord.gg/yPEP2vHTu4" label="DISCORD" external=true >}}


这篇博客出自 QwQ-Max-Preview 之手。希望各位看官喜欢！

## 介绍

> <span style="font-size: smaller; color: blue;">\<think\></span><br>
<i style="font-size: smaller; color: grey;">
好的，用户希望我为他们的博客创建一个标题和介绍，宣布 QwQ-Max-Preview 的发布。让我先整理一下他们提到的关键点。
首先，该模型属于通义千问系列，基于 Qwen2.5-Max 构建。这是一个预览版本，因此他们可能希望强调这是正式发布前的抢先体验。主要优势包括深度推理、数学、编程、通用领域以及与 Agent 相关的任务。他们还提到了未来的更新计划，并将开源代码，采用 Apache 2.0 许可证。
<br><br>
对于标题，我需要让它吸引人并包含模型名称。也许可以这样写：“隆重推出 QwQ-Max-Preview ：深度推理与多领域精通的全新飞跃”。这突出了预览状态和关键功能。
<br><br>
介绍部分应简要总结公告内容。以对发布的兴奋之情开头，提到它基于 Qwen2.5-Max ，强调其在推理、数学、编程和 Agent 任务方面的强大能力。同时指出这是一个预览版本，未来会有更新，并最终开源。保持简洁，不展开解释，按照用户要求避免使用 Markdown，段落也要简短。最后检查是否涵盖了所有要点：模型名称、基于 Qwen2.5、预览状态、推理/数学/编程/Agent 任务的优势、未来更新、以及 Apache 2.0 开源许可。是的，这些都包括了。好了，现在开始整合内容。
</i>
<br>
<span style="font-size: smaller; color: blue;">\</think\></span>

我们很高兴向大家介绍 QwQ-Max-Preview，这是 Qwen 系列的最新成果。这一版本基于 Qwen2.5-Max 构建，在数学、编程以及通用任务中展现了更强的能力，同时在与 Agent 相关的工作流中也有不错的表现。作为即将发布的 QwQ-Max 的预览版，这个版本还在持续优化中。我们计划在不久的将来以 Apache 2.0 许可协议开源发布 QwQ-Max 以及 Qwen2.5-Max。我们期待与大家一起探索智能推理的更多可能性！
<br><br>



## 示例

{{< fullwidth class="example-container" >}}
{{< example data="cases/coder.json" hide=false next=true >}}
{{< example data="cases/game.json" hide=true next=true >}}
{{< example data="cases/game2.json" hide=true next=true >}}
{{< example data="cases/agent.json" hide=true next=true >}}
{{< example data="cases/agent_zh.json" hide=true next=true >}}
{{< example data="cases/math.json" hide=true next=true >}}
{{< example data="cases/creative_writing.json" hide=true next=true >}}
{{< example data="cases/search.json" hide=true next=true >}}
{{< /fullwidth >}}




## 接下来的工作
> <span style="font-size: smaller; color: blue;">\<think\></span><br>
<i style="font-size: smaller; color: grey;">
好的，用户希望我为他们的博客文章写一个未来工作部分。他们提到，除了开源 QwQ-Max 之外，还计划发布一款 APP，并开源一些较小的推理模型，比如 QwQ-32B，供开发者本地使用。
<br><br>
首先，我需要清晰地组织这一部分内容。标题应该反映未来的计划。或许可以取名为“展望未来：扩展可访问性与创新”。这听起来很有前瞻性。
<br><br>
接下来，引言部分应简要概述即将发布的项目。提到 QwQ-Max 将在 Apache 2.0 协议下开源，APP 将提供更广泛的访问途径，以及像 QwQ-32B 这样的小型模型。强调这些模型可以本地运行，这对关注隐私或资源限制的开发者来说非常重要。
<br><br>
然后，分几个小节来展开内容。首先是 APP 的发布。需要解释它的功能：友好的用户界面、实时推理、协作工具等。强调它对非技术用户的易用性以及与现有工作流程的集成。
<br><br>
第二部分是开源小型模型。以 QwQ-32B 为例进行说明。解释其优势：低延迟、隐私保护、可定制化。目标受众包括开发者、研究人员和爱好者。
<br><br>
第三部分是社区驱动的创新。鼓励合作、贡献和反馈。提到正在构建一个人工智能应用的生态系统。
<br><br>
最后，用一段总结性文字将所有内容串联起来。重申对开源的承诺，以及赋能社区的决心。邀请读者加入这段旅程。
<br><br>
检查是否涵盖了所有要点：APP、小型模型、开源、Apache 许可、本地使用、不同受众。避免过多技术术语，但保持专业性。确保行文流畅，每个部分过渡自然。同时，确保语气与最初公告中的兴奋感一致。不使用 Markdown 格式，仅用纯文本并设置清晰的标题。好了，这样应该能满足用户的需求。
</i>
<br>
<span style="font-size: smaller; color: blue;">\</think\></span>

随后我们准备正式开源 QwQ-Max，并以 Apache 2.0 许可证发布，我们的愿景不仅仅限于分享前沿研究，还将致力于普及先进推理能力的访问权限，并推动跨领域应用的创新。以下是接下来的计划：

1. **APP 发布**
为了让强大的人工智能技术走进普通用户的生活，我们即将推出 Qwen Chat APP。这款应用将让用户以最简单的方式与 AI 模型互动，无论是解决问题、生成代码还是进行逻辑推理，都能轻松搞定——无需任何技术背景。Qwen Chat 专注于实时响应体验，并与主流生产力工具无缝衔接，让全球用户随时随地享受先进人工智能带来的便利。

2. **开源更小的推理模型**
为了满足市场对高效、低资源消耗解决方案的需求，我们将推出更小巧的 QwQ 系列模型，例如 QwQ-32B。这些模型在大幅降低计算需求的同时，依然保持出色的推理能力，非常适合需要隐私保护或低延迟的应用场景。开发者可以轻松将其部署到本地设备中，打造高度定制化的 AI 解决方案。

3. **社区驱动的创新**
通过开源 Qwen2.5-Max、QwQ-Max 及其轻量级变体，我们希望能够激发开发者、研究人员和爱好者的创造力。我们诚邀全球社区对这些模型进行实验、优化和扩展，探索从教育工具到智能代理等多样化应用场景。我们的愿景是构建一个开放的生态系统，在这里，创新通过知识共享和协作解决问题的方式不断涌现，共同推动人工智能技术的发展。

以上计划旨在为不同层次的用户提供支持，重新定义人工智能的边界。我们正在携手打造一个未来，让智能不仅强大，而且触手可及，真正服务于每一个人。
