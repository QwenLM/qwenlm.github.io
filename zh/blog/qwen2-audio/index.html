<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen2-Audio：开启语音对话！ | Qwen</title><meta name=keywords content><meta name=description content="DEMO PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD
在一个通用的AI系统中，核心模型应该能够理解不同模态的信息。当前的大语言模型现在已经能够理解语言并进行推理，并且已经扩展到了更多的模态，包括视觉和音频。此前我们陆续发布了多个 Qwen 语言模型系列以及 Qwen-VL 和 Qwen-Audio 等多模态模型。今天，我们正式发布 Qwen2-Audio。这是 Qwen-Audio 的下一代版本，它能够接受音频和文本输入，并生成文本输出。Qwen2-Audio 具有以下特点：
语音聊天：用户可以使用语音向音频语言模型发出指令，无需通过自动语音识别（ASR）模块。
音频分析：该模型能够根据文本指令分析音频信息，包括语音、声音、音乐等。
多语言支持：该模型支持超过8种语言和方言，例如中文、英语、粤语、法语、意大利语、西班牙语、德语和日语。
我们在 Hugging Face 和 ModelScope 上开源了 Qwen2-Audio-7B 以及 Qwen2-Audio-7B-Instruct，并且我们搭建了一个 demo 供用户互动。下面是一些具体例子：
语音交互 语音交互：基础交互NextUserYour browser does not support the audio element. Qwen2-Audio这种情况可能会让人感到沮丧和困惑，但是你需要记住的是，你不能强迫任何人去喜欢你。如果你真的喜欢这个女孩，那么最好的办法就是尊重她的感受，不去打扰她，同时也要保持自己的尊严。 以下是一些建议： &nbsp 1. 尊重她的决定：如果她明确表示不喜欢你，那么你应该尊重她的决定，不要试图改变她的想法。 2. 不要过于干涉：避免过多地干涉她的生活，也不要试图通过各种方式来接近她。 3. 保持距离：尽量避免与她有太多的接触，尤其是在她不希望的情况下。 4. 寻求支持：如果你感到很难过或者困惑，可以向你的朋友或家人寻求支持和建议。 &nbsp 最重要的是，你要保持自己的尊严和自信，不要因为别人的喜好而失去自我。 Your browser does not support the audio element. UserYour browser does not support the audio element."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/qwen2-audio/><link crossorigin=anonymous href=/assets/css/stylesheet.012512d6f1d6f320d85cff7ae2b89d136cc19960a4aa00adf35aaae57e557162.css integrity="sha256-ASUS1vHW8yDYXP964ridE2zBmWCkqgCt81qq5X5VcWI=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen2-audio/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen2-audio/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen2-Audio：开启语音对话！"><meta property="og:description" content="DEMO PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD
在一个通用的AI系统中，核心模型应该能够理解不同模态的信息。当前的大语言模型现在已经能够理解语言并进行推理，并且已经扩展到了更多的模态，包括视觉和音频。此前我们陆续发布了多个 Qwen 语言模型系列以及 Qwen-VL 和 Qwen-Audio 等多模态模型。今天，我们正式发布 Qwen2-Audio。这是 Qwen-Audio 的下一代版本，它能够接受音频和文本输入，并生成文本输出。Qwen2-Audio 具有以下特点：
语音聊天：用户可以使用语音向音频语言模型发出指令，无需通过自动语音识别（ASR）模块。
音频分析：该模型能够根据文本指令分析音频信息，包括语音、声音、音乐等。
多语言支持：该模型支持超过8种语言和方言，例如中文、英语、粤语、法语、意大利语、西班牙语、德语和日语。
我们在 Hugging Face 和 ModelScope 上开源了 Qwen2-Audio-7B 以及 Qwen2-Audio-7B-Instruct，并且我们搭建了一个 demo 供用户互动。下面是一些具体例子：
语音交互 语音交互：基础交互NextUserYour browser does not support the audio element. Qwen2-Audio这种情况可能会让人感到沮丧和困惑，但是你需要记住的是，你不能强迫任何人去喜欢你。如果你真的喜欢这个女孩，那么最好的办法就是尊重她的感受，不去打扰她，同时也要保持自己的尊严。 以下是一些建议： &nbsp 1. 尊重她的决定：如果她明确表示不喜欢你，那么你应该尊重她的决定，不要试图改变她的想法。 2. 不要过于干涉：避免过多地干涉她的生活，也不要试图通过各种方式来接近她。 3. 保持距离：尽量避免与她有太多的接触，尤其是在她不希望的情况下。 4. 寻求支持：如果你感到很难过或者困惑，可以向你的朋友或家人寻求支持和建议。 &nbsp 最重要的是，你要保持自己的尊严和自信，不要因为别人的喜好而失去自我。 Your browser does not support the audio element. UserYour browser does not support the audio element."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/qwen2-audio/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-08-09T16:22:39+08:00"><meta property="article:modified_time" content="2024-08-09T16:22:39+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen2-Audio：开启语音对话！"><meta name=twitter:description content="DEMO PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD
在一个通用的AI系统中，核心模型应该能够理解不同模态的信息。当前的大语言模型现在已经能够理解语言并进行推理，并且已经扩展到了更多的模态，包括视觉和音频。此前我们陆续发布了多个 Qwen 语言模型系列以及 Qwen-VL 和 Qwen-Audio 等多模态模型。今天，我们正式发布 Qwen2-Audio。这是 Qwen-Audio 的下一代版本，它能够接受音频和文本输入，并生成文本输出。Qwen2-Audio 具有以下特点：
语音聊天：用户可以使用语音向音频语言模型发出指令，无需通过自动语音识别（ASR）模块。
音频分析：该模型能够根据文本指令分析音频信息，包括语音、声音、音乐等。
多语言支持：该模型支持超过8种语言和方言，例如中文、英语、粤语、法语、意大利语、西班牙语、德语和日语。
我们在 Hugging Face 和 ModelScope 上开源了 Qwen2-Audio-7B 以及 Qwen2-Audio-7B-Instruct，并且我们搭建了一个 demo 供用户互动。下面是一些具体例子：
语音交互 语音交互：基础交互NextUserYour browser does not support the audio element. Qwen2-Audio这种情况可能会让人感到沮丧和困惑，但是你需要记住的是，你不能强迫任何人去喜欢你。如果你真的喜欢这个女孩，那么最好的办法就是尊重她的感受，不去打扰她，同时也要保持自己的尊严。 以下是一些建议： &nbsp 1. 尊重她的决定：如果她明确表示不喜欢你，那么你应该尊重她的决定，不要试图改变她的想法。 2. 不要过于干涉：避免过多地干涉她的生活，也不要试图通过各种方式来接近她。 3. 保持距离：尽量避免与她有太多的接触，尤其是在她不希望的情况下。 4. 寻求支持：如果你感到很难过或者困惑，可以向你的朋友或家人寻求支持和建议。 &nbsp 最重要的是，你要保持自己的尊严和自信，不要因为别人的喜好而失去自我。 Your browser does not support the audio element. UserYour browser does not support the audio element."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Qwen2-Audio：开启语音对话！","item":"https://qwenlm.github.io/zh/blog/qwen2-audio/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen2-Audio：开启语音对话！","name":"Qwen2-Audio：开启语音对话！","description":"DEMO PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD\n在一个通用的AI系统中，核心模型应该能够理解不同模态的信息。当前的大语言模型现在已经能够理解语言并进行推理，并且已经扩展到了更多的模态，包括视觉和音频。此前我们陆续发布了多个 Qwen 语言模型系列以及 Qwen-VL 和 Qwen-Audio 等多模态模型。今天，我们正式发布 Qwen2-Audio。这是 Qwen-Audio 的下一代版本，它能够接受音频和文本输入，并生成文本输出。Qwen2-Audio 具有以下特点：\n语音聊天：用户可以使用语音向音频语言模型发出指令，无需通过自动语音识别（ASR）模块。\n音频分析：该模型能够根据文本指令分析音频信息，包括语音、声音、音乐等。\n多语言支持：该模型支持超过8种语言和方言，例如中文、英语、粤语、法语、意大利语、西班牙语、德语和日语。\n我们在 Hugging Face 和 ModelScope 上开源了 Qwen2-Audio-7B 以及 Qwen2-Audio-7B-Instruct，并且我们搭建了一个 demo 供用户互动。下面是一些具体例子：\n语音交互 语音交互：基础交互\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r这种情况可能会让人感到沮丧和困惑，但是你需要记住的是，你不能强迫任何人去喜欢你。如果你真的喜欢这个女孩，那么最好的办法就是尊重她的感受，不去打扰她，同时也要保持自己的尊严。 以下是一些建议： \u0026nbsp 1. 尊重她的决定：如果她明确表示不喜欢你，那么你应该尊重她的决定，不要试图改变她的想法。 2. 不要过于干涉：避免过多地干涉她的生活，也不要试图通过各种方式来接近她。 3. 保持距离：尽量避免与她有太多的接触，尤其是在她不希望的情况下。 4. 寻求支持：如果你感到很难过或者困惑，可以向你的朋友或家人寻求支持和建议。 \u0026nbsp 最重要的是，你要保持自己的尊严和自信，不要因为别人的喜好而失去自我。 Your browser does not support the audio element. User\rYour browser does not support the audio element.","keywords":[],"articleBody":"DEMO PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD\n在一个通用的AI系统中，核心模型应该能够理解不同模态的信息。当前的大语言模型现在已经能够理解语言并进行推理，并且已经扩展到了更多的模态，包括视觉和音频。此前我们陆续发布了多个 Qwen 语言模型系列以及 Qwen-VL 和 Qwen-Audio 等多模态模型。今天，我们正式发布 Qwen2-Audio。这是 Qwen-Audio 的下一代版本，它能够接受音频和文本输入，并生成文本输出。Qwen2-Audio 具有以下特点：\n语音聊天：用户可以使用语音向音频语言模型发出指令，无需通过自动语音识别（ASR）模块。\n音频分析：该模型能够根据文本指令分析音频信息，包括语音、声音、音乐等。\n多语言支持：该模型支持超过8种语言和方言，例如中文、英语、粤语、法语、意大利语、西班牙语、德语和日语。\n我们在 Hugging Face 和 ModelScope 上开源了 Qwen2-Audio-7B 以及 Qwen2-Audio-7B-Instruct，并且我们搭建了一个 demo 供用户互动。下面是一些具体例子：\n语音交互 语音交互：基础交互\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r这种情况可能会让人感到沮丧和困惑，但是你需要记住的是，你不能强迫任何人去喜欢你。如果你真的喜欢这个女孩，那么最好的办法就是尊重她的感受，不去打扰她，同时也要保持自己的尊严。 以下是一些建议： 1. 尊重她的决定：如果她明确表示不喜欢你，那么你应该尊重她的决定，不要试图改变她的想法。 2. 不要过于干涉：避免过多地干涉她的生活，也不要试图通过各种方式来接近她。 3. 保持距离：尽量避免与她有太多的接触，尤其是在她不希望的情况下。 4. 寻求支持：如果你感到很难过或者困惑，可以向你的朋友或家人寻求支持和建议。 最重要的是，你要保持自己的尊严和自信，不要因为别人的喜好而失去自我。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r很抱歉，我无法帮助你追求她。这不仅是因为我是一个人工智能助手，而且也是因为她已经明确表示不喜欢你。在这种情况下，我建议你尊重她的决定，同时也要保持自己的尊严和自信。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r当然可以！追女孩子需要付出努力和耐心，但同时也需要尊重她们的感受和意愿。以下是一些基本的建议： 1. 做一个有趣的人：尽可能多地展示出你的幽默感和创造力，让女孩子觉得和你在一起会很开心。 2. 主动出击：如果你对某个女孩子感兴趣，不妨主动和她交流，比如邀请她一起吃饭、看电影等。 3. 给予关注：多关注女孩子的生活，了解她的兴趣爱好，给她提供帮助和支持。 4. 表达情感：用适当的方式表达你的情感，让她知道你对她有着特殊的感情。 5. 尊重她的选择：如果女孩子对你没有同样的感觉，你需要尊重她的决定，不要强求。 最后，要记住，每个人都是独特的，所以你需要根据她的个性和喜好来调整你的行为和策略。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r当然啦！制造浪漫惊喜的方法有很多，以下是一些常见的建议： 1. 制作一张手写卡片：写下你的心声，告诉她你有多么爱她。 2. 准备一份特别的礼物：可以是她最喜欢的物品，也可以是你自己亲手制作的东西。 3. 安排一次特别的约会：可以选择一家浪漫的餐厅，或者去看一场电影。 4. 给她一个意想不到的惊喜：比如在她的生日那天，提前安排好一个惊喜派对。 5. 帮助她实现一个梦想：如果她有什么梦想，尽你所能去帮助她实现。 6. 在她最需要的时候陪伴她：无论是在她生病还是遇到困难的时候，都要在她身边陪伴她。 最重要的是，要用心去制造每一个浪漫惊喜，让她感受到你的爱意和关心。 Your browser does not support the audio element. 语音交互：背景音乐感知及推荐\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r在这种环境下，你可以做很多事情，比如阅读、写作、编程、学习新技能、练习乐器、看电影、玩游戏等。你也可以和朋友聊天、锻炼身体、烹饪美食、组织活动等。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r当然可以！根据你的兴趣，我推荐《哈利·波特》系列、《冰与火之歌》系列、《指环王》系列、《福尔摩斯探案集》、《傲慢与偏见》、《老人与海》、《1984》、《麦田里的守望者》等。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r当然有！我推荐《肖申克的救赎》、《星球大战：帝国反击战》、《阿甘正传》、《美丽心灵》、《饮食男女》、《盗梦空间》、《海上钢琴师》、《机器人总动员》等。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r我推荐学习钢琴，因为钢琴是一种多才多艺的乐器，能够演奏出美妙的旋律，并且有很多有趣的技巧可以探索。学习钢琴的最佳方法是每天定时练习，每次至少30分钟，同时结合听音乐、看视频、参加课程等方式来加深理解。 Your browser does not support the audio element. 语音交互：说话人信息识别及环境音感知交互\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r男性，16-25岁 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r因为这种场景让你感到放松和舒适，有助于提高睡眠质量。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r你可以尝试使用耳塞或者寻找一个相对安静的工作环境来帮助你集中注意力。 Your browser does not support the audio element. 音频分析 音频分析：说话人信息识别\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r两个人在说话。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r说话人的情绪是兴奋和满意的。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r说话人大概在41岁以上。 Your browser does not support the audio element. 音频分析：混合音频分析\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r这段音频的原始内容是:‘路过灌木丛时’ Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r有人在说话，内容是’路过灌木丛时’。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r有人在说话，内容是’路过灌木丛时’。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r男性。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r他说的是：‘When passing through the bushes.’ User\rYour browser does not support the audio element. Qwen2-Audio\rThe person says ‘毕竟是年事已高啊’ in Mandarin. User\rYour browser does not support the audio element. Qwen2-Audio\rThe person says ‘毕竟是年事已高啊’ in Mandarin. 音频分析：混合音频中的歌词识别\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\rThe lyrics of the singing are ‘住着我最深爱的你史上最遥远的距离’. User\rYour browser does not support the audio element. Qwen2-Audio\rThe lyrics of the singing are ‘住着我最深爱的你史上最遥远的距离’. User\rYour browser does not support the audio element. Qwen2-Audio\rThe lyrics of the singing are ‘住着我最深爱的你史上最遥远的距离’. 音频分析：音乐分析\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r这段音乐包含有合成器的旋律，低音吉他和鼓点。鼓点是由原声鼓和小军鼓组成的，并且在循环的后半部分有一个上升的打击乐段。这首歌可能在家里跳舞时播放。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r这段音乐的调性是F#小调。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r这段音乐的BPM大约为130.045。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r这段音乐听起来像是朋克风格，有扭曲的电吉他、有力的鼓点和一个声音尖锐的男声在唱歌。整体感觉很强烈和充满能量。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r它传达了一种愤怒和挑战的情绪。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r它的BPM大约是100到120之间。 Your browser does not support the audio element. 音频分析：综合分析\rNext\rUser\rYour browser does not support the audio element. Qwen2-Audio\r有人在说话，内容是“梅西助跑打门球进了，球进了，比赛的第23分钟，阿根廷队1-0领先，梅西本届赛事的第六个球。” Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r这段音频的场景是足球比赛中的一个片段。梅西在比赛中助跑并打门进球，使得阿根廷队以1比0领先。这已经是梅西在本届赛事中的第六个球。现场有观众欢呼，气氛热烈。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r音频中有球迷欢呼的声音，因为梅西进球了。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r这是来自体育场内的声音。 Your browser does not support the audio element. User\rYour browser does not support the audio element. Qwen2-Audio\r这段音频可以用来制作体育新闻或比赛实况转播。 Your browser does not support the audio element. 模型效果 我们已经在一系列基准数据集上进行了实验，包括 LibriSpeech、Common Voice 15、Fleurs、Aishell2、CoVoST2、Meld、Vocalsound 以及 AIR-Benchmark，以评估 Qwen2-Audio 与我们之前发布的 Qwen-Audio 以及各项任务中的最先进模型相比的表现。下面我们将展示一张图表来说明 Qwen2-Audio 相对于竞争对手的表现。在所有任务中，Qwen2-Audio 都显著超越了先前的最佳模型或是 Qwen-Audio。\n关于数据集的更具体结果列于下表中。\n结构与训练范式 下图展示了模型结构及训练方法。具体来说，我们使用 Qwen 语言模型和音频编码器这两个基础模型，接着依次进行多任务预训练以实现音频与语言的对齐，以及 SFT 和 DPO 来掌握下游任务的能力并捕捉人类的偏好。\n如何使用 Qwen2-Audio 已经被 Hugging Face Transfomers 官方支持。我们建议您通过源码安装 transformers ，如下所示：\npip install git+https://github.com/huggingface/transformers 下面我们展示如何使用 Qwen2-Audio-7B-Instruct 来进行语音对话和音频分析. 下面是一个语音对话的例子：\nfrom io import BytesIO from urllib.request import urlopen import librosa from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\") model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\") conversation = [ {\"role\": \"user\", \"content\": [ {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/guess_age_gender.wav\"}, ]}, {\"role\": \"assistant\", \"content\": \"Yes, the speaker is female and in her twenties.\"}, {\"role\": \"user\", \"content\": [ {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/translate_to_chinese.wav\"}, ]}, ] text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False) audios = [] for message in conversation: if isinstance(message[\"content\"], list): for ele in message[\"content\"]: if ele[\"type\"] == \"audio\": audios.append(librosa.load( BytesIO(urlopen(ele['audio_url']).read()), sr=processor.feature_extractor.sampling_rate)[0] ) inputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True) inputs.input_ids = inputs.input_ids.to(\"cuda\") generate_ids = model.generate(**inputs, max_length=256) generate_ids = generate_ids[:, inputs.input_ids.size(1):] response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] 在语音对话模式中，用户只需输入语音而无需输入文字，指令则通过语音直接传达给模型。下面则是一个音频分析的例子：\nfrom io import BytesIO from urllib.request import urlopen import librosa from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\") model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\") conversation = [ {'role': 'system', 'content': 'You are a helpful assistant.'}, {\"role\": \"user\", \"content\": [ {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/glass-breaking-151256.mp3\"}, {\"type\": \"text\", \"text\": \"What's that sound?\"}, ]}, {\"role\": \"assistant\", \"content\": \"It is the sound of glass shattering.\"}, {\"role\": \"user\", \"content\": [ {\"type\": \"text\", \"text\": \"What can you do when you hear that?\"}, ]}, {\"role\": \"assistant\", \"content\": \"Stay alert and cautious, and check if anyone is hurt or if there is any damage to property.\"}, {\"role\": \"user\", \"content\": [ {\"type\": \"audio\", \"audio_url\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/1272-128104-0000.flac\"}, {\"type\": \"text\", \"text\": \"What does the person say?\"}, ]}, ] text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False) audios = [] for message in conversation: if isinstance(message[\"content\"], list): for ele in message[\"content\"]: if ele[\"type\"] == \"audio\": audios.append( librosa.load( BytesIO(urlopen(ele['audio_url']).read()), sr=processor.feature_extractor.sampling_rate)[0] ) inputs = processor(text=text, audios=audios, return_tensors=\"pt\", padding=True) inputs.input_ids = inputs.input_ids.to(\"cuda\") generate_ids = model.generate(**inputs, max_length=256) generate_ids = generate_ids[:, inputs.input_ids.size(1):] response = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] 与上述例子不同，音频分析模式可以传入文字指令。但是，在这两个模式之间切换只需修改用户输入而无需担心诸如系统指令等其他内容。\n下一步 这次我们带来了全新的音频语言模型 Qwen2-Audio，它支持语音对话和音频分析，并且能够理解超过 8 种语言和方言。在不久的将来，我们计划在更大的预训练数据集上训练出更优秀的 Qwen2-Audio 模型，使该模型能够支持更长的音频（超过30秒），并且我们还将构建更大规模的 Qwen2-Audio 模型，用于研究音频语言模型的扩展定律。\n","wordCount":"1058","inLanguage":"zh","datePublished":"2024-08-09T16:22:39+08:00","dateModified":"2024-08-09T16:22:39+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/zh/blog/qwen2-audio/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen2-Audio：开启语音对话！</h1><div class=post-meta><span title='2024-08-09 16:22:39 +0800 +0800'>2024年8月9日</span>&nbsp;·&nbsp;5 分钟&nbsp;·&nbsp;1058 字&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/qwen2-audio/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://huggingface.co/spaces/Qwen/Qwen2-Audio-Instruct-Demo class="btn external" target=_blank>DEMO</a>
<a href=https://arxiv.org/pdf/2407.10759 class="btn external" target=_blank>PAPER</a>
<a href=https://github.com/QwenLM/Qwen2-Audio class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/collections/Qwen/qwen2-audio-66b628d694096020e0c52ff6 class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><p>在一个通用的AI系统中，核心模型应该能够理解不同模态的信息。当前的大语言模型现在已经能够理解语言并进行推理，并且已经扩展到了更多的模态，包括视觉和音频。此前我们陆续发布了多个 Qwen 语言模型系列以及 Qwen-VL 和 Qwen-Audio 等多模态模型。今天，我们正式发布 Qwen2-Audio。这是 Qwen-Audio 的下一代版本，它能够接受音频和文本输入，并生成文本输出。Qwen2-Audio 具有以下特点：</p><ul><li><p>语音聊天：用户可以使用语音向音频语言模型发出指令，无需通过自动语音识别（ASR）模块。</p></li><li><p>音频分析：该模型能够根据文本指令分析音频信息，包括语音、声音、音乐等。</p></li><li><p>多语言支持：该模型支持超过8种语言和方言，例如中文、英语、粤语、法语、意大利语、西班牙语、德语和日语。</p></li></ul><br><p>我们在 Hugging Face 和 ModelScope 上开源了 Qwen2-Audio-7B 以及 Qwen2-Audio-7B-Instruct，并且我们搭建了一个 demo 供用户互动。下面是一些具体例子：</p><style>.example-content .grid-layout{display:grid;grid-template-columns:1fr;row-gap:var(--content-gap)}.example-container{width:100%;padding:0;margin:0}.grid-layout{display:flex;flex-direction:column;width:100%;grid-template-columns:1fr}.message{display:flex;flex-direction:column;align-items:flex-start;width:100%}.role{font-weight:700;margin-right:5px;white-space:nowrap}.content{display:flex;align-items:center;white-space:pre-wrap;width:100%;margin-bottom:10px;margin-left:50px}.wide-content{width:100%}.audio-icon{flex-shrink:0;margin-right:10px;margin-bottom:10px}.text-content{flex-grow:1;width:100%;white-space:pre-wrap;margin-top:10px}audio{vertical-align:middle}</style><h3 id=语音交互>语音交互<a hidden class=anchor aria-hidden=true href=#语音交互>#</a></h3><div class="full-width-container example-container"><div class=example-content><div class=title><span>语音交互：基础交互</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1719289379143.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这种情况可能会让人感到沮丧和困惑，但是你需要记住的是，你不能强迫任何人去喜欢你。如果你真的喜欢这个女孩，那么最好的办法就是尊重她的感受，不去打扰她，同时也要保持自己的尊严。
以下是一些建议：
&nbsp
1. 尊重她的决定：如果她明确表示不喜欢你，那么你应该尊重她的决定，不要试图改变她的想法。
2. 不要过于干涉：避免过多地干涉她的生活，也不要试图通过各种方式来接近她。
3. 保持距离：尽量避免与她有太多的接触，尤其是在她不希望的情况下。
4. 寻求支持：如果你感到很难过或者困惑，可以向你的朋友或家人寻求支持和建议。
&nbsp
最重要的是，你要保持自己的尊严和自信，不要因为别人的喜好而失去自我。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-3-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1719289395921.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>很抱歉，我无法帮助你追求她。这不仅是因为我是一个人工智能助手，而且也是因为她已经明确表示不喜欢你。在这种情况下，我建议你尊重她的决定，同时也要保持自己的尊严和自信。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-3-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1719289430389.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>当然可以！追女孩子需要付出努力和耐心，但同时也需要尊重她们的感受和意愿。以下是一些基本的建议：
&nbsp
1. 做一个有趣的人：尽可能多地展示出你的幽默感和创造力，让女孩子觉得和你在一起会很开心。
2. 主动出击：如果你对某个女孩子感兴趣，不妨主动和她交流，比如邀请她一起吃饭、看电影等。
3. 给予关注：多关注女孩子的生活，了解她的兴趣爱好，给她提供帮助和支持。
4. 表达情感：用适当的方式表达你的情感，让她知道你对她有着特殊的感情。
5. 尊重她的选择：如果女孩子对你没有同样的感觉，你需要尊重她的决定，不要强求。
&nbsp
最后，要记住，每个人都是独特的，所以你需要根据她的个性和喜好来调整你的行为和策略。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-3-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1719289572677.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>当然啦！制造浪漫惊喜的方法有很多，以下是一些常见的建议：
&nbsp
1. 制作一张手写卡片：写下你的心声，告诉她你有多么爱她。
2. 准备一份特别的礼物：可以是她最喜欢的物品，也可以是你自己亲手制作的东西。
3. 安排一次特别的约会：可以选择一家浪漫的餐厅，或者去看一场电影。
4. 给她一个意想不到的惊喜：比如在她的生日那天，提前安排好一个惊喜派对。
5. 帮助她实现一个梦想：如果她有什么梦想，尽你所能去帮助她实现。
6. 在她最需要的时候陪伴她：无论是在她生病还是遇到困难的时候，都要在她身边陪伴她。
&nbsp
最重要的是，要用心去制造每一个浪漫惊喜，让她感受到你的爱意和关心。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-3-4.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div></div></div><div class=example-content style=display:none><div class=title><span>语音交互：背景音乐感知及推荐</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1719289082714.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>在这种环境下，你可以做很多事情，比如阅读、写作、编程、学习新技能、练习乐器、看电影、玩游戏等。你也可以和朋友聊天、锻炼身体、烹饪美食、组织活动等。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-2-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1719289129739.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>当然可以！根据你的兴趣，我推荐《哈利·波特》系列、《冰与火之歌》系列、《指环王》系列、《福尔摩斯探案集》、《傲慢与偏见》、《老人与海》、《1984》、《麦田里的守望者》等。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-2-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/dianying.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>当然有！我推荐《肖申克的救赎》、《星球大战：帝国反击战》、《阿甘正传》、《美丽心灵》、《饮食男女》、《盗梦空间》、《海上钢琴师》、《机器人总动员》等。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-2-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/yueqi.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>我推荐学习钢琴，因为钢琴是一种多才多艺的乐器，能够演奏出美妙的旋律，并且有很多有趣的技巧可以探索。学习钢琴的最佳方法是每天定时练习，每次至少30分钟，同时结合听音乐、看视频、参加课程等方式来加深理解。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-2-4.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div></div></div><div class=example-content style=display:none><div class=title><span>语音交互：说话人信息识别及环境音感知交互</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/voice-chat-1-1-%E7%8C%9C%E7%8C%9C%E6%80%A7%E5%88%AB%E5%B9%B4%E9%BE%84.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>男性，16-25岁
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-1-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/voice-chat-2-1-%E9%9B%A8%E5%A3%B0%E7%9D%A1%E8%A7%89.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>因为这种场景让你感到放松和舒适，有助于提高睡眠质量。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-1-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/voice-chat-2-2-%E8%A3%85%E4%BF%AE%E5%99%AA%E9%9F%B3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>你可以尝试使用耳塞或者寻找一个相对安静的工作环境来帮助你集中注意力。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-1-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div></div></div></div><h3 id=音频分析>音频分析<a hidden class=anchor aria-hidden=true href=#音频分析>#</a></h3><div class="full-width-container example-container"><div class=example-content><div class=title><span>音频分析：说话人信息识别</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_5-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>两个人在说话。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a1-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_5-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>说话人的情绪是兴奋和满意的。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a1-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_5-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>说话人大概在41岁以上。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a1-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div></div></div><div class=example-content style=display:none><div class=title><span>音频分析：混合音频分析</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_1-0.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音频的原始内容是:‘路过灌木丛时’
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a2-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_1-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>有人在说话，内容是’路过灌木丛时’。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a2-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_1-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>有人在说话，内容是’路过灌木丛时’。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a2-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1718961628717.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>男性。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a2-4.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/audio_1718961640722.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>他说的是：‘When passing through the bushes.’</div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/spk_00.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>The person says ‘毕竟是年事已高啊’ in Mandarin.</div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/spk_33.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>The person says ‘毕竟是年事已高啊’ in Mandarin.</div></div></div></div></div><div class=example-content style=display:none><div class=title><span>音频分析：混合音频中的歌词识别</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/robust_zh_0.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>The lyrics of the singing are ‘住着我最深爱的你史上最遥远的距离’.</div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/robust_zh_1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>The lyrics of the singing are ‘住着我最深爱的你史上最遥远的距离’.</div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/robust_zh_2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>The lyrics of the singing are ‘住着我最深爱的你史上最遥远的距离’.</div></div></div></div></div><div class=example-content style=display:none><div class=title><span>音频分析：音乐分析</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/music_qingting_ACT9MsIM5Bg.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音乐包含有合成器的旋律，低音吉他和鼓点。鼓点是由原声鼓和小军鼓组成的，并且在循环的后半部分有一个上升的打击乐段。这首歌可能在家里跳舞时播放。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/合成1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/key_zh.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音乐的调性是F#小调。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/bpm.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音乐的BPM大约为130.045。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/bpm合成.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/music_fenxi__zVFfYfyyFg.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音乐听起来像是朋克风格，有扭曲的电吉他、有力的鼓点和一个声音尖锐的男声在唱歌。整体感觉很强烈和充满能量。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/合成4.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/qingxu .wav" type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>它传达了一种愤怒和挑战的情绪。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/5.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/bpm_p.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>它的BPM大约是100到120之间。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/6.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div></div></div><div class=example-content style=display:none><div class=title><span>音频分析：综合分析</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_9-5.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>有人在说话，内容是“梅西助跑打门球进了，球进了，比赛的第23分钟，阿根廷队1-0领先，梅西本届赛事的第六个球。”
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a5-5.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_9-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音频的场景是足球比赛中的一个片段。梅西在比赛中助跑并打门进球，使得阿根廷队以1比0领先。这已经是梅西在本届赛事中的第六个球。现场有观众欢呼，气氛热烈。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a5-1.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_9-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>音频中有球迷欢呼的声音，因为梅西进球了。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a5-2.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_9-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这是来自体育场内的声音。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a5-3.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>User</div><div class="content wide-content"><div class=text-content><audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/WHJ_9-4.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div><div class=message><div class=role>Qwen2-Audio</div><div class="content wide-content"><div class=text-content>这段音频可以用来制作体育新闻或比赛实况转播。
<audio class=audio-icon controls><source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/tts-a5-4.wav type=audio/wav>Your browser does not support the audio element.</audio></div></div></div></div></div></div><h2 id=模型效果>模型效果<a hidden class=anchor aria-hidden=true href=#模型效果>#</a></h2><p>我们已经在一系列基准数据集上进行了实验，包括 LibriSpeech、Common Voice 15、Fleurs、Aishell2、CoVoST2、Meld、Vocalsound 以及 AIR-Benchmark，以评估 Qwen2-Audio 与我们之前发布的 Qwen-Audio 以及各项任务中的最先进模型相比的表现。下面我们将展示一张图表来说明 Qwen2-Audio 相对于竞争对手的表现。在所有任务中，Qwen2-Audio 都显著超越了先前的最佳模型或是 Qwen-Audio。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/radar_compare_qwen_audio.png#center width=80%></figure><p>关于数据集的更具体结果列于下表中。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/assets/blog/qwenaudio/table.jpg#center width=100%></figure><h2 id=结构与训练范式>结构与训练范式<a hidden class=anchor aria-hidden=true href=#结构与训练范式>#</a></h2><p>下图展示了模型结构及训练方法。具体来说，我们使用 Qwen 语言模型和音频编码器这两个基础模型，接着依次进行多任务预训练以实现音频与语言的对齐，以及 SFT 和 DPO 来掌握下游任务的能力并捕捉人类的偏好。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/demo/framework.png#center width=80%></figure><h2 id=如何使用>如何使用<a hidden class=anchor aria-hidden=true href=#如何使用>#</a></h2><p>Qwen2-Audio 已经被 Hugging Face Transfomers 官方支持。我们建议您通过源码安装 <code>transformers</code> ，如下所示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install git+https://github.com/huggingface/transformers
</span></span></code></pre></div><p>下面我们展示如何使用 <code>Qwen2-Audio-7B-Instruct</code> 来进行语音对话和音频分析. 下面是一个语音对话的例子：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>io</span> <span class=kn>import</span> <span class=n>BytesIO</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>urllib.request</span> <span class=kn>import</span> <span class=n>urlopen</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>librosa</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>Qwen2AudioForConditionalGeneration</span><span class=p>,</span> <span class=n>AutoProcessor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen2-Audio-7B-Instruct&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Qwen2AudioForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen2-Audio-7B-Instruct&#34;</span><span class=p>,</span> <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>conversation</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;audio&#34;</span><span class=p>,</span> <span class=s2>&#34;audio_url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/guess_age_gender.wav&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Yes, the speaker is female and in her twenties.&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;audio&#34;</span><span class=p>,</span> <span class=s2>&#34;audio_url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/translate_to_chinese.wav&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>conversation</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>audios</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>message</span> <span class=ow>in</span> <span class=n>conversation</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>],</span> <span class=nb>list</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>ele</span> <span class=ow>in</span> <span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>ele</span><span class=p>[</span><span class=s2>&#34;type&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=s2>&#34;audio&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>audios</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>librosa</span><span class=o>.</span><span class=n>load</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>BytesIO</span><span class=p>(</span><span class=n>urlopen</span><span class=p>(</span><span class=n>ele</span><span class=p>[</span><span class=s1>&#39;audio_url&#39;</span><span class=p>])</span><span class=o>.</span><span class=n>read</span><span class=p>()),</span> 
</span></span><span class=line><span class=cl>                    <span class=n>sr</span><span class=o>=</span><span class=n>processor</span><span class=o>.</span><span class=n>feature_extractor</span><span class=o>.</span><span class=n>sampling_rate</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>text</span><span class=p>,</span> <span class=n>audios</span><span class=o>=</span><span class=n>audios</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>generate_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>generate_ids</span> <span class=o>=</span> <span class=n>generate_ids</span><span class=p>[:,</span> <span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>):]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>generate_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>clean_up_tokenization_spaces</span><span class=o>=</span><span class=kc>False</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span></code></pre></div><p>在语音对话模式中，用户只需输入语音而无需输入文字，指令则通过语音直接传达给模型。下面则是一个音频分析的例子：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>io</span> <span class=kn>import</span> <span class=n>BytesIO</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>urllib.request</span> <span class=kn>import</span> <span class=n>urlopen</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>librosa</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>Qwen2AudioForConditionalGeneration</span><span class=p>,</span> <span class=n>AutoProcessor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen2-Audio-7B-Instruct&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Qwen2AudioForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen2-Audio-7B-Instruct&#34;</span><span class=p>,</span> <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>conversation</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;role&#39;</span><span class=p>:</span> <span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;content&#39;</span><span class=p>:</span> <span class=s1>&#39;You are a helpful assistant.&#39;</span><span class=p>},</span> 
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;audio&#34;</span><span class=p>,</span> <span class=s2>&#34;audio_url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/glass-breaking-151256.mp3&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;What&#39;s that sound?&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;It is the sound of glass shattering.&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;What can you do when you hear that?&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Stay alert and cautious, and check if anyone is hurt or if there is any damage to property.&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;audio&#34;</span><span class=p>,</span> <span class=s2>&#34;audio_url&#34;</span><span class=p>:</span> <span class=s2>&#34;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-Audio/audio/1272-128104-0000.flac&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;What does the person say?&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>conversation</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>audios</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>message</span> <span class=ow>in</span> <span class=n>conversation</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>],</span> <span class=nb>list</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>ele</span> <span class=ow>in</span> <span class=n>message</span><span class=p>[</span><span class=s2>&#34;content&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>ele</span><span class=p>[</span><span class=s2>&#34;type&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=s2>&#34;audio&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>audios</span><span class=o>.</span><span class=n>append</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>librosa</span><span class=o>.</span><span class=n>load</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                        <span class=n>BytesIO</span><span class=p>(</span><span class=n>urlopen</span><span class=p>(</span><span class=n>ele</span><span class=p>[</span><span class=s1>&#39;audio_url&#39;</span><span class=p>])</span><span class=o>.</span><span class=n>read</span><span class=p>()),</span> 
</span></span><span class=line><span class=cl>                        <span class=n>sr</span><span class=o>=</span><span class=n>processor</span><span class=o>.</span><span class=n>feature_extractor</span><span class=o>.</span><span class=n>sampling_rate</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>text</span><span class=p>,</span> <span class=n>audios</span><span class=o>=</span><span class=n>audios</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>generate_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>generate_ids</span> <span class=o>=</span> <span class=n>generate_ids</span><span class=p>[:,</span> <span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>1</span><span class=p>):]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>generate_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>clean_up_tokenization_spaces</span><span class=o>=</span><span class=kc>False</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span></code></pre></div><p>与上述例子不同，音频分析模式可以传入文字指令。但是，在这两个模式之间切换只需修改用户输入而无需担心诸如系统指令等其他内容。</p><h2 id=下一步>下一步<a hidden class=anchor aria-hidden=true href=#下一步>#</a></h2><p>这次我们带来了全新的音频语言模型 Qwen2-Audio，它支持语音对话和音频分析，并且能够理解超过 8 种语言和方言。在不久的将来，我们计划在更大的预训练数据集上训练出更优秀的 Qwen2-Audio 模型，使该模型能够支持更长的音频（超过30秒），并且我们还将构建更大规模的 Qwen2-Audio 模型，用于研究音频语言模型的扩展定律。</p></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>