<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen3 Embedding：新一代文本表征与排序模型 | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE DISCORD
我们正式发布 Qwen3 Embedding 系列模型, Qwen 模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于 Qwen3 基础模型进行训练，充分继承了 Qwen3 在多语言文本理解能力方面的优势。在多项基准测试中，Qwen3 Embedding 系列在文本表征和排序任务中展现了卓越的性能。我们使用了 Apache 2.0 协议在 Hugging Face 和 ModelScope 上开源了这一系列的文本表征及排序模型，并在 GitHub 公布了技术报告及相关代码。
排序模型评测结果
Model Param MTEB-R CMTEB-R MMTEB-R MLDR MTEB-Code FollowIR Qwen3-Embedding-0.6B 0.6B 61.82 71.02 64.64 50.26 75.41 5.09 Jina-multilingual-reranker-v2-base 0.3B 58.22 63.37 63.73 39.66 58.98 -0.68 gte-multilingual-reranker-base 0.3B 59.51 74.08 59.44 66.33 54.18 -1.64 BGE-reranker-v2-m3 0.6B 57.03 72.16 58.36 59.51 41.38 -0.01 Qwen3-Reranker-0.6B 0."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/qwen3-embedding/><link crossorigin=anonymous href=/assets/css/stylesheet.25451dd4678157e0fb2e84a2fba5ad7861ab458e1168319a052575d04324b785.css integrity="sha256-JUUd1GeBV+D7LoSi+6WteGGrRY4RaDGaBSV10EMkt4U=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen3-embedding/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen3-embedding/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen3 Embedding：新一代文本表征与排序模型"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE DISCORD
我们正式发布 Qwen3 Embedding 系列模型, Qwen 模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于 Qwen3 基础模型进行训练，充分继承了 Qwen3 在多语言文本理解能力方面的优势。在多项基准测试中，Qwen3 Embedding 系列在文本表征和排序任务中展现了卓越的性能。我们使用了 Apache 2.0 协议在 Hugging Face 和 ModelScope 上开源了这一系列的文本表征及排序模型，并在 GitHub 公布了技术报告及相关代码。
排序模型评测结果
Model Param MTEB-R CMTEB-R MMTEB-R MLDR MTEB-Code FollowIR Qwen3-Embedding-0.6B 0.6B 61.82 71.02 64.64 50.26 75.41 5.09 Jina-multilingual-reranker-v2-base 0.3B 58.22 63.37 63.73 39.66 58.98 -0.68 gte-multilingual-reranker-base 0.3B 59.51 74.08 59.44 66.33 54.18 -1.64 BGE-reranker-v2-m3 0.6B 57.03 72.16 58.36 59.51 41.38 -0.01 Qwen3-Reranker-0.6B 0."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/qwen3-embedding/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-06-05T21:00:00+08:00"><meta property="article:modified_time" content="2025-06-05T21:00:00+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen3 Embedding：新一代文本表征与排序模型"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE DISCORD
我们正式发布 Qwen3 Embedding 系列模型, Qwen 模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于 Qwen3 基础模型进行训练，充分继承了 Qwen3 在多语言文本理解能力方面的优势。在多项基准测试中，Qwen3 Embedding 系列在文本表征和排序任务中展现了卓越的性能。我们使用了 Apache 2.0 协议在 Hugging Face 和 ModelScope 上开源了这一系列的文本表征及排序模型，并在 GitHub 公布了技术报告及相关代码。
排序模型评测结果
Model Param MTEB-R CMTEB-R MMTEB-R MLDR MTEB-Code FollowIR Qwen3-Embedding-0.6B 0.6B 61.82 71.02 64.64 50.26 75.41 5.09 Jina-multilingual-reranker-v2-base 0.3B 58.22 63.37 63.73 39.66 58.98 -0.68 gte-multilingual-reranker-base 0.3B 59.51 74.08 59.44 66.33 54.18 -1.64 BGE-reranker-v2-m3 0.6B 57.03 72.16 58.36 59.51 41.38 -0.01 Qwen3-Reranker-0.6B 0."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Qwen3 Embedding：新一代文本表征与排序模型","item":"https://qwenlm.github.io/zh/blog/qwen3-embedding/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen3 Embedding：新一代文本表征与排序模型","name":"Qwen3 Embedding：新一代文本表征与排序模型","description":"GITHUB HUGGING FACE MODELSCOPE DISCORD\n我们正式发布 Qwen3 Embedding 系列模型, Qwen 模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于 Qwen3 基础模型进行训练，充分继承了 Qwen3 在多语言文本理解能力方面的优势。在多项基准测试中，Qwen3 Embedding 系列在文本表征和排序任务中展现了卓越的性能。我们使用了 Apache 2.0 协议在 Hugging Face 和 ModelScope 上开源了这一系列的文本表征及排序模型，并在 GitHub 公布了技术报告及相关代码。\n排序模型评测结果\nModel Param MTEB-R CMTEB-R MMTEB-R MLDR MTEB-Code FollowIR Qwen3-Embedding-0.6B 0.6B 61.82 71.02 64.64 50.26 75.41 5.09 Jina-multilingual-reranker-v2-base 0.3B 58.22 63.37 63.73 39.66 58.98 -0.68 gte-multilingual-reranker-base 0.3B 59.51 74.08 59.44 66.33 54.18 -1.64 BGE-reranker-v2-m3 0.6B 57.03 72.16 58.36 59.51 41.38 -0.01 Qwen3-Reranker-0.6B 0.","keywords":[],"articleBody":" GITHUB HUGGING FACE MODELSCOPE DISCORD\n我们正式发布 Qwen3 Embedding 系列模型, Qwen 模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于 Qwen3 基础模型进行训练，充分继承了 Qwen3 在多语言文本理解能力方面的优势。在多项基准测试中，Qwen3 Embedding 系列在文本表征和排序任务中展现了卓越的性能。我们使用了 Apache 2.0 协议在 Hugging Face 和 ModelScope 上开源了这一系列的文本表征及排序模型，并在 GitHub 公布了技术报告及相关代码。\n排序模型评测结果\nModel Param MTEB-R CMTEB-R MMTEB-R MLDR MTEB-Code FollowIR Qwen3-Embedding-0.6B 0.6B 61.82 71.02 64.64 50.26 75.41 5.09 Jina-multilingual-reranker-v2-base 0.3B 58.22 63.37 63.73 39.66 58.98 -0.68 gte-multilingual-reranker-base 0.3B 59.51 74.08 59.44 66.33 54.18 -1.64 BGE-reranker-v2-m3 0.6B 57.03 72.16 58.36 59.51 41.38 -0.01 Qwen3-Reranker-0.6B 0.6B 65.80 71.31 66.36 67.28 73.42 5.41 Qwen3-Reranker-4B 4B 69.76 75.94 72.74 69.97 81.20 14.84 Qwen3-Reranker-8B 8B 69.02 77.45 72.94 70.19 81.22 8.05 Note:\n我们使用MTEB(eng, v2), MTEB(cmn, v1), MTEB (Multilingual) 以及MTEB (Code)中的检索数据集进行测试, 分别记作MTEB-R, CMTEB-R, MMTEB-R, MTEB-Code. 排序结果基于Qwen3-Embedding-0.6B的top-100向量召回结果进行排序. 主要特点:\n卓越的泛化性: Qwen3 Embedding 系列在多个下游任务评估中达到行业领先水平。其中，8B 参数规模的Embedding模型在MTEB多语言Leaderboard榜单中位列第一（截至 2025 年 6 月 5 日，得分 70.58），性能超越众多商业 API 服务。此外，该系列的排序模型在各类文本检索场景中表现出色，显著提升了搜索结果的相关性。\n灵活的模型架构: Qwen3 Embedding 系列提供从 0.6B 到 8B 参数规模的 3 种模型配置，以满足不同场景下的性能与效率需求。开发者可以灵活组合表征与排序模块，实现功能扩展。此外，模型支持以下定制化特性：1) 表征维度自定义：允许用户根据实际需求调整表征维度，有效降低应用成本；2) 指令适配优化：支持用户自定义指令模板，以提升特定任务、语言或场景下的性能表现。\n全面的多语言支持: Qwen3 Embedding 系列支持超过 100 种语言，涵盖主流自然语言及多种编程语言。该系列模型具备强大的多语言、跨语言及代码检索能力，能够有效应对多语言场景下的数据处理需求。\n模型总览 Model Type Models Size Layers Sequence Length Embedding Dimension MRL Support Instruction Aware Text Embedding Qwen3-Embedding-0.6B 0.6B 28 32K 1024 Yes Yes Qwen3-Embedding-4B 4B 36 32K 2560 Yes Yes Qwen3-Embedding-8B 8B 36 32K 4096 Yes Yes Text Reranking Qwen3-Reranker-0.6B 0.6B 28 32K - - Yes Qwen3-Reranker-4B 4B 36 32K - - Yes Qwen3-Reranker-8B 8B 36 32K - - Yes 注：MRL Support 表示 Embedding 模型是否支持最终向量的自定义维度。Instruction Aware 表示 Embedding 或 Reranking 模型是否支持根据不同任务定制输入指令。\n模型架构 基于 Qwen3 基础模型，我们的 Embedding 模型和 Reranking 模型分别采用了双塔结构和单塔结构的设计。通过 LoRA 微调，我们最大限度地保留并继承了基础模型的文本理解能力。具体实现如下：1) Embedding 模型接收单段文本作为输入，取模型最后一层[EOS]标记对应的隐藏状态向量，作为输入文本的语义表示；2) Reranking 模型则接收文本对（例如用户查询与候选文档）作为输入，利用单塔结构计算并输出两个文本的相关性得分。\n模型训练 Qwen3 Embedding 系列模型的训练继承了 GTE-Qwen 系列的多阶段训练范式，但针对具体应用场景进行了深度优化。在 Embedding 模型的训练过程中，我们采用三阶段训练架构：第一阶段通过超大规模弱监督数据进行对比学习预训练；第二阶段基于高质量标注数据进行监督训练；最终通过模型融合策略融合多个候选模型，以提升整体性能。这种分阶段训练机制有效平衡了模型的泛化能力与任务适配性。\n在 Reranking 模型的训练中，基于实验验证结果，我们直接采用高质量标注数据进行监督训练，以提升训练效率。特别需要说明的是，在 Embedding 模型的第一阶段弱监督训练中，我们构建了多任务适配的 Prompt 体系，利用 Qwen3 基础模型的文本生成能力，我们针对不同任务类型和语言特性，动态生成了一系列弱监督文本对，突破了传统方法依赖社区论坛或开源数据筛选获取弱监督文本对的局限性，实现了大规模弱监督数据的高效生成。\n未来发展 Qwen3 Embedding 系列模型是一个新的起点，依托于 Qwen 基础模型的持续优化, 我们将继续提升文本表征与排序模型的训练效率，以增强模型在实际场景中的部署性能。此外，我们还计划拓展多模态表征体系，构建跨模态语义理解能力。我们期待更多开发者基于 Qwen3 Embedding 系列探索更广泛的应用场景，推动模型在不同业务场景中的深入应用。\n","wordCount":"251","inLanguage":"zh","datePublished":"2025-06-05T21:00:00+08:00","dateModified":"2025-06-05T21:00:00+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/zh/blog/qwen3-embedding/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen3 Embedding：新一代文本表征与排序模型</h1><div class=post-meta><span title='2025-06-05 21:00:00 +0800 +0800'>2025年6月5日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;251 字&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/qwen3-embedding/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://github.com/QwenLM/Qwen3-Embedding class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/Qwen class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><p>我们正式发布 Qwen3 Embedding 系列模型, Qwen 模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于 Qwen3 基础模型进行训练，充分继承了 Qwen3 在多语言文本理解能力方面的优势。在多项基准测试中，Qwen3 Embedding 系列在文本表征和排序任务中展现了卓越的性能。我们使用了 Apache 2.0 协议在 Hugging Face 和 ModelScope 上开源了这一系列的文本表征及排序模型，并在 GitHub 公布了技术报告及相关代码。</p><div align=center><img src=https://mitalinlp.oss-cn-hangzhou.aliyuncs.com/dingkun/models/qwen-embedding/q3e-mteb-result-0605.png alt width=800></div><p><strong>排序模型评测结果</strong></p><table><thead><tr><th>Model</th><th>Param</th><th>MTEB-R</th><th>CMTEB-R</th><th>MMTEB-R</th><th>MLDR</th><th>MTEB-Code</th><th>FollowIR</th></tr></thead><tbody><tr><td><strong>Qwen3-Embedding-0.6B</strong></td><td>0.6B</td><td>61.82</td><td>71.02</td><td>64.64</td><td>50.26</td><td>75.41</td><td>5.09</td></tr><tr><td>Jina-multilingual-reranker-v2-base</td><td>0.3B</td><td>58.22</td><td>63.37</td><td>63.73</td><td>39.66</td><td>58.98</td><td>-0.68</td></tr><tr><td>gte-multilingual-reranker-base</td><td>0.3B</td><td>59.51</td><td>74.08</td><td>59.44</td><td>66.33</td><td>54.18</td><td>-1.64</td></tr><tr><td>BGE-reranker-v2-m3</td><td>0.6B</td><td>57.03</td><td>72.16</td><td>58.36</td><td>59.51</td><td>41.38</td><td>-0.01</td></tr><tr><td><strong>Qwen3-Reranker-0.6B</strong></td><td>0.6B</td><td>65.80</td><td>71.31</td><td>66.36</td><td>67.28</td><td>73.42</td><td>5.41</td></tr><tr><td><strong>Qwen3-Reranker-4B</strong></td><td>4B</td><td><strong>69.76</strong></td><td>75.94</td><td>72.74</td><td>69.97</td><td>81.20</td><td><strong>14.84</strong></td></tr><tr><td><strong>Qwen3-Reranker-8B</strong></td><td>8B</td><td>69.02</td><td><strong>77.45</strong></td><td><strong>72.94</strong></td><td><strong>70.19</strong></td><td><strong>81.22</strong></td><td>8.05</td></tr></tbody></table><blockquote><p><strong>Note</strong>:</p><ul><li>我们使用MTEB(eng, v2), MTEB(cmn, v1), MTEB (Multilingual) 以及MTEB (Code)中的检索数据集进行测试, 分别记作MTEB-R, CMTEB-R, MMTEB-R, MTEB-Code.</li><li>排序结果基于<a href=https://huggingface.co/Qwen/Qwen3-Embedding-0.6B>Qwen3-Embedding-0.6B</a>的top-100向量召回结果进行排序.</li></ul></blockquote><p><strong>主要特点</strong>:</p><p><strong>卓越的泛化性</strong>: Qwen3 Embedding 系列在多个下游任务评估中达到行业领先水平。其中，8B 参数规模的Embedding模型在MTEB多语言Leaderboard榜单中位列第一（截至 2025 年 6 月 5 日，得分 <strong>70.58</strong>），性能超越众多商业 API 服务。此外，该系列的排序模型在各类文本检索场景中表现出色，显著提升了搜索结果的相关性。</p><p><strong>灵活的模型架构</strong>: Qwen3 Embedding 系列提供从 0.6B 到 8B 参数规模的 3 种模型配置，以满足不同场景下的性能与效率需求。开发者可以灵活组合表征与排序模块，实现功能扩展。此外，模型支持以下定制化特性：1) 表征维度自定义：允许用户根据实际需求调整表征维度，有效降低应用成本；2) 指令适配优化：支持用户自定义指令模板，以提升特定任务、语言或场景下的性能表现。</p><p><strong>全面的多语言支持</strong>: Qwen3 Embedding 系列支持超过 100 种语言，涵盖主流自然语言及多种编程语言。该系列模型具备强大的多语言、跨语言及代码检索能力，能够有效应对多语言场景下的数据处理需求。</p><h2 id=模型总览>模型总览<a hidden class=anchor aria-hidden=true href=#模型总览>#</a></h2><table><thead><tr><th>Model Type</th><th>Models</th><th>Size</th><th>Layers</th><th>Sequence Length</th><th>Embedding Dimension</th><th>MRL Support</th><th>Instruction Aware</th></tr></thead><tbody><tr><td><strong>Text Embedding</strong></td><td>Qwen3-Embedding-0.6B</td><td>0.6B</td><td>28</td><td>32K</td><td>1024</td><td>Yes</td><td>Yes</td></tr><tr><td></td><td>Qwen3-Embedding-4B</td><td>4B</td><td>36</td><td>32K</td><td>2560</td><td>Yes</td><td>Yes</td></tr><tr><td></td><td>Qwen3-Embedding-8B</td><td>8B</td><td>36</td><td>32K</td><td>4096</td><td>Yes</td><td>Yes</td></tr><tr><td><strong>Text Reranking</strong></td><td>Qwen3-Reranker-0.6B</td><td>0.6B</td><td>28</td><td>32K</td><td>-</td><td>-</td><td>Yes</td></tr><tr><td></td><td>Qwen3-Reranker-4B</td><td>4B</td><td>36</td><td>32K</td><td>-</td><td>-</td><td>Yes</td></tr><tr><td></td><td>Qwen3-Reranker-8B</td><td>8B</td><td>36</td><td>32K</td><td>-</td><td>-</td><td>Yes</td></tr></tbody></table><p>注：<code>MRL Support</code> 表示 Embedding 模型是否支持最终向量的自定义维度。<code>Instruction Aware</code> 表示 Embedding 或 Reranking 模型是否支持根据不同任务定制输入指令。</p><h2 id=模型架构>模型架构<a hidden class=anchor aria-hidden=true href=#模型架构>#</a></h2><p>基于 Qwen3 基础模型，我们的 Embedding 模型和 Reranking 模型分别采用了双塔结构和单塔结构的设计。通过 LoRA 微调，我们最大限度地保留并继承了基础模型的文本理解能力。具体实现如下：1) Embedding 模型接收单段文本作为输入，取模型最后一层<code>[EOS]</code>标记对应的隐藏状态向量，作为输入文本的语义表示；2) Reranking 模型则接收文本对（例如用户查询与候选文档）作为输入，利用单塔结构计算并输出两个文本的相关性得分。</p><div align=center><img src=https://mitalinlp.oss-cn-hangzhou.aliyuncs.com/dingkun/models/qwen-embedding/q3e-model-arc.png alt width=600></div><h2 id=模型训练>模型训练<a hidden class=anchor aria-hidden=true href=#模型训练>#</a></h2><p>Qwen3 Embedding 系列模型的训练继承了 GTE-Qwen 系列的多阶段训练范式，但针对具体应用场景进行了深度优化。在 Embedding 模型的训练过程中，我们采用三阶段训练架构：第一阶段通过超大规模弱监督数据进行对比学习预训练；第二阶段基于高质量标注数据进行监督训练；最终通过模型融合策略融合多个候选模型，以提升整体性能。这种分阶段训练机制有效平衡了模型的泛化能力与任务适配性。</p><p>在 Reranking 模型的训练中，基于实验验证结果，我们直接采用高质量标注数据进行监督训练，以提升训练效率。特别需要说明的是，在 Embedding 模型的第一阶段弱监督训练中，我们构建了多任务适配的 Prompt 体系，利用 Qwen3 基础模型的文本生成能力，我们针对不同任务类型和语言特性，动态生成了一系列弱监督文本对，突破了传统方法依赖社区论坛或开源数据筛选获取弱监督文本对的局限性，实现了大规模弱监督数据的高效生成。</p><div align=center><img src=https://mitalinlp.oss-cn-hangzhou.aliyuncs.com/dingkun/models/qwen-embedding/q3e-train-pipeline.png alt width=600></div><h2 id=未来发展>未来发展<a hidden class=anchor aria-hidden=true href=#未来发展>#</a></h2><p>Qwen3 Embedding 系列模型是一个新的起点，依托于 Qwen 基础模型的持续优化, 我们将继续提升文本表征与排序模型的训练效率，以增强模型在实际场景中的部署性能。此外，我们还计划拓展多模态表征体系，构建跨模态语义理解能力。我们期待更多开发者基于 Qwen3 Embedding 系列探索更广泛的应用场景，推动模型在不同业务场景中的深入应用。</p></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>