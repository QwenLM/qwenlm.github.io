<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.4f62259998ff7b98600586086c11b90753ca941d3fefd46d058f5df6a9fa05f4.css integrity="sha256-T2IlmZj/e5hgBYYIbBG5B1PKlB0/79RtBY9d9qn6BfQ=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://qwenlm.github.io/zh/blog/index.xml><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/>English</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Qwen-Image：擅长文字渲染的创作利器</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
我们很高兴推出 Qwen-Image，一个20B的MMDiT模型。这是通义千问系列中首个图像生成基础模型，其在复杂文本渲染和精确图像编辑方面取得了显著进展。如需体验最新模型，欢迎访问 Qwen Chat 并选择“图像生成”功能。
主要特性包括：
卓越的文本渲染能力: Qwen-Image 在复杂文本渲染方面表现出色，支持多行布局、段落级文本生成以及细粒度细节呈现。无论是英语还是中文，均能实现高保真输出。 一致性的图像编辑能力: 通过增强的多任务训练范式，Qwen-Image 在编辑过程中能出色地保持编辑的一致性。 强大的跨基准性能表现: 在多个公开基准测试中的评估表明，Qwen-Image 在各类生成与编辑任务中均获得SOTA，是一个强大的图像生成基础模型。 性能表现 我们在多个公开基准上对Qwen-Image进行了全面评估，包括用于通用图像生成的GenEval、DPG和OneIG-Bench，以及用于图像编辑的GEdit、ImgEdit和GSO。Qwen-Image在所有基准测试中均取得了最先进的性能，展现出其在图像生成与图像编辑方面的强大能力。此外，在用于文本渲染的LongText-Bench、ChineseWord和TextCraft上的结果表明，Qwen-Image在文本渲染方面表现尤为出色，特别是在中文文本渲染上，大幅领先现有的最先进模型。这凸显了Qwen-Image作为先进图像生成模型的独特地位，兼具广泛的通用能力与卓越的文本渲染精度。
示例展示 Qwen-Image的突出能力之一是能够在不同场景中实现高保真的文本渲染。我们来看下面这个中文渲染的case：
宫崎骏的动漫风格。平视角拍摄，阳光下的古街热闹非凡。一个穿着青衫、手里拿着写着“阿里云”卡片的逍遥派弟子站在中间。旁边两个小孩惊讶的看着他。左边有一家店铺挂着“云存储”的牌子，里面摆放着发光的服务器机箱，门口两个侍卫守护者。右边有两家店铺，其中一家挂着“云计算”的牌子，一个穿着旗袍的美丽女子正看着里面闪闪发光的电脑屏幕；另一家店铺挂着“云模型”的牌子，门口放着一个大酒缸，上面写着“千问”，一位老板娘正在往里面倒发光的代码溶液。
模型不仅仅准确展示了宫崎骏的动漫风格，店铺的牌匾“云存储”，“云计算”，“云模型”，包括酒缸上的“千问”，都随着构图的景深，被真实准确的渲染。并且保留了人物姿势、神态刻画。
让我们再看一个中文渲染的case：
一副典雅庄重的对联悬挂于厅堂之中，房间是个安静古典的中式布置，桌子上放着一些青花瓷，对联上左书“义本生知人机同道善思新”，右书“通云赋智乾坤启数高志远”， 横批“智启通义”，字体飘逸，中间挂在一着一副中国风的画作，内容是岳阳楼。
模型准确了绘制了左右联和横批，并且使用了书法效果，并在中间准确的生成了岳阳楼。桌子上放着的青花瓷也看着非常真实。
那么，模型在英文上的能力如何呢？ 让我们来看一个英文渲染的case：
Bookstore window display. A sign displays “New Arrivals This Week”. Below, a shelf tag with the text “Best-Selling Novels Here”. To the side, a colorful poster advertises “Author Meet And Greet on Saturday” with a central portrait of the author....</p></div><footer class=entry-footer><span title='2025-08-04 22:08:30 +0800 +0800'>2025年8月4日</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;564 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen-Image：擅长文字渲染的创作利器" href=https://qwenlm.github.io/zh/blog/qwen-image/></a></article><article class=post-entry><header class=entry-header><h2>GSPO：迈向持续拓展的语言模型强化学习</h2></header><div class=entry-content><p>PAPER DISCORD
引言 强化学习 （Reinforcement Learning，RL）已成为拓展语言模型、增强其深度推理与问题求解能力的关键技术范式。为了持续拓展 RL，首要前提是确保稳定、鲁棒的训练过程。然而，我们观察到现有的 RL 算法（如 GRPO）在长期训练中会暴露出严重的不稳定性问题并招致不可逆转的模型崩溃，阻碍了通过增加计算以获得进一步的性能提升。
为了能够持续拓展 RL，我们提出了 Group Sequence Policy Optimization (GSPO) 算法。不同于过去的 RL 算法，GSPO 定义了序列级别的重要性比率，并在序列层面执行裁剪、奖励和优化。相较于 GRPO，GSPO 在以下方面展现出突出优势：
强大高效：GSPO 具备显著更高的训练效率，并且能够通过增加计算获得持续的性能提升； 稳定性出色：GSPO 能够保持稳定的训练过程，并且根本地解决了混合专家（Mixture-of-Experts，MoE）模型的 RL 训练稳定性问题； 基础设施友好：由于在序列层面执行优化，GSPO 原则上对精度容忍度更高，具有简化 RL 基础设施的诱人前景。 以上优点促成了最新的 Qwen3 模型（Instruct、Coder、Thinking）的卓越性能。
序列级别的优化目标 设 $x$ 为查询，$\pi_{\theta_\mathrm{old}}$ 为用于采样回复的策略，$\{y_i\}_{i=1}^G$ 为采样得到的回复组，$\widehat{A}_{i}$ 为各个回复的组内相对优势，$\pi_\theta$ 为需优化的当前策略。GSPO 采用以下优化目标：
$$ \mathcal{J}_\text{GSPO} (\theta) = \mathbb{E}_{ x \sim \mathcal{D},\, \{y_i\}_{i=1}^G \sim \pi_{\theta_\text{old}}( \cdot | x) } \left[ \frac{1}{G} \sum_{i=1}^{G} \min \left( s_{i}(\theta) \widehat{A}_{i}, \, \mathrm{clip} \left( s_{i}(\theta), 1 - {\varepsilon}, 1 + {\varepsilon} \right) \widehat{A}_{i} \right) \right], $$ 其中...</p></div><footer class=entry-footer><span title='2025-07-27 15:00:00 +0800 +0800'>2025年7月27日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;298 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to GSPO：迈向持续拓展的语言模型强化学习" href=https://qwenlm.github.io/zh/blog/gspo/></a></article><article class=post-entry><header class=entry-header><h2>Qwen-MT：速度与智能翻译的完美融合</h2></header><div class=entry-content><p>DEMO API DISCORD
简介 我们通过Qwen API 推出了 Qwen-MT（qwen-mt-turbo）的最新升级版本。本次更新基于强大的 Qwen3 模型，进一步使用超大规模多语言和翻译数据对模型进行训练，全面增强其多语言理解与翻译能力，并结合强化学习技术，显著提升了翻译结果的准确性与语言流畅度。
核心亮点包括：
92 种语言互译：支持超过92种主流官方语言及重要方言之间的高质量互译，覆盖全球 95% 以上的人口，满足广泛的语言交流需求。 高度可控性：提供术语干预、领域提示、记忆库等专业翻译功能，并支持用户自定义提示，有效提升模型在复杂、专业或特定应用场景下的翻译表现。 低延迟、低成本：采用轻量级 MoE（Mixture of Experts）架构，在保证卓越性能的同时实现更快的响应速度和更低的 API 调用价格（每百万输出token低至2元），更适合高并发、实时性要求高的应用场景。 自动评估 在中英、英德多领域翻译以及 WMT24 多语言翻译任务中，Qwen-MT 显著优于同规模模型，如 GPT-4.1-mini、Gemini-2.5-Flash 和 Qwen3-8B。甚至与 GPT-4.1、Gemini-2.5-Pro、Qwen3-235B-A22B 等顶级大模型相比，翻译效果依然毫不逊色，凭借轻量化的模型架构设计带来快速的翻译体验。
人工评估 翻译自动评测存在一定的局限性。为更准确地评估翻译质量，我们针对中文、英语、日语、韩语、泰语、阿拉伯语、意大利语、俄语、西班牙语、法语等主要语言，开展了基于真实场景翻译数据的人工评测。每条测试样本均由三名专业译员独立评分并进行交叉校准，确保评估结果的客观性与可靠性。在合格率、优良率上，Qwen-MT 均展现出显著优势，体现出其在实际应用中的卓越翻译能力。
以下是一些翻译样例：
原文 Qwen-MT译文 Make your cubicle neat, tidy and make it a homey charm. 让你的隔间整洁有序，营造出温馨舒适的氛围。 Little study hack for y’all… do your homework/assignments the first day it was given to you… NO PROCRASTINATING!!! the day it was assigned 给大家一个学习小技巧……拿到作业/任务的第一天就完成它……千万别拖延！就在布置的当天完成！ Kim also attended her ex’s first Donda listening party at Atlanta’s Mercedes-Benz Stadium on July 22....</p></div><footer class=entry-footer><span title='2025-07-24 22:00:00 +0800 +0800'>2025年7月24日</span>&nbsp;·&nbsp;4 分钟&nbsp;·&nbsp;650 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen-MT：速度与智能翻译的完美融合" href=https://qwenlm.github.io/zh/blog/qwen-mt/></a></article><article class=post-entry><header class=entry-header><h2>Qwen3-Coder: 在世界中自主编程</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DISCORD
今天我们正式发布 Qwen3-Coder，这是我们迄今为止最具代理能力的代码模型。Qwen3-Coder 拥有多个尺寸，但我们迫不及待地给大家提供当前最强大的版本，Qwen3-Coder-480B-A35B-Instruct。这是一个总参数量 480B，激活 35B 的 MoE 模型，原生支持 256K token 的上下文并可通过 YaRN 扩展到 1M token，拥有卓越的代码和 Agent 能力。Qwen3-Coder-480B-A35B-Instruct 在 Agentic Coding、Agentic Browser-Use 和 Agentic Tool-Use 上取得了开源模型的 SOTA 效果，可以与 Claude Sonnet4 媲美。
与此同时，我们还推出并开源了一款用于代理式编程的命令行工具：Qwen Code。Qwen Code 基于 Gemini Code 进行二次开发，但我们进行了 prompt 和工具调用协议适配，使得 Qwen Code 可以最大程度激发 Qwen3-Coder 在 Agentic Coding 任务上的表现。另外，Qwen3-Coder 可以和社区优秀的编程工具结合，如 Claude Code、Cline 等，作为一款基础模型，我们期待在数字世界的任何角落都可以使用它，Agentic Coding in the World!
Qwen3-Coder Pre-Training 我们在预训练阶段上仍然在努力，这次 Qwen3-Coder 我们从不同角度进行 Scaling，以提升模型的代码能力：
数据扩展：总计 7.5T（代码占比 70%），在保持通用与数学能力的同时，具备卓越的编程能力； 上下文扩展：原生支持 256K 上下文，借助 YaRN 可拓展至 1M，专为仓库级和动态数据（如 Pull Request）优化，助力 Agentic Coding； 合成数据扩展：利用 Qwen2....</p></div><footer class=entry-footer><span title='2025-07-22 21:00:00 +0800 +0800'>2025年7月22日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;424 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen3-Coder: 在世界中自主编程" href=https://qwenlm.github.io/zh/blog/qwen3-coder/></a></article><article class=post-entry><header class=entry-header><h2>Time to Speak Some Dialects, Qwen-TTS!</h2></header><div class=entry-content><p>API 简介 我们通过 Qwen API 更新了 Qwen-TTS ( qwen-tts-latest or qwen-tts-2025-05-22 ) 的最新版本。Qwen-TTS 使用了超过 300 万小时的大规模语料库进行训练，合成效果实现了人类级别的自然度和表现力。比较亮眼的是，Qwen-TTS 会根据输入文本自动调整韵律、节奏和情绪变化。此外，Qwen-TTS 支持生成三种中文方言，包括北京话、上海话和四川话。
目前，Qwen-TTS 支持七种中英双语音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京话）、Jada（上海话） 和 Sunny（四川话），更多语言和风格选项即将在近期推出。
中文方言样例 这里有一些样例展示了 Qwen-TTS 在中文方言上的自然生成能力。
音色
方言种类
文本
合成样例
Dylan
北京话
我们家那边后面有一个后山，就护城河那边，完了呢我们就在山上啊就其实也没什么，就是在土坡上跑来跑去，然后谁捡个那个嗯比较威风的棍，完了我们就呃得瞎打呃，要不就是什么掏个洞啊什么的。
得有自己的想法，别净跟着别人瞎起哄，多动动脑子，有点儿结构化的思维啥的。
Jada
上海话
侬只小赤佬，啊呀，数学句子错它八道题，还想吃肯德基啊！夜到麻将队三缺一啊，嘿嘿，叫阿三头来顶嘛！哦，提前上料这样产品，还要卖 300 块硬币啊。
侬来帮伊向暖吧，天光已经暗转亮哉。
Sunny
四川话
胖娃胖嘟嘟，骑马上成都，成都又好耍。胖娃骑白马，白马跳得高。胖娃耍关刀，关刀耍得圆。胖娃吃汤圆。
他一辈子的使命就是不停地爬哟，爬到大海头上去，不管有好多远！
额外结果 Qwen-TTS 生成的效果目前已经达到了人类水平，其在 SeedTTS-Eval 评测集上的指标如下：
音色
词错误率 WER (↓) 音色相似度 SIM (↑) zh
en
hard
zh
en
hard
Chelsie
1.256
2.004
6.171
0.658
0.473
0.662
Serena
1....</p></div><footer class=entry-footer><span title='2025-06-27 15:01:34 +0800 +0800'>2025年6月27日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;375 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Time to Speak Some Dialects, Qwen-TTS!" href=https://qwenlm.github.io/zh/blog/qwen-tts/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://qwenlm.github.io/zh/blog/page/2/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>