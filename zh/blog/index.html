<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.4f62259998ff7b98600586086c11b90753ca941d3fefd46d058f5df6a9fa05f4.css integrity="sha256-T2IlmZj/e5hgBYYIbBG5B1PKlB0/79RtBY9d9qn6BfQ=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://qwenlm.github.io/zh/blog/index.xml><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/>English</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>GSPO：迈向持续拓展的语言模型强化学习</h2></header><div class=entry-content><p>PAPER DISCORD
引言 强化学习 （Reinforcement Learning，RL）已成为拓展语言模型、增强其深度推理与问题求解能力的关键技术范式。为了持续拓展 RL，首要前提是确保稳定、鲁棒的训练过程。然而，我们观察到现有的 RL 算法（如 GRPO）在长期训练中会暴露出严重的不稳定性问题并招致不可逆转的模型崩溃，阻碍了通过增加计算以获得进一步的性能提升。
为了能够持续拓展 RL，我们提出了 Group Sequence Policy Optimization (GSPO) 算法。不同于过去的 RL 算法，GSPO 定义了序列级别的重要性比率，并在序列层面执行裁剪、奖励和优化。相较于 GRPO，GSPO 在以下方面展现出突出优势：
强大高效：GSPO 具备显著更高的训练效率，并且能够通过增加计算获得持续的性能提升； 稳定性出色：GSPO 能够保持稳定的训练过程，并且根本地解决了混合专家（Mixture-of-Experts，MoE）模型的 RL 训练稳定性问题； 基础设施友好：由于在序列层面执行优化，GSPO 原则上对精度容忍度更高，具有简化 RL 基础设施的诱人前景。 以上优点促成了最新的 Qwen3 模型（Instruct、Coder、Thinking）的卓越性能。
序列级别的优化目标 设 $x$ 为查询，$\pi_{\theta_\mathrm{old}}$ 为用于采样回复的策略，$\{y_i\}_{i=1}^G$ 为采样得到的回复组，$\widehat{A}_{i}$ 为各个回复的组内相对优势，$\pi_\theta$ 为需优化的当前策略。GSPO 采用以下优化目标：
$$f \mathcal{J}_\text{GSPO} (\theta) = \mathbb{E}_{ x \sim \mathcal{D},\, \{y_i\}_{i=1}^G \sim \pi_{\theta_\text{old}}( \cdot | x) } \left[ \frac{1}{G} \sum_{i=1}^{G} \min \left( s_{i}(\theta) \widehat{A}_{i}, \, \mathrm{clip} \left( s_{i}(\theta), 1 - {\varepsilon}, 1 + {\varepsilon} \right) \widehat{A}_{i} \right) \right], $$ 其中...</p></div><footer class=entry-footer><span title='2025-07-27 15:00:00 +0800 +0800'>2025年7月27日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;291 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to GSPO：迈向持续拓展的语言模型强化学习" href=https://qwenlm.github.io/zh/blog/gspo/></a></article><article class=post-entry><header class=entry-header><h2>Qwen-MT：速度与智能翻译的完美融合</h2></header><div class=entry-content><p>DEMO API DISCORD
简介 我们通过Qwen API 推出了 Qwen-MT（qwen-mt-turbo）的最新升级版本。本次更新基于强大的 Qwen3 模型，进一步使用超大规模多语言和翻译数据对模型进行训练，全面增强其多语言理解与翻译能力，并结合强化学习技术，显著提升了翻译结果的准确性与语言流畅度。
核心亮点包括：
92 种语言互译：支持超过92种主流官方语言及重要方言之间的高质量互译，覆盖全球 95% 以上的人口，满足广泛的语言交流需求。 高度可控性：提供术语干预、领域提示、记忆库等专业翻译功能，并支持用户自定义提示，有效提升模型在复杂、专业或特定应用场景下的翻译表现。 低延迟、低成本：采用轻量级 MoE（Mixture of Experts）架构，在保证卓越性能的同时实现更快的响应速度和更低的 API 调用价格（每百万输出token低至2元），更适合高并发、实时性要求高的应用场景。 自动评估 在中英、英德多领域翻译以及 WMT24 多语言翻译任务中，Qwen-MT 显著优于同规模模型，如 GPT-4.1-mini、Gemini-2.5-Flash 和 Qwen3-8B。甚至与 GPT-4.1、Gemini-2.5-Pro、Qwen3-235B-A22B 等顶级大模型相比，翻译效果依然毫不逊色，凭借轻量化的模型架构设计带来快速的翻译体验。
人工评估 翻译自动评测存在一定的局限性。为更准确地评估翻译质量，我们针对中文、英语、日语、韩语、泰语、阿拉伯语、意大利语、俄语、西班牙语、法语等主要语言，开展了基于真实场景翻译数据的人工评测。每条测试样本均由三名专业译员独立评分并进行交叉校准，确保评估结果的客观性与可靠性。在合格率、优良率上，Qwen-MT 均展现出显著优势，体现出其在实际应用中的卓越翻译能力。
以下是一些翻译样例：
原文 Qwen-MT译文 Make your cubicle neat, tidy and make it a homey charm. 让你的隔间整洁有序，营造出温馨舒适的氛围。 Little study hack for y’all… do your homework/assignments the first day it was given to you… NO PROCRASTINATING!!! the day it was assigned 给大家一个学习小技巧……拿到作业/任务的第一天就完成它……千万别拖延！就在布置的当天完成！ Kim also attended her ex’s first Donda listening party at Atlanta’s Mercedes-Benz Stadium on July 22....</p></div><footer class=entry-footer><span title='2025-07-24 22:00:00 +0800 +0800'>2025年7月24日</span>&nbsp;·&nbsp;4 分钟&nbsp;·&nbsp;650 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen-MT：速度与智能翻译的完美融合" href=https://qwenlm.github.io/zh/blog/qwen-mt/></a></article><article class=post-entry><header class=entry-header><h2>Qwen3-Coder: 在世界中自主编程</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DISCORD
今天我们正式发布 Qwen3-Coder，这是我们迄今为止最具代理能力的代码模型。Qwen3-Coder 拥有多个尺寸，但我们迫不及待地给大家提供当前最强大的版本，Qwen3-Coder-480B-A35B-Instruct。这是一个总参数量 480B，激活 35B 的 MoE 模型，原生支持 256K token 的上下文并可通过 YaRN 扩展到 1M token，拥有卓越的代码和 Agent 能力。Qwen3-Coder-480B-A35B-Instruct 在 Agentic Coding、Agentic Browser-Use 和 Agentic Tool-Use 上取得了开源模型的 SOTA 效果，可以与 Claude Sonnet4 媲美。
与此同时，我们还推出并开源了一款用于代理式编程的命令行工具：Qwen Code。Qwen Code 基于 Gemini Code 进行二次开发，但我们进行了 prompt 和工具调用协议适配，使得 Qwen Code 可以最大程度激发 Qwen3-Coder 在 Agentic Coding 任务上的表现。另外，Qwen3-Coder 可以和社区优秀的编程工具结合，如 Claude Code、Cline 等，作为一款基础模型，我们期待在数字世界的任何角落都可以使用它，Agentic Coding in the World!
Qwen3-Coder Pre-Training 我们在预训练阶段上仍然在努力，这次 Qwen3-Coder 我们从不同角度进行 Scaling，以提升模型的代码能力：
数据扩展：总计 7.5T（代码占比 70%），在保持通用与数学能力的同时，具备卓越的编程能力； 上下文扩展：原生支持 256K 上下文，借助 YaRN 可拓展至 1M，专为仓库级和动态数据（如 Pull Request）优化，助力 Agentic Coding； 合成数据扩展：利用 Qwen2....</p></div><footer class=entry-footer><span title='2025-07-22 21:00:00 +0800 +0800'>2025年7月22日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;424 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen3-Coder: 在世界中自主编程" href=https://qwenlm.github.io/zh/blog/qwen3-coder/></a></article><article class=post-entry><header class=entry-header><h2>Time to Speak Some Dialects, Qwen-TTS!</h2></header><div class=entry-content><p>API 简介 我们通过 Qwen API 更新了 Qwen-TTS ( qwen-tts-latest or qwen-tts-2025-05-22 ) 的最新版本。Qwen-TTS 使用了超过 300 万小时的大规模语料库进行训练，合成效果实现了人类级别的自然度和表现力。比较亮眼的是，Qwen-TTS 会根据输入文本自动调整韵律、节奏和情绪变化。此外，Qwen-TTS 支持生成三种中文方言，包括北京话、上海话和四川话。
目前，Qwen-TTS 支持七种中英双语音色，包括 Cherry、Ethan、Chelsie、Serena、Dylan（北京话）、Jada（上海话） 和 Sunny（四川话），更多语言和风格选项即将在近期推出。
中文方言样例 这里有一些样例展示了 Qwen-TTS 在中文方言上的自然生成能力。
音色
方言种类
文本
合成样例
Dylan
北京话
我们家那边后面有一个后山，就护城河那边，完了呢我们就在山上啊就其实也没什么，就是在土坡上跑来跑去，然后谁捡个那个嗯比较威风的棍，完了我们就呃得瞎打呃，要不就是什么掏个洞啊什么的。
得有自己的想法，别净跟着别人瞎起哄，多动动脑子，有点儿结构化的思维啥的。
Jada
上海话
侬只小赤佬，啊呀，数学句子错它八道题，还想吃肯德基啊！夜到麻将队三缺一啊，嘿嘿，叫阿三头来顶嘛！哦，提前上料这样产品，还要卖 300 块硬币啊。
侬来帮伊向暖吧，天光已经暗转亮哉。
Sunny
四川话
胖娃胖嘟嘟，骑马上成都，成都又好耍。胖娃骑白马，白马跳得高。胖娃耍关刀，关刀耍得圆。胖娃吃汤圆。
他一辈子的使命就是不停地爬哟，爬到大海头上去，不管有好多远！
额外结果 Qwen-TTS 生成的效果目前已经达到了人类水平，其在 SeedTTS-Eval 评测集上的指标如下：
音色
词错误率 WER (↓) 音色相似度 SIM (↑) zh
en
hard
zh
en
hard
Chelsie
1.256
2.004
6.171
0.658
0.473
0.662
Serena
1....</p></div><footer class=entry-footer><span title='2025-06-27 15:01:34 +0800 +0800'>2025年6月27日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;375 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Time to Speak Some Dialects, Qwen-TTS!" href=https://qwenlm.github.io/zh/blog/qwen-tts/></a></article><article class=post-entry><header class=entry-header><h2>Qwen VLo: 从“看懂”世界到“描绘”世界</h2></header><div class=entry-content><p>QWEN CHAT DISCORD
介绍 多模态大模型的演进正在不断突破我们对技术边界的认知。从最初的 QwenVL 到如今的 Qwen2.5 VL ，我们在提升模型对图像内容的理解能力方面取得了一些进展。今天，我们正式推出 Qwen VLo ——一个多模态统一理解与生成模型。这一全新升级的模型不仅能够“看懂”世界，更能基于理解进行高质量的再创造，真正实现了从感知到生成的跨越。需要注意的是，这是一款预览版本，您可以通过 Qwen Chat 访问它。您可以直接发送类似“生成一张可爱猫咪的图片”的提示来生成图像，或者上传一张猫咪的图片并要求“给猫咪头上加顶帽子”来修改图像。图像的生成过程如下所示:
生成过程：发挥你想象力，将你的想法变成现实
正如视频中展示的生成过程，Qwen VLo 以一种渐进式生成方式，从左到右、从上到下逐步清晰地构建整幅图片。在生成过程中，模型会对预测的内容不断调整和优化，从而确保最终结果更加和谐一致。这种生成机制不仅提升了视觉效果，还为用户带来了更灵活、更可控的创作体验。
从理解到创造：更精准的多模态生成能力 Qwen VLo在原始多模态理解与生成能力上进行了全面升级，显著增强了对图像内容的理解深度，并在此基础上实现了更加准确和一致的生成效果。以下是 Qwen VLo 的核心亮点：
更精准的内容理解与再创造 以往的多模态模型在生成过程中容易出现语义不一致的问题，例如将汽车误生成其他类型的物体，或者无法保留原图的关键结构特征。而 Qwen VLo 通过更强大的细节捕捉能力，能够在生成过程中保持高度的语义一致性。例如，当用户输入一张汽车的照片并要求“更换颜色”时，Qwen VLo 不仅能准确识别车型，还能保留其原有的结构特征，同时完成色彩风格的自然转换，让生成结果既符合预期又不失真实感。
支持开放指令编辑修改生成 用户可以通过自然语言提出各种创意性指令，如“将这张画风改为梵高风格”、“让这张照片看起来像19世纪的老照片”或“给这张图片添加一个晴朗的天空”。Qwen VLo 能够灵活响应这些开放性指令，并生成符合用户预期的结果。无论是艺术风格迁移、场景重构还是细节修饰，模型都能轻松应对。甚至一些传统的视觉感知人物如预测深度图、分割图、检测图以及边缘信息等也可以通过编辑指令轻松完成。更进一步，像很多更复杂的指令，比如一条指令中同时包含修改物体、修改文字、更换背景，模型也能轻松完成。
多语言指令支持 Qwen VLo 支持包括中文、英文在内的多种语言指令，打破了语言壁垒，为全球用户提供了统一且便捷的交互体验。无论您使用哪种语言，只需简单描述您的需求，模型便能快速理解并输出理想结果。
样例 Qwen VLo 更像一个人类画师, 根据自己的理解再进行创作. 下面是一些具体的例子。
Qwen VLo 能够直接生成图像，并对其进行修改，例如替换背景、添加主体、进行风格迁移，甚至可以完成基于开放指令的大幅修改，包括检测和分割等视觉感知任务。
A cute Shiba Inu
Next
User
生成一个可爱的柴犬
Translation: Generate a cute Shiba Inu
Qwen-VLo
User
背景改成草原
Translation: Change the background to a grassland...</p></div><footer class=entry-footer><span title='2025-06-26 22:00:04 +0800 +0800'>2025年6月26日</span>&nbsp;·&nbsp;11 分钟&nbsp;·&nbsp;2199 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen VLo: 从“看懂”世界到“描绘”世界" href=https://qwenlm.github.io/zh/blog/qwen-vlo/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://qwenlm.github.io/zh/blog/page/2/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>