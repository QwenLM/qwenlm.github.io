<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图 | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE DEMO WeChat
简介 开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。
过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。
模型效果 Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。
以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：
Model MMLU C-Eval GSM8K MATH HumanEval MBPP BBH CMMLU Llama2-34B 62.6 - 42.2 6.2 22.6 33.0 44.1 - Yi-34B 76.3 81.4 67.2 14.4 23.2 41.0 54.3 83.7 Mixtral-8x7B 70.6 - 74.4 28.4 40.2 60.7 - - Qwen1.5-72B 77.5 84.1 79.5 34.1 41.5 53.4 65.5 83.5 Qwen1.5-32B 73.4 83.5 77.4 36.1 37.2 49.4 66.8 82.3 我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/qwen1.5-32b/><link crossorigin=anonymous href=/assets/css/stylesheet.012512d6f1d6f320d85cff7ae2b89d136cc19960a4aa00adf35aaae57e557162.css integrity="sha256-ASUS1vHW8yDYXP964ridE2zBmWCkqgCt81qq5X5VcWI=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen1.5-32b/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen1.5-32b/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE DEMO WeChat
简介 开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。
过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。
模型效果 Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。
以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：
Model MMLU C-Eval GSM8K MATH HumanEval MBPP BBH CMMLU Llama2-34B 62.6 - 42.2 6.2 22.6 33.0 44.1 - Yi-34B 76.3 81.4 67.2 14.4 23.2 41.0 54.3 83.7 Mixtral-8x7B 70.6 - 74.4 28.4 40.2 60.7 - - Qwen1.5-72B 77.5 84.1 79.5 34.1 41.5 53.4 65.5 83.5 Qwen1.5-32B 73.4 83.5 77.4 36.1 37.2 49.4 66.8 82.3 我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。"><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/qwen1.5-32b/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-04-02T13:33:00+08:00"><meta property="article:modified_time" content="2024-04-02T13:33:00+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE DEMO WeChat
简介 开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。
过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。
模型效果 Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。
以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：
Model MMLU C-Eval GSM8K MATH HumanEval MBPP BBH CMMLU Llama2-34B 62.6 - 42.2 6.2 22.6 33.0 44.1 - Yi-34B 76.3 81.4 67.2 14.4 23.2 41.0 54.3 83.7 Mixtral-8x7B 70.6 - 74.4 28.4 40.2 60.7 - - Qwen1.5-72B 77.5 84.1 79.5 34.1 41.5 53.4 65.5 83.5 Qwen1.5-32B 73.4 83.5 77.4 36.1 37.2 49.4 66.8 82.3 我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图","item":"https://qwenlm.github.io/zh/blog/qwen1.5-32b/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图","name":"Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图","description":"GITHUB HUGGING FACE MODELSCOPE DEMO WeChat\n简介 开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。\n过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。\n模型效果 Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。\n以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：\nModel MMLU C-Eval GSM8K MATH HumanEval MBPP BBH CMMLU Llama2-34B 62.6 - 42.2 6.2 22.6 33.0 44.1 - Yi-34B 76.3 81.4 67.2 14.4 23.2 41.0 54.3 83.7 Mixtral-8x7B 70.6 - 74.4 28.4 40.2 60.7 - - Qwen1.5-72B 77.5 84.1 79.5 34.1 41.5 53.4 65.5 83.5 Qwen1.5-32B 73.4 83.5 77.4 36.1 37.2 49.4 66.8 82.3 我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。","keywords":[],"articleBody":"GITHUB HUGGING FACE MODELSCOPE DEMO WeChat\n简介 开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。\n过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。\n模型效果 Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。\n以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：\nModel MMLU C-Eval GSM8K MATH HumanEval MBPP BBH CMMLU Llama2-34B 62.6 - 42.2 6.2 22.6 33.0 44.1 - Yi-34B 76.3 81.4 67.2 14.4 23.2 41.0 54.3 83.7 Mixtral-8x7B 70.6 - 74.4 28.4 40.2 60.7 - - Qwen1.5-72B 77.5 84.1 79.5 34.1 41.5 53.4 65.5 83.5 Qwen1.5-32B 73.4 83.5 77.4 36.1 37.2 49.4 66.8 82.3 我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。\n而在Chat模型的评估上，我们遵循Qwen1.5的评估方案，对它们在MT-Bench与Alpaca-Eval 2.0上的表现进行了测试。具体结果如下：\nModels MT-Bench AlpacaEval 2.0 Avg. ScoreLC Win Rate Qwen1.5-72B-Chat 8.61 36.60 Qwen1.5-32B-Chat 8.30 27.49 值得注意的是，Qwen1.5-32B-Chat的得分超过8分，且Qwen1.5-32B-Chat与Qwen1.5-72B-Chat之间的差距相对较小。这一结果表明，对于需要更高效、更经济实惠的应用解决方案的用户而言，32B模型是一个可行的选择。\n我们还对Qwen1.5-32B的多语言能力进行了测试，涵盖了包括阿拉伯语、西班牙语、法语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语和印尼语在内的12种语言，涉及考试、理解、数学及翻译等多个领域。具体结果如下所示：\nModels Exams Understanding Math Translation Average Mixtral-8x7B 56.08 70.70 45.00 29.78 50.39 Qwen1.5-72B 66.35 78.16 61.67 35.57 60.44 Qwen1.5-32B 61.57 76.48 56.13 33.46 56.91 与其他Qwen1.5模型相似，32B版本同样具备出色的多语言能力，其表现略逊于72B模型。\n最后，我们关注其在长文本评估任务“大海捞针”中的表现，令人欣喜的是，该模型能够在长达32K tokens的上下文中实现了优秀的表现。\n使用Qwen1.5-32B 我们建议您阅读Qwen1.5的博客了解更多关于在transformers、llama.cpp、vLLM、Ollama等框架上使用的方法。\n结语 我们发布了中等规模模型Qwen1.5-32B及其Chat模型。相较于72B模型，这些模型的内存占用大幅减少，运行速度显著提升。我们期望此次发布能帮助用户为其下游应用找到更优解决方案，以应对14B模型尤其在智能体场景下能力偏弱以及72B模型推理成本过高的问题。\n引用 @misc{qwen1.5, title = {Introducing Qwen1.5}, url = {https://qwenlm.github.io/blog/qwen1.5/}, author = {Qwen Team}, month = {February}, year = {2024} } ","wordCount":"139","inLanguage":"zh","datePublished":"2024-04-02T13:33:00+08:00","dateModified":"2024-04-02T13:33:00+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/zh/blog/qwen1.5-32b/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图</h1><div class=post-meta><span title='2024-04-02 13:33:00 +0800 +0800'>2024年4月2日</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;139 字&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/qwen1.5-32b/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://github.com/QwenLM/Qwen1.5 class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/Qwen class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat class="btn external" target=_blank>DEMO</a>
<a href=https://github.com/QwenLM/Qwen/blob/main/assets/wechat.png class="btn external" target=_blank>WeChat</a></p><h1 id=简介>简介<a hidden class=anchor aria-hidden=true href=#简介>#</a></h1><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/qwen1.5-32b/32b.png#center width=100%></figure><p>开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。</p><p>过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。</p><h1 id=模型效果>模型效果<a hidden class=anchor aria-hidden=true href=#模型效果>#</a></h1><p>Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。</p><p>以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：</p><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:center>MMLU</th><th style=text-align:center>C-Eval</th><th style=text-align:center>GSM8K</th><th style=text-align:center>MATH</th><th style=text-align:center>HumanEval</th><th style=text-align:center>MBPP</th><th style=text-align:center>BBH</th><th style=text-align:center>CMMLU</th></tr></thead><tbody><tr><td style=text-align:left>Llama2-34B</td><td style=text-align:center>62.6</td><td style=text-align:center>-</td><td style=text-align:center>42.2</td><td style=text-align:center>6.2</td><td style=text-align:center>22.6</td><td style=text-align:center>33.0</td><td style=text-align:center>44.1</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Yi-34B</td><td style=text-align:center>76.3</td><td style=text-align:center>81.4</td><td style=text-align:center>67.2</td><td style=text-align:center>14.4</td><td style=text-align:center>23.2</td><td style=text-align:center>41.0</td><td style=text-align:center>54.3</td><td style=text-align:center>83.7</td></tr><tr><td style=text-align:left>Mixtral-8x7B</td><td style=text-align:center>70.6</td><td style=text-align:center>-</td><td style=text-align:center>74.4</td><td style=text-align:center>28.4</td><td style=text-align:center>40.2</td><td style=text-align:center>60.7</td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>Qwen1.5-72B</td><td style=text-align:center>77.5</td><td style=text-align:center>84.1</td><td style=text-align:center>79.5</td><td style=text-align:center>34.1</td><td style=text-align:center>41.5</td><td style=text-align:center>53.4</td><td style=text-align:center>65.5</td><td style=text-align:center>83.5</td></tr><tr><td style=text-align:left>Qwen1.5-32B</td><td style=text-align:center>73.4</td><td style=text-align:center>83.5</td><td style=text-align:center>77.4</td><td style=text-align:center>36.1</td><td style=text-align:center>37.2</td><td style=text-align:center>49.4</td><td style=text-align:center>66.8</td><td style=text-align:center>82.3</td></tr></tbody></table><p>我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。</p><p>而在Chat模型的评估上，我们遵循Qwen1.5的评估方案，对它们在MT-Bench与Alpaca-Eval 2.0上的表现进行了测试。具体结果如下：</p><table><tr><th rowspan=2 align=center>Models</th><th colspan=1 align=center>MT-Bench</th><th colspan=1 align=center>AlpacaEval 2.0</th></tr><tr><th align=center>Avg. Score</th><th align=center>LC Win Rate</th></tr><tr><td>Qwen1.5-72B-Chat</td><td align=center>8.61</td><td align=center>36.60</td></tr><tr><td>Qwen1.5-32B-Chat</td><td align=center>8.30</td><td align=center>27.49</td></tr></table><p>值得注意的是，Qwen1.5-32B-Chat的得分超过8分，且Qwen1.5-32B-Chat与Qwen1.5-72B-Chat之间的差距相对较小。这一结果表明，对于需要更高效、更经济实惠的应用解决方案的用户而言，32B模型是一个可行的选择。</p><p>我们还对Qwen1.5-32B的多语言能力进行了测试，涵盖了包括阿拉伯语、西班牙语、法语、葡萄牙语、德语、意大利语、俄语、日语、韩语、越南语、泰语和印尼语在内的12种语言，涉及考试、理解、数学及翻译等多个领域。具体结果如下所示：</p><table><thead><tr><th style=text-align:left>Models</th><th style=text-align:center>Exams</th><th style=text-align:center>Understanding</th><th style=text-align:center>Math</th><th style=text-align:center>Translation</th><th style=text-align:center>Average</th></tr></thead><tbody><tr><td style=text-align:left>Mixtral-8x7B</td><td style=text-align:center>56.08</td><td style=text-align:center>70.70</td><td style=text-align:center>45.00</td><td style=text-align:center>29.78</td><td style=text-align:center>50.39</td></tr><tr><td style=text-align:left>Qwen1.5-72B</td><td style=text-align:center>66.35</td><td style=text-align:center>78.16</td><td style=text-align:center>61.67</td><td style=text-align:center>35.57</td><td style=text-align:center>60.44</td></tr><tr><td style=text-align:left>Qwen1.5-32B</td><td style=text-align:center>61.57</td><td style=text-align:center>76.48</td><td style=text-align:center>56.13</td><td style=text-align:center>33.46</td><td style=text-align:center>56.91</td></tr></tbody></table><p>与其他Qwen1.5模型相似，32B版本同样具备出色的多语言能力，其表现略逊于72B模型。</p><p>最后，我们关注其在长文本评估任务“大海捞针”中的表现，令人欣喜的是，该模型能够在长达32K tokens的上下文中实现了优秀的表现。</p><figure><img src=https://qianwen-res.oss-accelerate.aliyuncs.com/assets/blog/qwen1.5-32b/needle-qwen1.5-32b-chat.jpg#center width=100%></figure><h1 id=使用qwen15-32b>使用Qwen1.5-32B<a hidden class=anchor aria-hidden=true href=#使用qwen15-32b>#</a></h1><p>我们建议您阅读Qwen1.5的<a href=https://qwenlm.github.io/blog/qwen1.5/>博客</a>了解更多关于在transformers、llama.cpp、vLLM、Ollama等框架上使用的方法。</p><h1 id=结语>结语<a hidden class=anchor aria-hidden=true href=#结语>#</a></h1><p>我们发布了中等规模模型Qwen1.5-32B及其Chat模型。相较于72B模型，这些模型的内存占用大幅减少，运行速度显著提升。我们期望此次发布能帮助用户为其下游应用找到更优解决方案，以应对14B模型尤其在智能体场景下能力偏弱以及72B模型推理成本过高的问题。</p><h1 id=引用>引用<a hidden class=anchor aria-hidden=true href=#引用>#</a></h1><pre tabindex=0><code>@misc{qwen1.5,
    title = {Introducing Qwen1.5},
    url = {https://qwenlm.github.io/blog/qwen1.5/},
    author = {Qwen Team},
    month = {February},
    year = {2024}
}
</code></pre></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>