<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen2.5-Coder: 码无止境，学无止境! | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
简介 四月初，我们发布了 CodeQwen1.5, 得到了社区广泛的关注与喜爱。自那以后，我们一直在继续努力提升代码模型。今天，我们很高兴地宣布新一代的开放代码模型 Qwen2.5-Coder 的发布。并正式将 CodeQwen 的命名改为 Qwen-Coder，我们认为 Coder 更加拟人、灵动，期待其可以在未来真正与人类结对编程。Qwen2.5-Coder 是我们 Qwen2.5 开源家族的一员，共包括三个尺寸的模型：1.5B、 7B 和 32B（在路上）。
本次更新的两大核心包括代码训练数据的进一步 scaling，以及探索在提升代码能力的同时保持数学和通用能力。
码无止境：Qwen2.5-Coder 基于强大的 Qwen2.5 初始化，扩增了更大规模的代码训练数据持续训练，包括源代码、文本代码混合数据、合成数据等共计 5.5T tokens。使得 Qwen2.5-Coder 在代码生成、代码推理、代码修复等任务上都有了显著提升。 学无止境：我们希望 Qwen2.5-Coder 在提升代码能力的同时，也能保持在数学、通用能力等方面的优势。因此，我们在 Qwen2.5-Coder 中加入了更多的数学、通用能力数据，为未来的真实应用提供更为全面的基座。 Qwen2.5-Coder: Base Models Qwen2.5-Coder 最多 128K tokens 上下文，支持 92 种编程语言，并在多个代码相关的评估任务中都取得了显著的提升，包括代码生成、多编程语言代码生成、代码补全、代码修复等。值得注意的是，本次开源的 7B 版本 Qwen2.5-Coder，甚至打败了更大尺寸的 DeepSeek-Coder-V2-Lite 和 CodeStral-22B，成为当前最强大的基础代码模型之一。除了代码任务外，Qwen2.5-Coder 也具备极具竞争力的数学能力。面向通用任务，我们评估了 MMLU 和 ARC，结果表明 Qwen2.5-Coder 很好的保持了 Qwen2.5 的通用能力。
Qwen2.5-Coder-Instruct: Instruction-Tuned Models 我们在 Qwen2.5-Coder 的基础上，通过指令微调，得到了 Qwen2.5-Coder-Instruct。Qwen2.5-Coder-Instruct 除了进一步提升了多个任务上的性能外，还在更多的评估中体现出了卓越的泛化性。"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/qwen2.5-coder/><link crossorigin=anonymous href=/assets/css/stylesheet.012512d6f1d6f320d85cff7ae2b89d136cc19960a4aa00adf35aaae57e557162.css integrity="sha256-ASUS1vHW8yDYXP964ridE2zBmWCkqgCt81qq5X5VcWI=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen2.5-coder/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen2.5-coder/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen2.5-Coder: 码无止境，学无止境!"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
简介 四月初，我们发布了 CodeQwen1.5, 得到了社区广泛的关注与喜爱。自那以后，我们一直在继续努力提升代码模型。今天，我们很高兴地宣布新一代的开放代码模型 Qwen2.5-Coder 的发布。并正式将 CodeQwen 的命名改为 Qwen-Coder，我们认为 Coder 更加拟人、灵动，期待其可以在未来真正与人类结对编程。Qwen2.5-Coder 是我们 Qwen2.5 开源家族的一员，共包括三个尺寸的模型：1.5B、 7B 和 32B（在路上）。
本次更新的两大核心包括代码训练数据的进一步 scaling，以及探索在提升代码能力的同时保持数学和通用能力。
码无止境：Qwen2.5-Coder 基于强大的 Qwen2.5 初始化，扩增了更大规模的代码训练数据持续训练，包括源代码、文本代码混合数据、合成数据等共计 5.5T tokens。使得 Qwen2.5-Coder 在代码生成、代码推理、代码修复等任务上都有了显著提升。 学无止境：我们希望 Qwen2.5-Coder 在提升代码能力的同时，也能保持在数学、通用能力等方面的优势。因此，我们在 Qwen2.5-Coder 中加入了更多的数学、通用能力数据，为未来的真实应用提供更为全面的基座。 Qwen2.5-Coder: Base Models Qwen2.5-Coder 最多 128K tokens 上下文，支持 92 种编程语言，并在多个代码相关的评估任务中都取得了显著的提升，包括代码生成、多编程语言代码生成、代码补全、代码修复等。值得注意的是，本次开源的 7B 版本 Qwen2.5-Coder，甚至打败了更大尺寸的 DeepSeek-Coder-V2-Lite 和 CodeStral-22B，成为当前最强大的基础代码模型之一。除了代码任务外，Qwen2.5-Coder 也具备极具竞争力的数学能力。面向通用任务，我们评估了 MMLU 和 ARC，结果表明 Qwen2.5-Coder 很好的保持了 Qwen2.5 的通用能力。
Qwen2.5-Coder-Instruct: Instruction-Tuned Models 我们在 Qwen2.5-Coder 的基础上，通过指令微调，得到了 Qwen2.5-Coder-Instruct。Qwen2.5-Coder-Instruct 除了进一步提升了多个任务上的性能外，还在更多的评估中体现出了卓越的泛化性。"><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/qwen2.5-coder/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-09-19T00:00:02+08:00"><meta property="article:modified_time" content="2024-09-19T00:00:02+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen2.5-Coder: 码无止境，学无止境!"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
简介 四月初，我们发布了 CodeQwen1.5, 得到了社区广泛的关注与喜爱。自那以后，我们一直在继续努力提升代码模型。今天，我们很高兴地宣布新一代的开放代码模型 Qwen2.5-Coder 的发布。并正式将 CodeQwen 的命名改为 Qwen-Coder，我们认为 Coder 更加拟人、灵动，期待其可以在未来真正与人类结对编程。Qwen2.5-Coder 是我们 Qwen2.5 开源家族的一员，共包括三个尺寸的模型：1.5B、 7B 和 32B（在路上）。
本次更新的两大核心包括代码训练数据的进一步 scaling，以及探索在提升代码能力的同时保持数学和通用能力。
码无止境：Qwen2.5-Coder 基于强大的 Qwen2.5 初始化，扩增了更大规模的代码训练数据持续训练，包括源代码、文本代码混合数据、合成数据等共计 5.5T tokens。使得 Qwen2.5-Coder 在代码生成、代码推理、代码修复等任务上都有了显著提升。 学无止境：我们希望 Qwen2.5-Coder 在提升代码能力的同时，也能保持在数学、通用能力等方面的优势。因此，我们在 Qwen2.5-Coder 中加入了更多的数学、通用能力数据，为未来的真实应用提供更为全面的基座。 Qwen2.5-Coder: Base Models Qwen2.5-Coder 最多 128K tokens 上下文，支持 92 种编程语言，并在多个代码相关的评估任务中都取得了显著的提升，包括代码生成、多编程语言代码生成、代码补全、代码修复等。值得注意的是，本次开源的 7B 版本 Qwen2.5-Coder，甚至打败了更大尺寸的 DeepSeek-Coder-V2-Lite 和 CodeStral-22B，成为当前最强大的基础代码模型之一。除了代码任务外，Qwen2.5-Coder 也具备极具竞争力的数学能力。面向通用任务，我们评估了 MMLU 和 ARC，结果表明 Qwen2.5-Coder 很好的保持了 Qwen2.5 的通用能力。
Qwen2.5-Coder-Instruct: Instruction-Tuned Models 我们在 Qwen2.5-Coder 的基础上，通过指令微调，得到了 Qwen2.5-Coder-Instruct。Qwen2.5-Coder-Instruct 除了进一步提升了多个任务上的性能外，还在更多的评估中体现出了卓越的泛化性。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Qwen2.5-Coder: 码无止境，学无止境!","item":"https://qwenlm.github.io/zh/blog/qwen2.5-coder/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen2.5-Coder: 码无止境，学无止境!","name":"Qwen2.5-Coder: 码无止境，学无止境!","description":"GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\n简介 四月初，我们发布了 CodeQwen1.5, 得到了社区广泛的关注与喜爱。自那以后，我们一直在继续努力提升代码模型。今天，我们很高兴地宣布新一代的开放代码模型 Qwen2.5-Coder 的发布。并正式将 CodeQwen 的命名改为 Qwen-Coder，我们认为 Coder 更加拟人、灵动，期待其可以在未来真正与人类结对编程。Qwen2.5-Coder 是我们 Qwen2.5 开源家族的一员，共包括三个尺寸的模型：1.5B、 7B 和 32B（在路上）。\n本次更新的两大核心包括代码训练数据的进一步 scaling，以及探索在提升代码能力的同时保持数学和通用能力。\n码无止境：Qwen2.5-Coder 基于强大的 Qwen2.5 初始化，扩增了更大规模的代码训练数据持续训练，包括源代码、文本代码混合数据、合成数据等共计 5.5T tokens。使得 Qwen2.5-Coder 在代码生成、代码推理、代码修复等任务上都有了显著提升。 学无止境：我们希望 Qwen2.5-Coder 在提升代码能力的同时，也能保持在数学、通用能力等方面的优势。因此，我们在 Qwen2.5-Coder 中加入了更多的数学、通用能力数据，为未来的真实应用提供更为全面的基座。 Qwen2.5-Coder: Base Models Qwen2.5-Coder 最多 128K tokens 上下文，支持 92 种编程语言，并在多个代码相关的评估任务中都取得了显著的提升，包括代码生成、多编程语言代码生成、代码补全、代码修复等。值得注意的是，本次开源的 7B 版本 Qwen2.5-Coder，甚至打败了更大尺寸的 DeepSeek-Coder-V2-Lite 和 CodeStral-22B，成为当前最强大的基础代码模型之一。除了代码任务外，Qwen2.5-Coder 也具备极具竞争力的数学能力。面向通用任务，我们评估了 MMLU 和 ARC，结果表明 Qwen2.5-Coder 很好的保持了 Qwen2.5 的通用能力。\nQwen2.5-Coder-Instruct: Instruction-Tuned Models 我们在 Qwen2.5-Coder 的基础上，通过指令微调，得到了 Qwen2.5-Coder-Instruct。Qwen2.5-Coder-Instruct 除了进一步提升了多个任务上的性能外，还在更多的评估中体现出了卓越的泛化性。","keywords":[],"articleBody":" GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\n简介 四月初，我们发布了 CodeQwen1.5, 得到了社区广泛的关注与喜爱。自那以后，我们一直在继续努力提升代码模型。今天，我们很高兴地宣布新一代的开放代码模型 Qwen2.5-Coder 的发布。并正式将 CodeQwen 的命名改为 Qwen-Coder，我们认为 Coder 更加拟人、灵动，期待其可以在未来真正与人类结对编程。Qwen2.5-Coder 是我们 Qwen2.5 开源家族的一员，共包括三个尺寸的模型：1.5B、 7B 和 32B（在路上）。\n本次更新的两大核心包括代码训练数据的进一步 scaling，以及探索在提升代码能力的同时保持数学和通用能力。\n码无止境：Qwen2.5-Coder 基于强大的 Qwen2.5 初始化，扩增了更大规模的代码训练数据持续训练，包括源代码、文本代码混合数据、合成数据等共计 5.5T tokens。使得 Qwen2.5-Coder 在代码生成、代码推理、代码修复等任务上都有了显著提升。 学无止境：我们希望 Qwen2.5-Coder 在提升代码能力的同时，也能保持在数学、通用能力等方面的优势。因此，我们在 Qwen2.5-Coder 中加入了更多的数学、通用能力数据，为未来的真实应用提供更为全面的基座。 Qwen2.5-Coder: Base Models Qwen2.5-Coder 最多 128K tokens 上下文，支持 92 种编程语言，并在多个代码相关的评估任务中都取得了显著的提升，包括代码生成、多编程语言代码生成、代码补全、代码修复等。值得注意的是，本次开源的 7B 版本 Qwen2.5-Coder，甚至打败了更大尺寸的 DeepSeek-Coder-V2-Lite 和 CodeStral-22B，成为当前最强大的基础代码模型之一。除了代码任务外，Qwen2.5-Coder 也具备极具竞争力的数学能力。面向通用任务，我们评估了 MMLU 和 ARC，结果表明 Qwen2.5-Coder 很好的保持了 Qwen2.5 的通用能力。\nQwen2.5-Coder-Instruct: Instruction-Tuned Models 我们在 Qwen2.5-Coder 的基础上，通过指令微调，得到了 Qwen2.5-Coder-Instruct。Qwen2.5-Coder-Instruct 除了进一步提升了多个任务上的性能外，还在更多的评估中体现出了卓越的泛化性。\n特别的，Qwen2.5-Coder-Instruct 在几个方面表现非常突出：\n卓越的多编程语言能力：为了更广泛的评估多编程语言能力，我们使用 McEval 在 Qwen2.5-Coder-Instruct 上进行了更多的测试，共设计 40 多种编程语言。结果表明 Qwen2.5-Coder-Instruct 在多种编程语言任务上表现非常出色，包括一些小众语言。 代码推理：我们认为代码推理能力和通用推理能力是密切相关的，我们选择 CRUXEval 作为评估基准，结果表明 Qwen2.5-Coder-Instruct 在代码推理任务上表现非常出色。更有趣的是，我们发现随着代码推理能力的提升，模型的复杂指令遵循也得到了增强，这鼓舞我们继续探索代码对于通用能力的增益。 数学能力：数学和代码经常被一起讨论，数学是代码的基础学科，代码是数学的重要工具。我们发现 Qwen2.5-Coder-Instruct 在代码和数学任务上都表现出色，是一个名副其实的理科生。 Model Math GSM8K GaoKao2023en OlympiadBench CollegeMath AIME24 DeepSeek-Coder-V2-Lite-Instruct 61 87.6 56.1 26.4 39.8 6.7 Qwen2.5-Coder-7B-Instruct 66.8 86.7 60.5 29.8 43.5 10 基础能力：我们还在通用能力上进行了评估，结果表明 Qwen2.5-Coder-Instruct 在通用能力上也保持了 Qwen2.5 的优势。 Model AMC23 MMLU-Pro MMLU IFEval CEval GPQA DeepSeek-Coder-V2-Lite-Instruct 40.4 42.5 60.6 38.6 60.1 27.6 Qwen2.5-Coder-7B-Instruct 42.5 45.6 68.7 58.6 61.4 35.6 模型许可 Qwen2.5-Coder 采用Apache 2.0的许可。我们希望本次开放程度的提升能够加速 Qwen2.5-Coder 在代码智能方面的应用。\nWhat’s Next for Qwen2.5-Coder? 我们正在筹备 32B 版本的 Qwen2.5-Coder，期待可以直接向闭源模型发起挑战，很快就会和大家见面，敬请期待！ 除此之外，我们还在积极探索以代码为中心的强大推理模型，探索代码智能的边界。\nCitation @article{hui2024qwen2, title={Qwen2. 5-Coder Technical Report}, author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others}, journal={arXiv preprint arXiv:2409.12186}, year={2024} } @article{yang2024qwen2, title={Qwen2 technical report}, author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others}, journal={arXiv preprint arXiv:2407.10671}, year={2024} } ","wordCount":"233","inLanguage":"zh","datePublished":"2024-09-19T00:00:02+08:00","dateModified":"2024-09-19T00:00:02+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/zh/blog/qwen2.5-coder/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen2.5-Coder: 码无止境，学无止境!</h1><div class=post-meta><span title='2024-09-19 00:00:02 +0800 +0800'>2024年9月19日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;233 字&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/qwen2.5-coder/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/coder-main.png#center width=70%></figure><p><a href=https://github.com/QwenLM/Qwen2.5-Coder class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/Qwen class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://huggingface.co/spaces/Qwen/Qwen2.5-Coder-7B-Instruct class="btn external" target=_blank>DEMO</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><h1 id=简介>简介<a hidden class=anchor aria-hidden=true href=#简介>#</a></h1><p>四月初，我们发布了 CodeQwen1.5, 得到了社区广泛的关注与喜爱。自那以后，我们一直在继续努力提升代码模型。今天，我们很高兴地宣布新一代的开放代码模型 Qwen2.5-Coder 的发布。并正式将 CodeQwen 的命名改为 Qwen-Coder，我们认为 Coder 更加拟人、灵动，期待其可以在未来真正与人类结对编程。Qwen2.5-Coder 是我们 Qwen2.5 开源家族的一员，共包括三个尺寸的模型：1.5B、 7B 和 32B（在路上）。</p><p>本次更新的两大核心包括代码训练数据的进一步 scaling，以及探索在提升代码能力的同时保持数学和通用能力。</p><ol><li>码无止境：Qwen2.5-Coder 基于强大的 Qwen2.5 初始化，扩增了更大规模的代码训练数据持续训练，包括源代码、文本代码混合数据、合成数据等共计 5.5T tokens。使得 Qwen2.5-Coder 在代码生成、代码推理、代码修复等任务上都有了显著提升。</li><li>学无止境：我们希望 Qwen2.5-Coder 在提升代码能力的同时，也能保持在数学、通用能力等方面的优势。因此，我们在 Qwen2.5-Coder 中加入了更多的数学、通用能力数据，为未来的真实应用提供更为全面的基座。</li></ol><h1 id=qwen25-coder-base-models>Qwen2.5-Coder: Base Models<a hidden class=anchor aria-hidden=true href=#qwen25-coder-base-models>#</a></h1><p>Qwen2.5-Coder 最多 <strong>128K</strong> tokens 上下文，支持 92 种编程语言，并在多个代码相关的评估任务中都取得了显著的提升，包括代码生成、多编程语言代码生成、代码补全、代码修复等。值得注意的是，本次开源的 7B 版本 Qwen2.5-Coder，甚至打败了更大尺寸的 DeepSeek-Coder-V2-Lite 和 CodeStral-22B，成为当前最强大的基础代码模型之一。除了代码任务外，Qwen2.5-Coder 也具备极具竞争力的数学能力。面向通用任务，我们评估了 MMLU 和 ARC，结果表明 Qwen2.5-Coder 很好的保持了 Qwen2.5 的通用能力。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/qwen2.5-coder-base.jpg#center width=100%></figure><h1 id=qwen25-coder-instruct-instruction-tuned-models>Qwen2.5-Coder-Instruct: Instruction-Tuned Models<a hidden class=anchor aria-hidden=true href=#qwen25-coder-instruct-instruction-tuned-models>#</a></h1><p>我们在 Qwen2.5-Coder 的基础上，通过指令微调，得到了 Qwen2.5-Coder-Instruct。Qwen2.5-Coder-Instruct 除了进一步提升了多个任务上的性能外，还在更多的评估中体现出了卓越的泛化性。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/qwen2.5-coder-instruct.jpg#center width=100%></figure><p>特别的，Qwen2.5-Coder-Instruct 在几个方面表现非常突出：</p><ol><li>卓越的多编程语言能力：为了更广泛的评估多编程语言能力，我们使用 McEval 在 Qwen2.5-Coder-Instruct 上进行了更多的测试，共设计 40 多种编程语言。结果表明 Qwen2.5-Coder-Instruct 在多种编程语言任务上表现非常出色，包括一些小众语言。</li></ol><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/mveval.jpg#center width=70%></figure><ol start=2><li>代码推理：我们认为代码推理能力和通用推理能力是密切相关的，我们选择 CRUXEval 作为评估基准，结果表明 Qwen2.5-Coder-Instruct 在代码推理任务上表现非常出色。更有趣的是，我们发现随着代码推理能力的提升，模型的复杂指令遵循也得到了增强，这鼓舞我们继续探索代码对于通用能力的增益。</li></ol><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/crux.jpg#center width=70%></figure><ol start=3><li>数学能力：数学和代码经常被一起讨论，数学是代码的基础学科，代码是数学的重要工具。我们发现 Qwen2.5-Coder-Instruct 在代码和数学任务上都表现出色，是一个名副其实的理科生。</li></ol><table><thead><tr><th><strong>Model</strong></th><th><strong>Math</strong></th><th><strong>GSM8K</strong></th><th><strong>GaoKao2023en</strong></th><th><strong>OlympiadBench</strong></th><th><strong>CollegeMath</strong></th><th><strong>AIME24</strong></th></tr></thead><tbody><tr><td>DeepSeek-Coder-V2-Lite-Instruct</td><td>61</td><td><strong>87.6</strong></td><td>56.1</td><td>26.4</td><td>39.8</td><td>6.7</td></tr><tr><td>Qwen2.5-Coder-7B-Instruct</td><td><strong>66.8</strong></td><td>86.7</td><td><strong>60.5</strong></td><td><strong>29.8</strong></td><td><strong>43.5</strong></td><td><strong>10</strong></td></tr></tbody></table><ol start=4><li>基础能力：我们还在通用能力上进行了评估，结果表明 Qwen2.5-Coder-Instruct 在通用能力上也保持了 Qwen2.5 的优势。</li></ol><table><thead><tr><th><strong>Model</strong></th><th><strong>AMC23</strong></th><th><strong>MMLU-Pro</strong></th><th><strong>MMLU</strong></th><th><strong>IFEval</strong></th><th><strong>CEval</strong></th><th><strong>GPQA</strong></th></tr></thead><tbody><tr><td>DeepSeek-Coder-V2-Lite-Instruct</td><td>40.4</td><td>42.5</td><td>60.6</td><td>38.6</td><td>60.1</td><td>27.6</td></tr><tr><td>Qwen2.5-Coder-7B-Instruct</td><td><strong>42.5</strong></td><td><strong>45.6</strong></td><td><strong>68.7</strong></td><td><strong>58.6</strong></td><td><strong>61.4</strong></td><td><strong>35.6</strong></td></tr></tbody></table><h1 id=模型许可>模型许可<a hidden class=anchor aria-hidden=true href=#模型许可>#</a></h1><p>Qwen2.5-Coder 采用<strong>Apache 2.0</strong>的许可。我们希望本次开放程度的提升能够加速 Qwen2.5-Coder 在代码智能方面的应用。</p><h1 id=whats-next-for-qwen25-coder>What&rsquo;s Next for Qwen2.5-Coder?<a hidden class=anchor aria-hidden=true href=#whats-next-for-qwen25-coder>#</a></h1><p>我们正在筹备 32B 版本的 Qwen2.5-Coder，期待可以直接向闭源模型发起挑战，很快就会和大家见面，敬请期待！
除此之外，我们还在积极探索以代码为中心的强大推理模型，探索代码智能的边界。</p><h1 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h1><pre tabindex=0><code>@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}
@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
</code></pre></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>