<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen2.5-Coder 全系列: 强大、多样、实用。 | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE KAGGLE DEMO DISCORD
简介 今天，我们很高兴开源「强大」、「多样」、「实用」的 Qwen2.5-Coder 全系列模型，致力于持续推动 Open CodeLLMs 的发展。
强大：Qwen2.5-Coder-32B-Instruct 成为目前 SOTA 的开源代码模型，代码能力追平 GPT-4o，展现出强大且全面的代码能力，同时具备良好的通用和数学能力。 多样：上个月我们开源了 1.5B、7B 两个尺寸，本次开源又带来 0.5B、3B、14B、32B 四个尺寸，截至目前， Qwen2.5-Coder 已经覆盖了主流的六个模型尺寸，以满足不同开发者的需要。 实用：我们探索了 Qwen2.5-Coder 在代码助手和 Artifacts 两种场景下的实用性，并用一些样例来展示 Qwen2.5-Coder 在实际场景中的应用潜力。 强大：代码能力达到开源模型 SOTA 代码生成：Qwen2.5-Coder-32B-Instruct 作为本次开源的旗舰模型，在多个流行的代码生成基准（如EvalPlus、LiveCodeBench、BigCodeBench）上都取得了开源模型中的最佳表现，并且达到和 GPT-4o 有竞争力的表现。
代码修复：代码修复是一个重要的编程能力。Qwen2.5-Coder-32B-Instruct 可以帮助用户修复代码中的错误，让编程更加高效。Aider 是流行的代码修复的基准，Qwen2.5-Coder-32B-Instruct 达到 73.7 分，在 Aider 上的表现与 GPT-4o 相当。
代码推理：代码推理是指模型能否学习代码执行的过程，准确地预测模型的输入与输出。上个月发布的 Qwen2.5-Coder-7B-Instruct 已经在代码推理能力上展现出了不俗的表现，32B 模型的表现更进一步。 多编程语言：智能编程助手应该熟悉所有编程语言，Qwen2.5-Coder-32B-Instruct 在 40 多种编程语言上表现出色，在 McEval 上取得了 65.9 分，其中 Haskell、Racket 等语言表现令人印象深刻，这得益于我们在预训练阶段独特的数据清洗和配比。 另外，Qwen2.5-Coder-32B-Instruct 的多编程语言代码修复能力同样令人惊喜，这将有助于用户理解和修改自己熟悉的编程语言，极大缓解陌生语言的学习成本。
与 McEval 类似，MdEval 是多编程语言的代码修复基准，Qwen2.5-Coder-32B-Instruct 在 MdEval 上取得了 75."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/zh/blog/qwen2.5-coder-family/><link crossorigin=anonymous href=/assets/css/stylesheet.012512d6f1d6f320d85cff7ae2b89d136cc19960a4aa00adf35aaae57e557162.css integrity="sha256-ASUS1vHW8yDYXP964ridE2zBmWCkqgCt81qq5X5VcWI=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen2.5-coder-family/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen2.5-coder-family/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen2.5-Coder 全系列: 强大、多样、实用。"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE KAGGLE DEMO DISCORD
简介 今天，我们很高兴开源「强大」、「多样」、「实用」的 Qwen2.5-Coder 全系列模型，致力于持续推动 Open CodeLLMs 的发展。
强大：Qwen2.5-Coder-32B-Instruct 成为目前 SOTA 的开源代码模型，代码能力追平 GPT-4o，展现出强大且全面的代码能力，同时具备良好的通用和数学能力。 多样：上个月我们开源了 1.5B、7B 两个尺寸，本次开源又带来 0.5B、3B、14B、32B 四个尺寸，截至目前， Qwen2.5-Coder 已经覆盖了主流的六个模型尺寸，以满足不同开发者的需要。 实用：我们探索了 Qwen2.5-Coder 在代码助手和 Artifacts 两种场景下的实用性，并用一些样例来展示 Qwen2.5-Coder 在实际场景中的应用潜力。 强大：代码能力达到开源模型 SOTA 代码生成：Qwen2.5-Coder-32B-Instruct 作为本次开源的旗舰模型，在多个流行的代码生成基准（如EvalPlus、LiveCodeBench、BigCodeBench）上都取得了开源模型中的最佳表现，并且达到和 GPT-4o 有竞争力的表现。
代码修复：代码修复是一个重要的编程能力。Qwen2.5-Coder-32B-Instruct 可以帮助用户修复代码中的错误，让编程更加高效。Aider 是流行的代码修复的基准，Qwen2.5-Coder-32B-Instruct 达到 73.7 分，在 Aider 上的表现与 GPT-4o 相当。
代码推理：代码推理是指模型能否学习代码执行的过程，准确地预测模型的输入与输出。上个月发布的 Qwen2.5-Coder-7B-Instruct 已经在代码推理能力上展现出了不俗的表现，32B 模型的表现更进一步。 多编程语言：智能编程助手应该熟悉所有编程语言，Qwen2.5-Coder-32B-Instruct 在 40 多种编程语言上表现出色，在 McEval 上取得了 65.9 分，其中 Haskell、Racket 等语言表现令人印象深刻，这得益于我们在预训练阶段独特的数据清洗和配比。 另外，Qwen2.5-Coder-32B-Instruct 的多编程语言代码修复能力同样令人惊喜，这将有助于用户理解和修改自己熟悉的编程语言，极大缓解陌生语言的学习成本。
与 McEval 类似，MdEval 是多编程语言的代码修复基准，Qwen2.5-Coder-32B-Instruct 在 MdEval 上取得了 75."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/zh/blog/qwen2.5-coder-family/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-11-12T00:00:02+08:00"><meta property="article:modified_time" content="2024-11-12T00:00:02+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen2.5-Coder 全系列: 强大、多样、实用。"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE KAGGLE DEMO DISCORD
简介 今天，我们很高兴开源「强大」、「多样」、「实用」的 Qwen2.5-Coder 全系列模型，致力于持续推动 Open CodeLLMs 的发展。
强大：Qwen2.5-Coder-32B-Instruct 成为目前 SOTA 的开源代码模型，代码能力追平 GPT-4o，展现出强大且全面的代码能力，同时具备良好的通用和数学能力。 多样：上个月我们开源了 1.5B、7B 两个尺寸，本次开源又带来 0.5B、3B、14B、32B 四个尺寸，截至目前， Qwen2.5-Coder 已经覆盖了主流的六个模型尺寸，以满足不同开发者的需要。 实用：我们探索了 Qwen2.5-Coder 在代码助手和 Artifacts 两种场景下的实用性，并用一些样例来展示 Qwen2.5-Coder 在实际场景中的应用潜力。 强大：代码能力达到开源模型 SOTA 代码生成：Qwen2.5-Coder-32B-Instruct 作为本次开源的旗舰模型，在多个流行的代码生成基准（如EvalPlus、LiveCodeBench、BigCodeBench）上都取得了开源模型中的最佳表现，并且达到和 GPT-4o 有竞争力的表现。
代码修复：代码修复是一个重要的编程能力。Qwen2.5-Coder-32B-Instruct 可以帮助用户修复代码中的错误，让编程更加高效。Aider 是流行的代码修复的基准，Qwen2.5-Coder-32B-Instruct 达到 73.7 分，在 Aider 上的表现与 GPT-4o 相当。
代码推理：代码推理是指模型能否学习代码执行的过程，准确地预测模型的输入与输出。上个月发布的 Qwen2.5-Coder-7B-Instruct 已经在代码推理能力上展现出了不俗的表现，32B 模型的表现更进一步。 多编程语言：智能编程助手应该熟悉所有编程语言，Qwen2.5-Coder-32B-Instruct 在 40 多种编程语言上表现出色，在 McEval 上取得了 65.9 分，其中 Haskell、Racket 等语言表现令人印象深刻，这得益于我们在预训练阶段独特的数据清洗和配比。 另外，Qwen2.5-Coder-32B-Instruct 的多编程语言代码修复能力同样令人惊喜，这将有助于用户理解和修改自己熟悉的编程语言，极大缓解陌生语言的学习成本。
与 McEval 类似，MdEval 是多编程语言的代码修复基准，Qwen2.5-Coder-32B-Instruct 在 MdEval 上取得了 75."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Qwen2.5-Coder 全系列: 强大、多样、实用。","item":"https://qwenlm.github.io/zh/blog/qwen2.5-coder-family/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen2.5-Coder 全系列: 强大、多样、实用。","name":"Qwen2.5-Coder 全系列: 强大、多样、实用。","description":"GITHUB HUGGING FACE MODELSCOPE KAGGLE DEMO DISCORD\n简介 今天，我们很高兴开源「强大」、「多样」、「实用」的 Qwen2.5-Coder 全系列模型，致力于持续推动 Open CodeLLMs 的发展。\n强大：Qwen2.5-Coder-32B-Instruct 成为目前 SOTA 的开源代码模型，代码能力追平 GPT-4o，展现出强大且全面的代码能力，同时具备良好的通用和数学能力。 多样：上个月我们开源了 1.5B、7B 两个尺寸，本次开源又带来 0.5B、3B、14B、32B 四个尺寸，截至目前， Qwen2.5-Coder 已经覆盖了主流的六个模型尺寸，以满足不同开发者的需要。 实用：我们探索了 Qwen2.5-Coder 在代码助手和 Artifacts 两种场景下的实用性，并用一些样例来展示 Qwen2.5-Coder 在实际场景中的应用潜力。 强大：代码能力达到开源模型 SOTA 代码生成：Qwen2.5-Coder-32B-Instruct 作为本次开源的旗舰模型，在多个流行的代码生成基准（如EvalPlus、LiveCodeBench、BigCodeBench）上都取得了开源模型中的最佳表现，并且达到和 GPT-4o 有竞争力的表现。\n代码修复：代码修复是一个重要的编程能力。Qwen2.5-Coder-32B-Instruct 可以帮助用户修复代码中的错误，让编程更加高效。Aider 是流行的代码修复的基准，Qwen2.5-Coder-32B-Instruct 达到 73.7 分，在 Aider 上的表现与 GPT-4o 相当。\n代码推理：代码推理是指模型能否学习代码执行的过程，准确地预测模型的输入与输出。上个月发布的 Qwen2.5-Coder-7B-Instruct 已经在代码推理能力上展现出了不俗的表现，32B 模型的表现更进一步。 多编程语言：智能编程助手应该熟悉所有编程语言，Qwen2.5-Coder-32B-Instruct 在 40 多种编程语言上表现出色，在 McEval 上取得了 65.9 分，其中 Haskell、Racket 等语言表现令人印象深刻，这得益于我们在预训练阶段独特的数据清洗和配比。 另外，Qwen2.5-Coder-32B-Instruct 的多编程语言代码修复能力同样令人惊喜，这将有助于用户理解和修改自己熟悉的编程语言，极大缓解陌生语言的学习成本。\n与 McEval 类似，MdEval 是多编程语言的代码修复基准，Qwen2.5-Coder-32B-Instruct 在 MdEval 上取得了 75.","keywords":[],"articleBody":" GITHUB HUGGING FACE MODELSCOPE KAGGLE DEMO DISCORD\n简介 今天，我们很高兴开源「强大」、「多样」、「实用」的 Qwen2.5-Coder 全系列模型，致力于持续推动 Open CodeLLMs 的发展。\n强大：Qwen2.5-Coder-32B-Instruct 成为目前 SOTA 的开源代码模型，代码能力追平 GPT-4o，展现出强大且全面的代码能力，同时具备良好的通用和数学能力。 多样：上个月我们开源了 1.5B、7B 两个尺寸，本次开源又带来 0.5B、3B、14B、32B 四个尺寸，截至目前， Qwen2.5-Coder 已经覆盖了主流的六个模型尺寸，以满足不同开发者的需要。 实用：我们探索了 Qwen2.5-Coder 在代码助手和 Artifacts 两种场景下的实用性，并用一些样例来展示 Qwen2.5-Coder 在实际场景中的应用潜力。 强大：代码能力达到开源模型 SOTA 代码生成：Qwen2.5-Coder-32B-Instruct 作为本次开源的旗舰模型，在多个流行的代码生成基准（如EvalPlus、LiveCodeBench、BigCodeBench）上都取得了开源模型中的最佳表现，并且达到和 GPT-4o 有竞争力的表现。\n代码修复：代码修复是一个重要的编程能力。Qwen2.5-Coder-32B-Instruct 可以帮助用户修复代码中的错误，让编程更加高效。Aider 是流行的代码修复的基准，Qwen2.5-Coder-32B-Instruct 达到 73.7 分，在 Aider 上的表现与 GPT-4o 相当。\n代码推理：代码推理是指模型能否学习代码执行的过程，准确地预测模型的输入与输出。上个月发布的 Qwen2.5-Coder-7B-Instruct 已经在代码推理能力上展现出了不俗的表现，32B 模型的表现更进一步。 多编程语言：智能编程助手应该熟悉所有编程语言，Qwen2.5-Coder-32B-Instruct 在 40 多种编程语言上表现出色，在 McEval 上取得了 65.9 分，其中 Haskell、Racket 等语言表现令人印象深刻，这得益于我们在预训练阶段独特的数据清洗和配比。 另外，Qwen2.5-Coder-32B-Instruct 的多编程语言代码修复能力同样令人惊喜，这将有助于用户理解和修改自己熟悉的编程语言，极大缓解陌生语言的学习成本。\n与 McEval 类似，MdEval 是多编程语言的代码修复基准，Qwen2.5-Coder-32B-Instruct 在 MdEval 上取得了 75.2 分，在所有开源模型中排名第一。 人类偏好对齐：为了检验 Qwen2.5-Coder-32B-Instruct 在人类偏好上的对齐表现，我们构建了一个来自内部标注的代码偏好评估基准 Code Arena（类似 Arena Hard）。我们采用 GPT-4o 作为偏好对齐的评测模型，采用 “A vs. B win” 的评测方式——即在测试集实例中，模型 A 的分数超过模型 B 的百分比。下图结果表现出 Qwen2.5-Coder-32B-Instruct 在偏好对齐方面的优势。 多样：丰富的模型尺寸 Qwen2.5-Coder 开源模型家族包含 0.5B、1.5B、3B、7B、14B、32B 六个尺寸，不仅能够满足开发者在不同资源场景下的需求，还能给研究社区提供良好的实验场。下表是详细的模型信息：\nModels Params Non-Emb Params Layers Heads (KV) Tie Embedding Context Length License Qwen2.5-Coder-0.5B 0.49B 0.36B 24 14 / 2 Yes 32K Apache 2.0 Qwen2.5-Coder-1.5B 1.54B 1.31B 28 12 / 2 Yes 32K Apache 2.0 Qwen2.5-Coder-3B 3.09B 2.77B 36 16 / 2 Yes 32K Qwen Research Qwen2.5-Coder-7B 7.61B 6.53B 28 28 / 4 No 128K Apache 2.0 Qwen2.5-Coder-14B 14.7B 13.1B 48 40 / 8 No 128K Apache 2.0 Qwen2.5-Coder-32B 32.5B 31.0B 64 40 / 8 No 128K Apache 2.0 我们一直相信 Scaling Law 哲学。我们评估了不同尺寸的 Qwen2.5-Coder 模型在所有数据集上的表现，以验证 Scaling 在 Code LLMs 上的有效性。\n对于每一个尺寸，我们都开源了 Base 和 Instruct 模型，其中， Base 模型可作为开发者微调模型的基座，Instruct 模型是可以直接聊天的官方对齐模型，\n下面是不同尺寸 Base 模型的表现： 下面是不同尺寸 Instruct 模型的表现： 为了更加直观，我们展示了不同尺寸 Qwen2.5-Coder 模型和其他开源模型在核心数据集上的对比。\n针对 Base 模型，我们选择 MBPP-3shot 作为评估指标，我们大量的实验表明，MBPP-3shot 更适合评估基础模型，且能够和模型的真实效果有较好的相关性。\n针对 Instruct 模型，我们选择 LiveCodeBench 最近 4 个月（2024.07 - 2024.11）的题目作为评估，这些最新公布的、不可能泄露到训练集的题目能够反映模型的 OOD 能力。\n模型尺寸和模型效果之间存在预期中的正相关关系，并且， Qwen2.5-Coder 在所有尺寸下都取得了 SOTA 表现，这鼓励我们继续探索更大尺寸的 Coder 模型。\n实用：遇见 Cursor 和 Artifacts 实用的 Coder 一直是我们的愿景。为此，我们探索了 Qwen2.5-Coder 模型在代码助手和 Artifacts 场景下的实际应用。\nQwen2.5-Coder 🤝 Cursor 智能代码助手已经得到广泛应用，但目前大多依赖闭源模型，我们希望 Qwen2.5-Coder 的出现能够为开发者提供一个友好且强大的选择。\n下面是 Qwen2.5-Coder 在 Cursor 场景下的一个例子。\nExample: Qwen2.5-Coder 🤝 Cursor\r另外，Qwen2.5-Coder-32B 在预训练模型上就展现出强大的代码补全能力，在 Humaneval-Infilling、CrossCodeEval、CrossCodeLongEval、RepoEval、SAFIM 等 5 个评测集上都取得了 SOTA 表现。\n为了保持公平对比，我们将最大序列长度控制在 8k，采用 Fill-in-the-Middle 模式进行测试。在 CrossCodeEval、CrossCodeLongEval、RepoEval、Humaneval-Infilling 4 个评测集中，我们评估了生成内容与真实标签是否绝对相等（Exact Match）；在 SAFIM 中，我们采用 1 次执行成功率（Pass@1）进行评价。\nQwen2.5-Coder 🤝 Artifacts Artifacts 是代码生成的重要应用之一，能够帮助用户创作一些适合可视化的作品，我们选择 Open WebUI 探索 Qwen2.5-Coder 在 Artifacts 场景下的潜力，下面是一些具体的例子：\nExample: Three-body Problem Simulation\rNext\rExample: Lissajous Curve\rNext\rExample: Drafting a resume\rNext\rExample: Emoji dancing\rNext\r我们即将在通义官网 https://tongyi.aliyun.com 上线代码模式，支持一句话生成网站、小游戏和数据图表等各类可视化应用。欢迎大家体验！\n模型许可 Qwen2.5-Coder 0.5B/1.5B/7B/14B/32B 模型均采用 Apache 2.0 许可证，3B模型使用 Research Only 许可。\nWhat’s Next for Qwen-Coder? 相信我们这次的发布能够真正帮助到开发者，和社区一起探索更多有趣的应用场景。另外，我们正在深入探索以代码为中心的强大推理模型，相信很快能和大家见面！\nCitation @article{hui2024qwen2, title={Qwen2. 5-Coder Technical Report}, author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others}, journal={arXiv preprint arXiv:2409.12186}, year={2024} } @article{yang2024qwen2, title={Qwen2 technical report}, author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others}, journal={arXiv preprint arXiv:2407.10671}, year={2024} } ","wordCount":"405","inLanguage":"zh","datePublished":"2024-11-12T00:00:02+08:00","dateModified":"2024-11-12T00:00:02+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/zh/blog/qwen2.5-coder-family/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen2.5-Coder 全系列: 强大、多样、实用。</h1><div class=post-meta><span title='2024-11-12 00:00:02 +0800 +0800'>2024年11月12日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;405 字&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://qwenlm.github.io/blog/qwen2.5-coder-family/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-top.jpg#center width=100%></figure><a href=https://github.com/QwenLM/Qwen2.5-Coder class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/collections/Qwen/qwen25-coder-66eaa22e6f99801bf65b0c2f class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://www.kaggle.com/models/qwen-lm/qwen2.5-coder class="btn external" target=_blank>KAGGLE</a>
<a href=https://huggingface.co/spaces/Qwen/Qwen2.5-Coder-demo class="btn external" target=_blank>DEMO</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><h2 id=简介>简介<a hidden class=anchor aria-hidden=true href=#简介>#</a></h2><p>今天，我们很高兴开源「强大」、「多样」、「实用」的 Qwen2.5-Coder 全系列模型，致力于持续推动 Open CodeLLMs 的发展。</p><ul><li><strong>强大</strong>：Qwen2.5-Coder-32B-Instruct 成为目前 SOTA 的开源代码模型，代码能力追平 GPT-4o，展现出强大且全面的代码能力，同时具备良好的通用和数学能力。</li><li><strong>多样</strong>：上个月我们开源了 1.5B、7B 两个尺寸，本次开源又带来 0.5B、3B、14B、32B 四个尺寸，截至目前， Qwen2.5-Coder 已经覆盖了主流的六个模型尺寸，以满足不同开发者的需要。</li><li><strong>实用</strong>：我们探索了 Qwen2.5-Coder 在代码助手和 Artifacts 两种场景下的实用性，并用一些样例来展示 Qwen2.5-Coder 在实际场景中的应用潜力。</li></ul><h2 id=强大代码能力达到开源模型-sota>强大：代码能力达到开源模型 SOTA<a hidden class=anchor aria-hidden=true href=#强大代码能力达到开源模型-sota>#</a></h2><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-main.png#center width=100%></figure><ul><li><p><strong>代码生成</strong>：Qwen2.5-Coder-32B-Instruct 作为本次开源的旗舰模型，在多个流行的代码生成基准（如EvalPlus、LiveCodeBench、BigCodeBench）上都取得了开源模型中的最佳表现，并且达到和 GPT-4o 有竞争力的表现。</p></li><li><p><strong>代码修复</strong>：代码修复是一个重要的编程能力。Qwen2.5-Coder-32B-Instruct 可以帮助用户修复代码中的错误，让编程更加高效。Aider 是流行的代码修复的基准，Qwen2.5-Coder-32B-Instruct 达到 73.7 分，在 Aider 上的表现与 GPT-4o 相当。</p></li><li><p><strong>代码推理</strong>：代码推理是指模型能否学习代码执行的过程，准确地预测模型的输入与输出。上个月发布的 Qwen2.5-Coder-7B-Instruct 已经在代码推理能力上展现出了不俗的表现，32B 模型的表现更进一步。<figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-crux.png#center width=80%></figure></p></li><li><p><strong>多编程语言</strong>：智能编程助手应该熟悉所有编程语言，Qwen2.5-Coder-32B-Instruct 在 40 多种编程语言上表现出色，在 McEval 上取得了 65.9 分，其中 Haskell、Racket 等语言表现令人印象深刻，这得益于我们在预训练阶段独特的数据清洗和配比。<br><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-mceval.jpg#center width=80%></figure></p></li></ul><p>另外，Qwen2.5-Coder-32B-Instruct 的多编程语言代码修复能力同样令人惊喜，这将有助于用户理解和修改自己熟悉的编程语言，极大缓解陌生语言的学习成本。</p><p>与 McEval 类似，MdEval 是多编程语言的代码修复基准，Qwen2.5-Coder-32B-Instruct 在 MdEval 上取得了 75.2 分，在所有开源模型中排名第一。<figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-mdeval.jpg#center width=80%></figure></p><ul><li><strong>人类偏好对齐</strong>：为了检验 Qwen2.5-Coder-32B-Instruct 在人类偏好上的对齐表现，我们构建了一个来自内部标注的代码偏好评估基准 Code Arena（类似 Arena Hard）。我们采用 GPT-4o 作为偏好对齐的评测模型，采用 “A vs. B win” 的评测方式——即在测试集实例中，模型 A 的分数超过模型 B 的百分比。下图结果表现出 Qwen2.5-Coder-32B-Instruct 在偏好对齐方面的优势。</li></ul><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-arena.jpg#center width=80%></figure><h2 id=多样丰富的模型尺寸>多样：丰富的模型尺寸<a hidden class=anchor aria-hidden=true href=#多样丰富的模型尺寸>#</a></h2><p>Qwen2.5-Coder 开源模型家族包含 0.5B、1.5B、3B、7B、14B、32B 六个尺寸，不仅能够满足开发者在不同资源场景下的需求，还能给研究社区提供良好的实验场。下表是详细的模型信息：</p><table><thead><tr><th style=text-align:left>Models</th><th style=text-align:center>Params</th><th style=text-align:center>Non-Emb Params</th><th style=text-align:center>Layers</th><th style=text-align:center>Heads (KV)</th><th style=text-align:center>Tie Embedding</th><th style=text-align:center>Context Length</th><th style=text-align:center>License</th></tr></thead><tbody><tr><td style=text-align:left>Qwen2.5-Coder-0.5B</td><td style=text-align:center>0.49B</td><td style=text-align:center>0.36B</td><td style=text-align:center>24</td><td style=text-align:center>14 / 2</td><td style=text-align:center>Yes</td><td style=text-align:center>32K</td><td style=text-align:center>Apache 2.0</td></tr><tr><td style=text-align:left>Qwen2.5-Coder-1.5B</td><td style=text-align:center>1.54B</td><td style=text-align:center>1.31B</td><td style=text-align:center>28</td><td style=text-align:center>12 / 2</td><td style=text-align:center>Yes</td><td style=text-align:center>32K</td><td style=text-align:center>Apache 2.0</td></tr><tr><td style=text-align:left>Qwen2.5-Coder-3B</td><td style=text-align:center>3.09B</td><td style=text-align:center>2.77B</td><td style=text-align:center>36</td><td style=text-align:center>16 / 2</td><td style=text-align:center>Yes</td><td style=text-align:center>32K</td><td style=text-align:center>Qwen Research</td></tr><tr><td style=text-align:left>Qwen2.5-Coder-7B</td><td style=text-align:center>7.61B</td><td style=text-align:center>6.53B</td><td style=text-align:center>28</td><td style=text-align:center>28 / 4</td><td style=text-align:center>No</td><td style=text-align:center>128K</td><td style=text-align:center>Apache 2.0</td></tr><tr><td style=text-align:left>Qwen2.5-Coder-14B</td><td style=text-align:center>14.7B</td><td style=text-align:center>13.1B</td><td style=text-align:center>48</td><td style=text-align:center>40 / 8</td><td style=text-align:center>No</td><td style=text-align:center>128K</td><td style=text-align:center>Apache 2.0</td></tr><tr><td style=text-align:left>Qwen2.5-Coder-32B</td><td style=text-align:center>32.5B</td><td style=text-align:center>31.0B</td><td style=text-align:center>64</td><td style=text-align:center>40 / 8</td><td style=text-align:center>No</td><td style=text-align:center>128K</td><td style=text-align:center>Apache 2.0</td></tr></tbody></table><p>我们一直相信 Scaling Law 哲学。我们评估了不同尺寸的 Qwen2.5-Coder 模型在所有数据集上的表现，以验证 Scaling 在 Code LLMs 上的有效性。</p><p>对于每一个尺寸，我们都开源了 Base 和 Instruct 模型，其中， Base 模型可作为开发者微调模型的基座，Instruct 模型是可以直接聊天的官方对齐模型，</p><p>下面是不同尺寸 Base 模型的表现：<figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/qwen2.5-coder-family-base.png#center width=100%></figure></p><p>下面是不同尺寸 Instruct 模型的表现：<figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/qwen2.5-coder-family-instruct.png#center width=100%></figure></p><p>为了更加直观，我们展示了不同尺寸 Qwen2.5-Coder 模型和其他开源模型在核心数据集上的对比。</p><ul><li><p>针对 Base 模型，我们选择 MBPP-3shot 作为评估指标，我们大量的实验表明，MBPP-3shot 更适合评估基础模型，且能够和模型的真实效果有较好的相关性。</p></li><li><p>针对 Instruct 模型，我们选择 LiveCodeBench 最近 4 个月（2024.07 - 2024.11）的题目作为评估，这些最新公布的、不可能泄露到训练集的题目能够反映模型的 OOD 能力。</p></li></ul><p>模型尺寸和模型效果之间存在预期中的正相关关系，并且， Qwen2.5-Coder 在所有尺寸下都取得了 SOTA 表现，这鼓励我们继续探索更大尺寸的 Coder 模型。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/qwen2.5-coder-family-dual.jpg#center width=100%></figure><h2 id=实用遇见-cursor-和-artifacts>实用：遇见 Cursor 和 Artifacts<a hidden class=anchor aria-hidden=true href=#实用遇见-cursor-和-artifacts>#</a></h2><p>实用的 Coder 一直是我们的愿景。为此，我们探索了 Qwen2.5-Coder 模型在代码助手和 Artifacts 场景下的实际应用。</p><h3 id=qwen25-coder--cursor>Qwen2.5-Coder 🤝 Cursor<a hidden class=anchor aria-hidden=true href=#qwen25-coder--cursor>#</a></h3><p>智能代码助手已经得到广泛应用，但目前大多依赖闭源模型，我们希望 Qwen2.5-Coder 的出现能够为开发者提供一个友好且强大的选择。</p><p>下面是 Qwen2.5-Coder 在 <a href=https://www.cursor.com/>Cursor</a> 场景下的一个例子。</p><div class="full-width-container example-container"><div class=example-content><div class=title><span>Example: Qwen2.5-Coder 🤝 Cursor</span></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/cases/final-game_of_life.mp4></video></figure></div></div></div></div><p>另外，Qwen2.5-Coder-32B 在预训练模型上就展现出强大的代码补全能力，在 Humaneval-Infilling、CrossCodeEval、CrossCodeLongEval、RepoEval、SAFIM 等 5 个评测集上都取得了 SOTA 表现。</p><p>为了保持公平对比，我们将最大序列长度控制在 8k，采用 Fill-in-the-Middle 模式进行测试。在 CrossCodeEval、CrossCodeLongEval、RepoEval、Humaneval-Infilling 4 个评测集中，我们评估了生成内容与真实标签是否绝对相等（Exact Match）；在 SAFIM 中，我们采用 1 次执行成功率（Pass@1）进行评价。</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/32b-fim.jpg#center width=80%></figure><h3 id=qwen25-coder--artifacts>Qwen2.5-Coder 🤝 Artifacts<a hidden class=anchor aria-hidden=true href=#qwen25-coder--artifacts>#</a></h3><p>Artifacts 是代码生成的重要应用之一，能够帮助用户创作一些适合可视化的作品，我们选择 <a href=https://openwebui.com/>Open WebUI</a> 探索 Qwen2.5-Coder 在 Artifacts 场景下的潜力，下面是一些具体的例子：</p><div class="full-width-container example-container"><div class=example-content><div class=title><span>Example: Three-body Problem Simulation</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/cases/final-3body.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Lissajous Curve</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/cases/final-lissajous.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Drafting a resume</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/cases/final-cv.mp4></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Emoji dancing</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder-Family/cases/final-dancing.mp4></video></figure></div></div></div></div><p>我们即将在通义官网 <a href=https://tongyi.aliyun.com>https://tongyi.aliyun.com</a> 上线代码模式，支持一句话生成网站、小游戏和数据图表等各类可视化应用。欢迎大家体验！</p><h2 id=模型许可>模型许可<a hidden class=anchor aria-hidden=true href=#模型许可>#</a></h2><p>Qwen2.5-Coder 0.5B/1.5B/7B/14B/32B 模型均采用 <strong>Apache 2.0</strong> 许可证，3B模型使用 <code>Research Only</code> 许可。</p><h2 id=whats-next-for-qwen-coder>What&rsquo;s Next for Qwen-Coder?<a hidden class=anchor aria-hidden=true href=#whats-next-for-qwen-coder>#</a></h2><p>相信我们这次的发布能够真正帮助到开发者，和社区一起探索更多有趣的应用场景。另外，我们正在深入探索以代码为中心的强大推理模型，相信很快能和大家见面！</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><pre tabindex=0><code>@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}
@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
</code></pre></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>