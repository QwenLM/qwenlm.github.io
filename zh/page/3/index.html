<!doctype html><html lang=zh dir=auto><head><meta name=generator content="Hugo 0.106.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen</title><meta name=keywords content="multi-modal,machine learning,blog"><meta name=description content="Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=http://qwenlm.github.io/zh/><link crossorigin=anonymous href=/assets/css/stylesheet.3045213cee0439fa94bd732879be5b19072f75f4d28f6e62dd58c34f5243e49f.css integrity="sha256-MEUhPO4EOfqUvXMoeb5bGQcvdfTSj25i3VjDT1JD5J8=" rel="preload stylesheet" as=style><link rel=icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=icon type=image/png sizes=16x16 href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=icon type=image/png sizes=32x32 href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg%22><link rel=apple-touch-icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=mask-icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/json href=http://qwenlm.github.io/zh/index.json><link rel=alternate hreflang=en href=http://qwenlm.github.io/><link rel=alternate hreflang=zh href=http://qwenlm.github.io/zh/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.f20a5212619392e989b6d24ad9ce42302014debfad4d3c8c01db030c36d03475.js integrity="sha256-8gpSEmGTkumJttJK2c5CMCAU3r+tTTyMAdsDDDbQNHU="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="http://qwenlm.github.io/zh/"><meta property="og:image" content="http://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Qwen","url":"http://qwenlm.github.io/","description":"Qwen","thumbnailUrl":"https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg","sameAs":[]}</script></head><body class=list id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><svg width="25" height="24" viewBox="0 0 25 24" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><linearGradient x1="76.7202373%" y1="41.6070847%" x2="18.306123%" y2="65.5065085%" id="linearGradient-9_1k7ha4jv-1"><stop stop-color="#797beb" offset="0"/><stop stop-color="#373080" offset="100%"/></linearGradient></defs><g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="_编组-7" fill="url(#linearGradient-9_1k7ha4jv-1)"><path d="M12.2746711.0C12.5125388.0 12.7434104.12583746 12.8693403.33556656l1.3852293 2.3769298h6.1425827C20.63502 2.71249636 20.8658915 2.83833382 20.9918215 3.04806292l1.7420308 2.97815322C22.8597822 6.23594524 22.8597822 6.5016021 22.7338523 6.7113312L22.6988718 6.76725896C22.6708873 6.80920478 22.6359068 6.8511506 22.5939301 6.88610545L21.2156969 9.24905331l3.050303 5.24322749L24.3429571 14.6041363C24.4339065 14.8138654 24.4548948 15.0795223 24.3919298 15.2682785l-1.6021086 2.7404602C22.6638912 18.2184678 22.4400158 18.3443053 22.195152 18.3443053L19.4176972 18.3582872 16.353402 23.6504515C16.227472 23.8601806 16.0035966 23.9860181 15.7587328 23.9860181L12.2886633 24H12.2396906C12.0158151 23.9860181 11.7989358 23.8601806 11.6869981 23.6644334l-1.490171-2.551704H4.13120166C4.0822289 21.1267113 4.04025225 21.1267113 3.9912795 21.1267113 3.75341183 21.1267113 3.52254028 21.0008739 3.39661034 20.7911448L1.79450165 18.0506845C1.66857171 17.8479464 1.66857171 17.5892805 1.79450165 17.3725604l1.37823324-2.3909117L.0944474553 9.69647539c-.1259299404-.20273813-.1259299404-.46140402.0-.678124089999999L1.80849387 6.02621614c.11193772-.2097291.34280928-.33556656.59466916-.33556656C2.466128 5.67666764 2.51510075 5.69064958 2.56407351 5.70463152H5.40449327L8.44080406.46140402C8.45479628.4194582 8.46179238.38450335 8.48278071.35653947L8.49677292.33556656C8.62270286.12583746 8.84657831.0 9.09144209.0H12.2816672 12.2746711zM9.04246933.72706088 5.74730256 6.41071949H2.3751786L8.93752771 17.6871541H5.59338819l-1.61610091 2.789397H10.5606247l1.6790659 2.8942616 6.5623491-11.3043985 1.6790659 2.8802797L23.7203035 14.9327119 20.4181406 9.24905331l1.6650737-2.8662977L9.00049268 6.39673755 10.6795586 3.51645791 9.04946544.72706088H9.04246933zM16.1435187 9.82930382 12.2187023 16.5755899 8.2938858 9.82930382h7.8496329z" id="_形状"/></g></g></svg></a><div class=logo-switches></div></div><ul id=menu><li><a href=/resources title=Resources><span>Resources</span></a></li><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container style=min-height:100vh;display:flex;justify-content:center;background-color:#000><div class=mouse-hint><div class=mouse-point></div></div><style>body{-ms-overflow-style:none;scrollbar-width:none}body::-webkit-scrollbar{display:none}.mouse-hint{position:absolute;height:36px;width:24px;border:1px solid #fff;border-radius:12px;bottom:20%;left:50% - calc(12px);opacity:1;transition:opacity .3s;animation:1s ease-out 0s 1 slideBelow}.mouse-hint .mouse-point{height:4px;width:4px;background-color:#fff;position:absolute;left:50%;bottom:40%;border-radius:4px;transform-origin:50% 100%;transform:translate(-50%);animation:2.2s ease-in-out infinite jump;will-change:transform}@keyframes slideBelow{0%{transform:translateY(50px);opacity:0}100%{transform:translateX(0);opacity:1}}@keyframes jump{0%,20%,60%,to{transform:translate(-50%)translateY(0);height:4px;animation-timing-function:ease-in}40%,80%{transform:translate(-50%)translateY(8px);height:8px;animation-timing-function:ease-out}}</style><div class="hero text-fade-in"><div class=hero-header><h1>Qwen</h1></div><div class=hero-footer><div class=social-icons></div></div></div></div><main class="main home"><article class=post-entry><header class=entry-header><h2>Qwen-Max-0428模型介绍</h2></header><div class=entry-content><p>API DEMO DISCORD
此前，我们开源了Qwen1.5系列的模型，参数规模最小至5亿，最大至1100亿。这一次，我们推出更大规模模型Qwen-Max-0428（通义千问网页端及APP产品版本从2.1升级至2.5）。Qwen-Max-0428是经过指令微调的Chat模型。近期该模型登陆了Chatbot Arena，并登榜前十。此外，我们在MT-Bench的评测上也观察到该模型的表现显著优于Qwen1.5-110B-Chat。
Models MT-Bench Arena Qwen1.5-110B-Chat 8.88 1172 Qwen-Max-0428 8.96 1186 我们也在Hugging Face上提供了Demo服务（链接）：
同时我们也提供了DashScope API服务（链接）。目前API服务已经支持OpenAI API格式，示例如下所示：
from openai import OpenAI client = OpenAI( api_key="$your-dashscope-api-key", base_url="https://dashscope.aliyuncs.com/compatible-mode/v1" ) completion = client.chat.completions.create( model="qwen-max", messages=[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Tell me something about large language models.'}] ) print(completion.choices[0].message) 此外，Qwen-Max-0428已上线通义千问网页端及APP。欢迎体验！
引用 @misc{qwen1.5, title = {Introducing Qwen1.5}, url = {https://qwenlm.github.io/blog/qwen1.5/}, author = {Qwen Team}, month = {February}, year = {2024} }</p></div><footer class=entry-footer><span title='2024-05-11 18:10:00 +0800 +0800'>2024年5月11日</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;74 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen-Max-0428模型介绍" href=http://qwenlm.github.io/zh/blog/qwen-max-0428/></a></article><article class=post-entry><header class=entry-header><h2>Qwen1.5-110B：Qwen1.5系列的首个千亿参数开源模型</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
简介 近期开源社区陆续出现了千亿参数规模以上的大模型，这些模型都在各项评测中取得杰出的成绩。今天，我们开源1100亿参数的Qwen1.5系列首个千亿参数模型Qwen1.5-110B，该模型在基础能力评估中与Meta-Llama3-70B相媲美，在Chat评估中表现出色，包括MT-Bench和AlpacaEval 2.0。
模型特性 Qwen1.5-110B与其他Qwen1.5模型相似，采用了相同的Transformer解码器架构。它包含了分组查询注意力（GQA），在模型推理时更加高效。该模型支持32K tokens的上下文长度，同时它仍然是多语言的，支持英、中、法、西、德、俄、日、韩、越、阿等多种语言。
模型效果 我们对基础语言模型进行了一系列评估，并与最近的SOTA语言模型Meta-Llama3-70B以及Mixtral-8x22B进行了比较。
Qwen1.5-110B Qwen1.5-72B Llama-3-70B Mixtral-8x22B MMLU 80.4 77.5 79.5 77.8 TheoremQA 34.9 29.3 32.0 35.9 GPQA 35.9 36.3 36.4 34.3 Hellaswag 87.5 86.0 88.0 88.7 BBH 74.8 65.5 76.6 69.2 ARC-C 69.6 65.9 68.8 70.7 GSM8K 85.4 79.5 79.2 78.6 MATH 49.6 34.1 41.0 41.7 HumanEval 52.4 41.5 45.7 45.1 MBPP 58.1 53.4 55.1 71.2 上述结果显示，新的110B模型在基础能力方面至少与Llama-3-70B模型相媲美。在这个模型中，我们没有对预训练的方法进行大幅改变，因此我们认为与72B相比的性能提升主要来自于增加模型规模。
我们还在MT-Bench和AlpacaEval 2....</p></div><footer class=entry-footer><span title='2024-04-25 13:33:00 +0800 +0800'>2024年4月25日</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;113 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen1.5-110B：Qwen1.5系列的首个千亿参数开源模型" href=http://qwenlm.github.io/zh/blog/qwen1.5-110b/></a></article><article class=post-entry><header class=entry-header><h2>与 CodeQwen1.5 结对编程</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
简介 代码助手，是一种基于 LLMs 的智能化的编程工具，它可以帮助程序员更高效、更准确的编写代码，使得整个软件开发过程更加流畅和高效。然而流行的代码助手，比如 Github Copilot，依赖于闭源的商业模型，不仅昂贵还会引起如隐私、安全、版权等方面的担忧。幸运的是，开源社区正在致力于打造开放代码模型来实现开放的代码助手。近期涌现出了一批优秀的 Open CodeLLMs，比如 StarCoder2、CodeLlama、DeepSeek-Coder 等，提供了一条新的路径，但仍然值得探索。
今天，我们非常激动地和大家介绍来自 Qwen1.5 开源家族的新成员，一个代码专家模型 CodeQwen1.5! CodeQwen1.5 基于 Qwen 语言模型初始化，拥有 7B 参数的模型，其拥有 GQA 架构，经过了 ~3T tokens 代码相关的数据进行预训练，共计支持 92 种编程语言、且最长支持 64K 的上下文输入。效果方面，CodeQwen1.5 展现出了非凡的代码生成、长序列建模、代码修改、SQL 能力等,该模型可以大大提高开发人员的工作效率，并在不同的技术环境中简化软件开发工作流程。
CodeQwen 是基础的 Coder 代码生成是大语言模型的关键能力之一，期待模型将自然语言指令转换为具有精确的、可执行的代码。仅拥有 70 亿参数的 CodeQwen1.5 在基础代码生成能力上已经超过了更尺寸的模型，进一步缩小了开源代码 LLM 和 GPT-4 之间的编码能力差距。我们对 HumanEval 和 MBPP 进行了评估，下面是具体的比较。
Model Size HumanEval 0-shot HumanEval+ 0-shot MBPP 0-shot MBPP+ 0-shot MBPP 3-shot Base Model CodeLlama-Base 7B 33.5 25....</p></div><footer class=entry-footer><span title='2024-04-16 13:33:00 +0800 +0800'>2024年4月16日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;296 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to 与 CodeQwen1.5 结对编程" href=http://qwenlm.github.io/zh/blog/codeqwen1.5/></a></article><article class=post-entry><header class=entry-header><h2>Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO WeChat
简介 开源社区长期以来一直在寻求一种能在性能、效率和内存占用之间达到理想平衡的模型。尽管出现了诸如Qwen1.5-72B和DBRX这样的SOTA模型，但这些模型持续面临诸如内存消耗巨大、推理速度缓慢以及显著的微调成本等问题。当前，参数量约30B的模型往往在这方面被看好，得到很多用户的青睐。顺应这一趋势，我们推出Qwen1.5语言模型系列的最新成员：Qwen1.5-32B和Qwen1.5-32B-Chat。
过去数月中，我们精心研发了Qwen1.5-32B基础模型，旨在对标甚至超越当前最先进的30B模型所设定的性能基准。同时，我们在对齐方面取得了进展，特别是在RLHF方面，以提升Qwen1.5-32B-Chat的对话能力。
模型效果 Qwen1.5-32B 是 Qwen1.5 语言模型系列的最新成员，除了模型大小外，其在模型架构上除了GQA几乎无其他差异。GQA能让该模型在模型服务时具有更高的推理效率潜力。
以下我们将对比展示其与参数量约为30B或更大的当前最优（SOTA）模型在基础能力评估、chat评估以及多语言评估方面的性能。以下是对于基础语言模型能力的评估结果：
Model MMLU C-Eval GSM8K MATH HumanEval MBPP BBH CMMLU Llama2-34B 62.6 - 42.2 6.2 22.6 33.0 44.1 - Yi-34B 76.3 81.4 67.2 14.4 23.2 41.0 54.3 83.7 Mixtral-8x7B 70.6 - 74.4 28.4 40.2 60.7 - - Qwen1.5-72B 77.5 84.1 79.5 34.1 41.5 53.4 65.5 83.5 Qwen1.5-32B 73.4 83.5 77.4 36.1 37.2 49.4 66.8 82.3 我们的32B模型在多种任务上展现出颇具竞争力的表现，涵盖MMLU、GSM8K、HumanEval以及BBH等。相较于72B参数模型，Qwen1.5-32B虽在性能上有轻微下降，但在多数任务中仍优于其他30B级别模型，如Llama2-34B和Mixtral-8x7B。...</p></div><footer class=entry-footer><span title='2024-04-02 13:33:00 +0800 +0800'>2024年4月2日</span>&nbsp;·&nbsp;1 分钟&nbsp;·&nbsp;139 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen1.5-32B：Qwen1.5语言模型系列的最后一块拼图" href=http://qwenlm.github.io/zh/blog/qwen1.5-32b/></a></article><article class=post-entry><header class=entry-header><h2>Qwen1.5-MoE: 1/3的激活参数量达到7B模型的性能</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
介绍 今天，我们推出Qwen系列的首个MoE模型，Qwen1.5-MoE-A2.7B。它仅拥有27亿个激活参数，但其性能却能与当前最先进的70亿参数模型，如Mistral 7B和Qwen1.5-7B相媲美。相较于包含65亿个Non-Embedding参数的Qwen1.5-7B，Qwen1.5-MoE-A2.7B只有20亿个Non-Embedding参数，约为原模型大小的三分之一。此外，相比Qwen1.5-7B，Qwen1.5-MoE-A2.7B的训练成本降低了75%，推理速度则提升至1.74倍。
模型结构 我们在Qwen1.5-MoE模型中采用了特别设计的MoE架构。通常情况下，如Mixtral等方法所示，每个transformer block中的MoE层会配备8个expert，并采用top-2门控策略进行routing。这种配置还存在很大的优化空间。我们对这一架构进行了多项改进：
Finegrained experts 初始化 新的routing机制 DeepSeek-MoE和DBRX已经证明了finegrained experts的有效性。从FFN层过渡到MoE层时，我们一般只是简单地复制多次FFN来实现多个expert。而finegrained experts的目标是在不增加参数数量的前提下生成更多expert。为了实现这一点，我们将单个FFN分割成几个部分，每个部分作为一个独立的expert。我们设计了具有总共64个expert的的MoE，对比其他配置，我们认为这个实现能达到效果和效率的最优。
模型初始化阶段至关重要。初步实验表明，从零开始训练MoE模型可能效率低下，且难以提升至预期的最优性能水平。因此，我们首先利用已有的Qwen-1.8B，将其改造为Qwen1.5-MoE-A2.7B。此外，在初始化阶段引入随机性可以显著加快收敛速度，并在整个预训练过程中带来更好的整体性能表现。
目前，一个明显的趋势是在MoE中实现共享expert与routing expert。从更宏观的角度看，这是一种广义的routing方法，因为在没有共享expert的情况下，实际上就退化为传统的MoE路由设置。对于Qwen1.5-MoE-A2.7B模型，我们在其中整合了4个总是被激活的共享expert和每次只激活其中4个的60个routing expert。这种方式非常灵活，同时在我们实验中效率最佳。
性能 为了全面评估和展示Qwen1.5-MoE-A2.7B的能力和优势，我们对base模型和chat模型进行了评估。对于base模型，我们在MMLU、GSM8K和HumanEval评估了其语言理解、数学和代码能力。此外，为了评估其多语言能力，我们按照Qwen1.5的评测方法在数学、理解、考试和翻译等多个领域的多语言基准测试中进行了测试，并在"Multilingual"列中给出了综合得分。对于chat模型，我们没有使用传统的基准测试，而是使用MT-Bench进行了测试。
在这个比较分析中，我们将Qwen1.5-MoE-A2.7B与最好的7B模型，比如Mistral-7B（base模型为v0.1，chat模型为v0.2）、Gemma-7B以及Qwen1.5-7B进行了对比。此外，我们还将其与具有相似参数数量的MoE模型DeepSeekMoE 16B进行了比较。结果如下表所示：
Model MMLU GSM8K HumanEval Multilingual MT-Bench Mistral-7B 64.1 47.5 27.4 40.0 7.60 Gemma-7B 64.6 50.9 32.3 - - Qwen1.5-7B 61.0 62.5 36.0 45.2 7.60 DeepSeekMoE 16B 45.0 18.8 26.8 - 6.93 Qwen1.5-MoE-A2.7B 62.5 61.5 34.2 40.8 7.17 Qwen1.5-MoE-A2.7B在与最佳的7B模型相比取得了非常接近的性能。然而，我们发现在chat模型方面仍有改进的空间。我们将继续研究如何更加有效地微调MoE模型。
训练成本与推理效率 MoE模型的训练成本与dense模型存在显著差异。尽管MoE模型通常拥有更多的参数，但由于其稀疏性，训练开销可以显著降低。我们先对比各个模型的三个关键参数，分别是总参数数量、激活参数数量和Non-embedding参数：
Model #Parameters #(Activated) Parameters #(Activated) Non-embedding parameters Mistral-7B 7....</p></div><footer class=entry-footer><span title='2024-03-28 11:31:44 +0800 +0800'>2024年3月28日</span>&nbsp;·&nbsp;2 分钟&nbsp;·&nbsp;274 字&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen1.5-MoE: 1/3的激活参数量达到7B模型的性能" href=http://qwenlm.github.io/zh/blog/qwen-moe/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=http://qwenlm.github.io/zh/page/2/>«&nbsp;上一页&nbsp;</a>
<a class=next href=http://qwenlm.github.io/zh/page/4/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=http://qwenlm.github.io/zh/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>