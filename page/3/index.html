<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.106.0"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen</title><meta name=keywords content="multi-modal,machine learning,blog"><meta name=description content="Qwickly forging AGI, enhancing intelligence."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.4f62259998ff7b98600586086c11b90753ca941d3fefd46d058f5df6a9fa05f4.css integrity="sha256-T2IlmZj/e5hgBYYIbBG5B1PKlB0/79RtBY9d9qn6BfQ=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/json href=https://qwenlm.github.io/index.json><link rel=alternate hreflang=en href=https://qwenlm.github.io/><link rel=alternate hreflang=zh href><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen"><meta property="og:description" content="Qwickly forging AGI, enhancing intelligence."><meta property="og:type" content="website"><meta property="og:url" content="https://qwenlm.github.io/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen"><meta name=twitter:description content="Qwickly forging AGI, enhancing intelligence."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Qwen","url":"https://qwenlm.github.io/","description":"Qwen","thumbnailUrl":"https://qwenlm.github.io/favicon.png","sameAs":[]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container style=min-height:100vh;display:flex;justify-content:center;background-color:#000><img class=hero-background style=opacity:0 onload="this.style.opacity=1" src=https://cdn.jsdelivr.net/gh/qwenlm/qwenlm.github.io@master/static/img/background.webp width=100%><div class=hero-gradient></div><div class=hero-blur></div><div class=mouse-hint><div class=mouse-point></div></div><style>body{-ms-overflow-style:none;scrollbar-width:none}body::-webkit-scrollbar{display:none}.mouse-hint{position:absolute;height:36px;width:24px;border:1px solid #fff;border-radius:12px;bottom:20%;left:50% - calc(12px);opacity:1;transition:opacity .3s;animation:1s ease-out 0s 1 slideBelow}.mouse-hint .mouse-point{height:4px;width:4px;background-color:#fff;position:absolute;left:50%;bottom:40%;border-radius:4px;transform-origin:50% 100%;transform:translate(-50%);animation:2.2s ease-in-out infinite jump;will-change:transform}@keyframes slideBelow{0%{transform:translateY(50px);opacity:0}100%{transform:translateX(0);opacity:1}}@keyframes jump{0%,20%,60%,to{transform:translate(-50%)translateY(0);height:4px;animation-timing-function:ease-in}40%,80%{transform:translate(-50%)translateY(8px);height:8px;animation-timing-function:ease-out}}</style><div class="hero text-light text-fade-in"><div class=hero-header><svg width="280" height="100" style="filter:drop-shadow(0 0 32px #4f2dda)" viewBox="0 0 66.067 20.526" xmlns="http://www.w3.org/2000/svg"><path d="m8.7933 13.184h3.3982l1.4263 1.6743q1.3146-1.0914 2.0216-2.6417.71934-1.5503.71934-3.3238.0-2.8401-1.7487-4.5765-1.7363-1.7487-4.6013-1.7487-1.4387.0-2.6913.5209-1.2526.5085-2.2324 1.5131-1.0914 1.1286-1.6743 2.5549-.58291 1.4263-.58291 2.9766.0 2.8029 1.7115 4.5889 1.7115 1.7859 4.3532 1.7859.5457.0 1.1286-.08682.59531-.08682 1.2402-.27285zm6.2012 7.3422-1.9844-2.2944q-1.0542.40928-2.034.60772-.97978.21084-1.9348.21084-4.1548.0-6.598-2.3812t-2.4433-6.4368q0-2.2076.78135-4.13.78135-1.9348 2.2448-3.3362 1.4139-1.3519 3.237-2.0588 1.8355-.70693 3.9315-.70693 4.0804.0 6.536 2.4061 2.4557 2.4061 2.4557 6.412.0 2.4681-.99219 4.5765t-2.8277 3.5223l3.0262 3.6091zm5.3578-13.692h2.6913l1.91 6.0027q.0124.03721.04961.14883.34726 1.1038.37207 1.6371.13643-.42168.34727-.89297.22324-.48369.5457-1.0294l3.9439-6.7345 1.9224 6.9329q.11162.38447.18604.79375.07441.40928.12402.94258.18604-.5209.37207-.94258.19844-.42168.38447-.73174l3.5595-6.1268h3.0262l-7.9747 12.489-1.9844-6.5732q-.11162-.34727-.19844-.74414-.07441-.40928-.13643-.90537-.27285.57051-.48369.99219t-.32246.59531l-3.9936 6.6353zm22.758 4.4648h6.0647q-.03721-1.1906-.74414-1.8728-.69453-.69453-1.8728-.69453-1.3395.0-2.2696.69453t-1.1782 1.8728zm5.9159 3.6835 1.9224 1.5007q-1.0294 1.3519-2.2324 1.972-1.203.62012-2.7657.62012-2.6169.0-4.2292-1.5751-1.6123-1.5875-1.6123-4.1672.0-3.0262 1.8479-4.9609 1.8604-1.9472 4.7253-1.9472 2.3937.0 3.8075 1.4883 1.4263 1.4759 1.4263 3.9688.0.21084-.0248.5457-.0124.32246-.04961.78135h-8.9669q0 1.5999.80615 2.5549.80615.94258 2.1456.94258.93018.0 1.7611-.44648.84336-.45889 1.4387-1.2774zm13.357 3.6091.89297-6.7593q.0248-.18604.03721-.38447.0124-.21084.0124-.60772.0-1.1534-.5581-1.7611-.55811-.62012-1.6247-.62012-1.6619.0-2.6045 1.079-.94258 1.0666-1.2278 3.2866l-.74414 5.7671h-2.6665l1.5503-11.757h2.5673l-.19844 1.4139q1.017-.93018 2.096-1.3767 1.0914-.44648 2.3192-.44648 1.8107.0 2.8153.95498 1.017.94258 1.017 2.6541.0.43408-.04961 1.017-.04961.57051-.14883 1.3395l-.81855 6.2012z" fill="#fff" stroke-linejoin="round" stroke-opacity=".7352" stroke-width="1.6"/></svg></div><div class=hero-content>Qwickly forging AGI, enhancing intelligence.</div><div class=hero-footer><div class=social-icons></div></div></div></div><main class="main home"><article class=post-entry><header class=entry-header><h2>Qwen2.5-1M: Deploy Your Own Qwen with Context Length up to 1M Tokens</h2></header><div class=entry-content><p>Tech Report HuggingFace ModelScope Qwen Chat HuggingFace Demo ModelScope Demo DISCORD
Introduction Two months after upgrading Qwen2.5-Turbo to support context length up to one million tokens, we are back with the open-source Qwen2.5-1M models and the corresponding inference framework support. Here’s what you can expect from this release:
Opensource Models: We’re releasing two new checkpoints, Qwen2.5-7B-Instruct-1M and Qwen2.5-14B-Instruct-1M, marking the first time we’ve upgraded our opensource Qwen models to handle 1M-token contexts....</p></div><footer class=entry-footer><span title='2025-01-27 00:00:03 +0800 +0800'>January 27, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1589 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen2.5-1M: Deploy Your Own Qwen with Context Length up to 1M Tokens" href=https://qwenlm.github.io/blog/qwen2.5-1m/></a></article><article class=post-entry><header class=entry-header><h2>Qwen2.5 VL! Qwen2.5 VL! Qwen2.5 VL!</h2></header><div class=entry-content><p>QWEN CHAT GITHUB HUGGING FACE MODELSCOPE DISCORD
We release Qwen2.5-VL, the new flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL. To try the latest model, feel free to visit Qwen Chat and choose Qwen2.5-VL-72B-Instruct. Also, we open both base and instruct models in 3 sizes, including 3B, 7B, and 72B, in both Hugging Face and ModelScope.
The key features include:
Understand things visually: Qwen2....</p></div><footer class=entry-footer><span title='2025-01-26 19:08:30 +0800 +0800'>January 26, 2025</span>&nbsp;·&nbsp;21 min&nbsp;·&nbsp;4364 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen2.5 VL! Qwen2.5 VL! Qwen2.5 VL!" href=https://qwenlm.github.io/blog/qwen2.5-vl/></a></article><article class=post-entry><header class=entry-header><h2>Global-batch load balance almost free lunch to improve your MoE LLM training</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DISCORD
Background The Mixture-of-Experts (MoEs) architecture has become a popular model-parameter-scale-up technique. Typically, one MoE layer consists of a router (often parameterized as one single Linear layer) and a group of experts (for transformer-based models, each expert is one feedforward layer). Given an input, only a subset of experts will be activated, and then their outputs will be aggregated based on the scores the router assigned....</p></div><footer class=entry-footer><span title='2025-01-21 00:00:03 +0800 +0800'>January 21, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;739 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Global-batch load balance almost free lunch to improve your MoE LLM training" href=https://qwenlm.github.io/blog/global-load-balance/></a></article><article class=post-entry><header class=entry-header><h2>Towards Effective Process Supervision in Mathematical Reasoning</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DISCORD
Introduction In recent years, Large Language Models (LLMs) have made remarkable advances in mathematical reasoning, yet they can make mistakes, such as miscalculations or logical errors, leading to wrong conclusions. Moreover, even when achieving correct final answers, these powerful models can still regularly make up plausible reasoning steps, where the final answers build upon flawed calculations or derivations, which undermine the reliability and trustworthiness of LLMs’ reasoning processes....</p></div><footer class=entry-footer><span title='2025-01-14 00:00:03 +0800 +0800'>January 14, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;741 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Towards Effective Process Supervision in Mathematical Reasoning" href=https://qwenlm.github.io/blog/qwen2.5-math-prm/></a></article><article class=post-entry><header class=entry-header><h2>QVQ: To See the World with Wisdom</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE KAGGLE DEMO DISCORD
Language and vision intertwine in the human mind, shaping how we perceive and understand the world around us. Our ability to reason is deeply rooted in both linguistic thought and visual memory - but what happens when we extend these capabilities to AI? Today’s large language models have demonstrated remarkable reasoning abilities, but we wondered: could they harness the power of visual understanding to reach new heights of cognitive capability?...</p></div><footer class=entry-footer><span title='2024-12-25 00:00:03 +0800 +0800'>December 25, 2024</span>&nbsp;·&nbsp;19 min&nbsp;·&nbsp;3874 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to QVQ: To See the World with Wisdom" href=https://qwenlm.github.io/blog/qvq-72b-preview/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://qwenlm.github.io/page/2/>«&nbsp;Prev&nbsp;</a>
<a class=next href=https://qwenlm.github.io/page/4/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>