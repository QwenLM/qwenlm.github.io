<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen2.5-Coder: Code More, Learn More! | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction In early April, we introduced CodeQwen1.5, which garnered significant attention from the community. Since then, we have been working to enhance the coding model. Today, we are excited to announce the release of the next generation of open-source coding models, Qwen2.5-Coder, and officially rename CodeQwen to Qwen-Coder. We think &ldquo;Coder&rdquo; is more human-like and agile, reflecting our vision of it becoming a true coding partner in the future."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/qwen2.5-coder/><link crossorigin=anonymous href=/assets/css/stylesheet.012512d6f1d6f320d85cff7ae2b89d136cc19960a4aa00adf35aaae57e557162.css integrity="sha256-ASUS1vHW8yDYXP964ridE2zBmWCkqgCt81qq5X5VcWI=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen2.5-coder/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen2.5-coder/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen2.5-Coder: Code More, Learn More!"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction In early April, we introduced CodeQwen1.5, which garnered significant attention from the community. Since then, we have been working to enhance the coding model. Today, we are excited to announce the release of the next generation of open-source coding models, Qwen2.5-Coder, and officially rename CodeQwen to Qwen-Coder. We think &ldquo;Coder&rdquo; is more human-like and agile, reflecting our vision of it becoming a true coding partner in the future."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/blog/qwen2.5-coder/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-09-19T00:00:02+08:00"><meta property="article:modified_time" content="2024-09-19T00:00:02+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen2.5-Coder: Code More, Learn More!"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction In early April, we introduced CodeQwen1.5, which garnered significant attention from the community. Since then, we have been working to enhance the coding model. Today, we are excited to announce the release of the next generation of open-source coding models, Qwen2.5-Coder, and officially rename CodeQwen to Qwen-Coder. We think &ldquo;Coder&rdquo; is more human-like and agile, reflecting our vision of it becoming a true coding partner in the future."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Qwen2.5-Coder: Code More, Learn More!","item":"https://qwenlm.github.io/blog/qwen2.5-coder/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen2.5-Coder: Code More, Learn More!","name":"Qwen2.5-Coder: Code More, Learn More!","description":"GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\nIntroduction In early April, we introduced CodeQwen1.5, which garnered significant attention from the community. Since then, we have been working to enhance the coding model. Today, we are excited to announce the release of the next generation of open-source coding models, Qwen2.5-Coder, and officially rename CodeQwen to Qwen-Coder. We think \u0026ldquo;Coder\u0026rdquo; is more human-like and agile, reflecting our vision of it becoming a true coding partner in the future.","keywords":[],"articleBody":" GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\nIntroduction In early April, we introduced CodeQwen1.5, which garnered significant attention from the community. Since then, we have been working to enhance the coding model. Today, we are excited to announce the release of the next generation of open-source coding models, Qwen2.5-Coder, and officially rename CodeQwen to Qwen-Coder. We think ‚ÄúCoder‚Äù is more human-like and agile, reflecting our vision of it becoming a true coding partner in the future. Qwen2.5-Coder is part of the Qwen2.5 series, available in three model sizes: 1.5B, 7B, and a 32B version (coming soon).\nThis update focuses on two main improvements: scaling up the code training data and enhancing coding capabilities while maintaining strong performance in other core areas like math and general tasks.\nüíª Code More: Qwen2.5-Coder builds on the strong Qwen2.5 and continues training on a larger scale of code data, including source code, text-code grounding data, and synthetic data, totaling 5.5 trillion tokens. This leads to significant improvements in code-related tasks.\nüìö Learn More: While enhancing coding abilities, we aimed to retain strengths in math and general capabilities from base model. Therefore, Qwen2.5-Coder incorporates additional data on mathematics and general abilities, providing a comprehensive foundation for real-world applications like Code Agent.\nQwen2.5-Coder: Base Models Qwen2.5-Coder supports up to 128K tokens of context, covers 92 programming languages, and has achieved remarkable improvements across various code-related evaluation tasks, including code generation, multi-programming code generation, code completion, and code repair. Notably, the open-source 7B version of Qwen2.5-Coder has even outperformed larger models like DeepSeek-Coder-V2-Lite and CodeStral-22B, making it one of the most powerful base code models available. Beyond code tasks, Qwen2.5-Coder also demonstrates competitive math capabilities in evaluations such as GSM8K and Math. For general tasks, evaluations on MMLU and ARC show that Qwen2.5-Coder has retained the general ability performance of Qwen2.5.\nQwen2.5-Coder-Instruct: Instruction-Tuned Models Building on Qwen2.5-Coder, we fine-tuned it with instruction data, creating Qwen2.5-Coder-Instruct. This instruction-tuned model not only further improves task performance but also demonstrates exceptional generalization across various benchmarks.\nQwen2.5-Coder-Instruct excels in several key areas:\nOutstanding Multi-programming Expert: We expanded the multi-language evaluations using McEval, covering more than 40 programming languages. The results show that Qwen2.5-Coder-Instruct performs remarkably well across many languages, including niche ones. Code Reasoning: We believe code reasoning is closely tied to general reasoning skills. We used CRUXEval as a benchmark, and the results show Qwen2.5-Coder-Instruct excels in code reasoning tasks. Interestingly, as code reasoning improves, the model‚Äôs ability to follow complex instructions also gets better, encouraging us to further explore how code can enhance general skills. Math Reasoning: Math and code are often discussed together: math is the foundation of code, and code is a key tool for math. Qwen2.5-Coder-Instruct shines in both code and math tasks, proven to be a ‚Äúscience student‚Äù. Model Math GSM8K GaoKao2023en OlympiadBench CollegeMath AIME24 DeepSeek-Coder-V2-Lite-Instruct 61.0 87.6 56.1 26.4 39.8 6.7 Qwen2.5-Coder-7B-Instruct 66.8 86.7 60.5 29.8 43.5 10.0 Basic capabilities: We also assessed the general capabilities, and the results indicate that Qwen2.5-Coder-Instruct maintains the advantages of Qwen2.5 in terms of general abilities. Model AMC23 MMLU-Pro MMLU IFEval CEval GPQA DeepSeek-Coder-V2-Lite-Instruct 40.4 42.5 60.6 38.6 60.1 27.6 Qwen2.5-Coder-7B-Instruct 42.5 45.6 68.7 58.6 61.4 35.6 License Qwen2.5-Coder is released under the Apache 2.0 license. We hope this increased openness will accelerate its application in code intelligence.\nWhat‚Äôs Next for Qwen2.5-Coder? We are preparing the 32B version of Qwen2.5-Coder, aiming to challenge proprietary models. Stay tuned‚Äîit‚Äôs coming soon! Additionally, we‚Äôre exploring powerful code-centric reasoning models to push the boundaries of code intelligence.\nCitation @article{hui2024qwen2, title={Qwen2. 5-Coder Technical Report}, author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others}, journal={arXiv preprint arXiv:2409.12186}, year={2024} } @article{yang2024qwen2, title={Qwen2 technical report}, author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others}, journal={arXiv preprint arXiv:2407.10671}, year={2024} } ","wordCount":"666","inLanguage":"en","datePublished":"2024-09-19T00:00:02+08:00","dateModified":"2024-09-19T00:00:02+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/blog/qwen2.5-coder/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen2.5-Coder: Code More, Learn More!</h1><div class=post-meta><span title='2024-09-19 00:00:02 +0800 +0800'>September 19, 2024</span>&nbsp;¬∑&nbsp;4 min&nbsp;¬∑&nbsp;666 words&nbsp;¬∑&nbsp;Qwen Team&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://qwenlm.github.io/zh/blog/qwen2.5-coder/>ÁÆÄ‰Ωì‰∏≠Êñá</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/coder-main.png#center width=70%></figure><p><a href=https://github.com/QwenLM/Qwen2.5-Coder class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/Qwen class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://huggingface.co/spaces/Qwen/Qwen2.5-Coder-7B-Instruct class="btn external" target=_blank>DEMO</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><h1 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h1><p>In early April, we introduced CodeQwen1.5, which garnered significant attention from the community. Since then, we have been working to enhance the coding model. Today, we are excited to announce the release of the next generation of open-source coding models, <strong>Qwen2.5-Coder</strong>, and officially rename CodeQwen to Qwen-Coder. We think &ldquo;Coder&rdquo; is more human-like and agile, reflecting our vision of it becoming a true coding partner in the future. Qwen2.5-Coder is part of the Qwen2.5 series, available in three model sizes: 1.5B, 7B, and a 32B version (coming soon).</p><p>This update focuses on two main improvements: scaling up the code training data and enhancing coding capabilities while maintaining strong performance in other core areas like math and general tasks.</p><p>üíª Code More: Qwen2.5-Coder builds on the strong Qwen2.5 and continues training on a larger scale of code data, including source code, text-code grounding data, and synthetic data, totaling 5.5 trillion tokens. This leads to significant improvements in code-related tasks.</p><p>üìö Learn More: While enhancing coding abilities, we aimed to retain strengths in math and general capabilities from base model. Therefore, Qwen2.5-Coder incorporates additional data on mathematics and general abilities, providing a comprehensive foundation for real-world applications like Code Agent.</p><h1 id=qwen25-coder-base-models>Qwen2.5-Coder: Base Models<a hidden class=anchor aria-hidden=true href=#qwen25-coder-base-models>#</a></h1><p>Qwen2.5-Coder supports up to 128K tokens of context, covers 92 programming languages, and has achieved remarkable improvements across various code-related evaluation tasks, including code generation, multi-programming code generation, code completion, and code repair. Notably, the open-source 7B version of Qwen2.5-Coder has even outperformed larger models like DeepSeek-Coder-V2-Lite and CodeStral-22B, making it one of the most powerful base code models available. Beyond code tasks, Qwen2.5-Coder also demonstrates competitive math capabilities in evaluations such as GSM8K and Math. For general tasks, evaluations on MMLU and ARC show that Qwen2.5-Coder has retained the general ability performance of Qwen2.5.</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/qwen2.5-coder-base.jpg#center width=100%></figure><h1 id=qwen25-coder-instruct-instruction-tuned-models>Qwen2.5-Coder-Instruct: Instruction-Tuned Models<a hidden class=anchor aria-hidden=true href=#qwen25-coder-instruct-instruction-tuned-models>#</a></h1><p>Building on Qwen2.5-Coder, we fine-tuned it with instruction data, creating Qwen2.5-Coder-Instruct. This instruction-tuned model not only further improves task performance but also demonstrates exceptional generalization across various benchmarks.</p><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/qwen2.5-coder-instruct.jpg#center width=100%></figure><p>Qwen2.5-Coder-Instruct excels in several key areas:</p><ol><li><strong>Outstanding Multi-programming Expert</strong>: We expanded the multi-language evaluations using McEval, covering more than 40 programming languages. The results show that Qwen2.5-Coder-Instruct performs remarkably well across many languages, including niche ones.</li></ol><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/mveval.jpg#center width=70%></figure><ol start=2><li><strong>Code Reasoning</strong>: We believe code reasoning is closely tied to general reasoning skills. We used CRUXEval as a benchmark, and the results show Qwen2.5-Coder-Instruct excels in code reasoning tasks. Interestingly, as code reasoning improves, the model&rsquo;s ability to follow complex instructions also gets better, encouraging us to further explore how code can enhance general skills.</li></ol><figure><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5/Qwen2.5-Coder/crux.jpg#center width=70%></figure><ol start=3><li><strong>Math Reasoning</strong>: Math and code are often discussed together: math is the foundation of code, and code is a key tool for math. Qwen2.5-Coder-Instruct shines in both code and math tasks, proven to be a &ldquo;science student&rdquo;.</li></ol><table><thead><tr><th><strong>Model</strong></th><th><strong>Math</strong></th><th><strong>GSM8K</strong></th><th><strong>GaoKao2023en</strong></th><th><strong>OlympiadBench</strong></th><th><strong>CollegeMath</strong></th><th><strong>AIME24</strong></th></tr></thead><tbody><tr><td>DeepSeek-Coder-V2-Lite-Instruct</td><td>61.0</td><td><strong>87.6</strong></td><td>56.1</td><td>26.4</td><td>39.8</td><td>6.7</td></tr><tr><td>Qwen2.5-Coder-7B-Instruct</td><td><strong>66.8</strong></td><td>86.7</td><td><strong>60.5</strong></td><td><strong>29.8</strong></td><td><strong>43.5</strong></td><td><strong>10.0</strong></td></tr></tbody></table><ol start=4><li><strong>Basic capabilities</strong>: We also assessed the general capabilities, and the results indicate that Qwen2.5-Coder-Instruct maintains the advantages of Qwen2.5 in terms of general abilities.</li></ol><table><thead><tr><th><strong>Model</strong></th><th><strong>AMC23</strong></th><th><strong>MMLU-Pro</strong></th><th><strong>MMLU</strong></th><th><strong>IFEval</strong></th><th><strong>CEval</strong></th><th><strong>GPQA</strong></th></tr></thead><tbody><tr><td>DeepSeek-Coder-V2-Lite-Instruct</td><td>40.4</td><td>42.5</td><td>60.6</td><td>38.6</td><td>60.1</td><td>27.6</td></tr><tr><td>Qwen2.5-Coder-7B-Instruct</td><td><strong>42.5</strong></td><td><strong>45.6</strong></td><td><strong>68.7</strong></td><td><strong>58.6</strong></td><td><strong>61.4</strong></td><td><strong>35.6</strong></td></tr></tbody></table><h1 id=license>License<a hidden class=anchor aria-hidden=true href=#license>#</a></h1><p>Qwen2.5-Coder is released under the Apache 2.0 license. We hope this increased openness will accelerate its application in code intelligence.</p><h1 id=whats-next-for-qwen25-coder>What&rsquo;s Next for Qwen2.5-Coder?<a hidden class=anchor aria-hidden=true href=#whats-next-for-qwen25-coder>#</a></h1><p>We are preparing the 32B version of Qwen2.5-Coder, aiming to challenge proprietary models. Stay tuned‚Äîit&rsquo;s coming soon! Additionally, we&rsquo;re exploring powerful code-centric reasoning models to push the boundaries of code intelligence.</p><h1 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h1><pre tabindex=0><code>@article{hui2024qwen2,
  title={Qwen2. 5-Coder Technical Report},
  author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
  journal={arXiv preprint arXiv:2409.12186},
  year={2024}
}
@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}
</code></pre></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>