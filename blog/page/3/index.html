<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=http://qwenlm.github.io/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.09368503f3694f7ead33b6239bc528583b3431b7837d0401ce3b2c7fd4b0f5f1.css integrity="sha256-CTaFA/NpT36tM7Yjm8UoWDs0MbeDfQQBzjssf9Sw9fE=" rel="preload stylesheet" as=style><link rel=icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=icon type=image/png sizes=16x16 href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=icon type=image/png sizes=32x32 href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg%22><link rel=apple-touch-icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=mask-icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://qwenlm.github.io/blog/index.xml><link rel=alternate hreflang=en href=http://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=http://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="http://qwenlm.github.io/blog/"><meta property="og:image" content="http://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"http://qwenlm.github.io/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><svg width="25" height="24" viewBox="0 0 25 24" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><linearGradient x1="76.7202373%" y1="41.6070847%" x2="18.306123%" y2="65.5065085%" id="linearGradient-9_1k7ha4jv-1"><stop stop-color="#797beb" offset="0"/><stop stop-color="#373080" offset="100%"/></linearGradient></defs><g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="_编组-7" fill="url(#linearGradient-9_1k7ha4jv-1)"><path d="M12.2746711.0C12.5125388.0 12.7434104.12583746 12.8693403.33556656l1.3852293 2.3769298h6.1425827C20.63502 2.71249636 20.8658915 2.83833382 20.9918215 3.04806292l1.7420308 2.97815322C22.8597822 6.23594524 22.8597822 6.5016021 22.7338523 6.7113312L22.6988718 6.76725896C22.6708873 6.80920478 22.6359068 6.8511506 22.5939301 6.88610545L21.2156969 9.24905331l3.050303 5.24322749L24.3429571 14.6041363C24.4339065 14.8138654 24.4548948 15.0795223 24.3919298 15.2682785l-1.6021086 2.7404602C22.6638912 18.2184678 22.4400158 18.3443053 22.195152 18.3443053L19.4176972 18.3582872 16.353402 23.6504515C16.227472 23.8601806 16.0035966 23.9860181 15.7587328 23.9860181L12.2886633 24H12.2396906C12.0158151 23.9860181 11.7989358 23.8601806 11.6869981 23.6644334l-1.490171-2.551704H4.13120166C4.0822289 21.1267113 4.04025225 21.1267113 3.9912795 21.1267113 3.75341183 21.1267113 3.52254028 21.0008739 3.39661034 20.7911448L1.79450165 18.0506845C1.66857171 17.8479464 1.66857171 17.5892805 1.79450165 17.3725604l1.37823324-2.3909117L.0944474553 9.69647539c-.1259299404-.20273813-.1259299404-.46140402.0-.678124089999999L1.80849387 6.02621614c.11193772-.2097291.34280928-.33556656.59466916-.33556656C2.466128 5.67666764 2.51510075 5.69064958 2.56407351 5.70463152H5.40449327L8.44080406.46140402C8.45479628.4194582 8.46179238.38450335 8.48278071.35653947L8.49677292.33556656C8.62270286.12583746 8.84657831.0 9.09144209.0H12.2816672 12.2746711zM9.04246933.72706088 5.74730256 6.41071949H2.3751786L8.93752771 17.6871541H5.59338819l-1.61610091 2.789397H10.5606247l1.6790659 2.8942616 6.5623491-11.3043985 1.6790659 2.8802797L23.7203035 14.9327119 20.4181406 9.24905331l1.6650737-2.8662977L9.00049268 6.39673755 10.6795586 3.51645791 9.04946544.72706088H9.04246933zM16.1435187 9.82930382 12.2187023 16.5755899 8.2938858 9.82930382h7.8496329z" id="_形状"/></g></g></svg></a><div class=logo-switches></div></div><ul id=menu><li><a href=/resources title=Resources><span>Resources</span></a></li><li><a href=/blog/ title=Blog><span class=active>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=http://qwenlm.github.io/zh/blog/>简体中文</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Generalizing an LLM from 8k to 1M Context using Qwen-Agent</h2></header><div class=entry-content><p>We’ve created an agent using Qwen2 models with an 8k context size to understand documents with 1M tokens, surpassing RAG and native long-context models. This agent was also used to generate data for training new long-context Qwen models.</p></div><footer class=entry-footer><span title='2024-06-06 11:59:59 +0800 +0800'>June 6, 2024</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1412 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Generalizing an LLM from 8k to 1M Context using Qwen-Agent" href=http://qwenlm.github.io/blog/qwen-agent-2405/></a></article><article class=post-entry><header class=entry-header><h2>Notes on Qwen-Max-0428</h2></header><div class=entry-content><p>API DEMO DISCORD
Previously, we opensourced a series of Qwen1.5 model ranging from 0.5 to 110 billion parameters. Now, we release a larger model, Qwen-Max-0428. Qwen-Max-0428 is an instruction-tuned model for chat service. Very recently, it is available via Chatbot Arena and it has now become the top-10 in the leaderboard. Furthermore, our evaluation of MT-Bench also demonstrates that the new model outperforms our previous largest model Qwen1.5-110B-Chat.
Models MT-Bench Arena Qwen1....</p></div><footer class=entry-footer><span title='2024-05-11 18:10:00 +0800 +0800'>May 11, 2024</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;190 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Notes on Qwen-Max-0428" href=http://qwenlm.github.io/blog/qwen-max-0428/></a></article><article class=post-entry><header class=entry-header><h2>Qwen1.5-110B: The First 100B+ Model of the Qwen1.5 Series</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction Recently we have witnessed a burst of large-scale models with over 100 billion parameters in the opensource community. These models have demonstrated remarkable performance in both benchmark evaluation and chatbot arena. Today, we release the first 100B+ model of the Qwen1.5 series, Qwen1.5-110B, which achieves comparable performance with Meta-Llama3-70B in the base model evaluation, and outstanding performance in the chat evaluation, including MT-Bench and AlpacaEval 2....</p></div><footer class=entry-footer><span title='2024-04-25 13:33:00 +0800 +0800'>April 25, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;499 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen1.5-110B: The First 100B+ Model of the Qwen1.5 Series" href=http://qwenlm.github.io/blog/qwen1.5-110b/></a></article><article class=post-entry><header class=entry-header><h2>Code with CodeQwen1.5</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs....</p></div><footer class=entry-footer><span title='2024-04-16 13:33:00 +0800 +0800'>April 16, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1176 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Code with CodeQwen1.5" href=http://qwenlm.github.io/blog/codeqwen1.5/></a></article><article class=post-entry><header class=entry-header><h2>Qwen1.5-32B: Fitting the Capstone of the Qwen1.5 Language Model Series</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction The open-source community has long sought a model that strikes an ideal balance between performance, efficiency, and memory footprint. Despite the emergence of cutting-edge models like Qwen1.5-72B and DBRX, the models have faced persistent challenges such as large memory consumption, slow inference speed, and substantial finetuning costs.
A growing consensus within the field now points to a model with approximately 30 billion parameters as the optimal “sweet spot” for achieving both strong performance and manageable resource requirements....</p></div><footer class=entry-footer><span title='2024-04-02 13:33:00 +0800 +0800'>April 2, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;663 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen1.5-32B: Fitting the Capstone of the Qwen1.5 Language Model Series" href=http://qwenlm.github.io/blog/qwen1.5-32b/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=http://qwenlm.github.io/blog/page/2/>«&nbsp;Prev&nbsp;</a>
<a class=next href=http://qwenlm.github.io/blog/page/4/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=http://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>