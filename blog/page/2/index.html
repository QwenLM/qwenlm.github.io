<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=http://qwenlm.github.io/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.09368503f3694f7ead33b6239bc528583b3431b7837d0401ce3b2c7fd4b0f5f1.css integrity="sha256-CTaFA/NpT36tM7Yjm8UoWDs0MbeDfQQBzjssf9Sw9fE=" rel="preload stylesheet" as=style><link rel=icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=icon type=image/png sizes=16x16 href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=icon type=image/png sizes=32x32 href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg%22><link rel=apple-touch-icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><link rel=mask-icon href=https://acd-assets.alicdn.com/acd_work/tongyi/assets/logo.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=http://qwenlm.github.io/blog/index.xml><link rel=alternate hreflang=en href=http://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=http://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="http://qwenlm.github.io/blog/"><meta property="og:image" content="http://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"http://qwenlm.github.io/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><svg width="25" height="24" viewBox="0 0 25 24" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><linearGradient x1="76.7202373%" y1="41.6070847%" x2="18.306123%" y2="65.5065085%" id="linearGradient-9_1k7ha4jv-1"><stop stop-color="#797beb" offset="0"/><stop stop-color="#373080" offset="100%"/></linearGradient></defs><g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="_ç¼–ç»„-7" fill="url(#linearGradient-9_1k7ha4jv-1)"><path d="M12.2746711.0C12.5125388.0 12.7434104.12583746 12.8693403.33556656l1.3852293 2.3769298h6.1425827C20.63502 2.71249636 20.8658915 2.83833382 20.9918215 3.04806292l1.7420308 2.97815322C22.8597822 6.23594524 22.8597822 6.5016021 22.7338523 6.7113312L22.6988718 6.76725896C22.6708873 6.80920478 22.6359068 6.8511506 22.5939301 6.88610545L21.2156969 9.24905331l3.050303 5.24322749L24.3429571 14.6041363C24.4339065 14.8138654 24.4548948 15.0795223 24.3919298 15.2682785l-1.6021086 2.7404602C22.6638912 18.2184678 22.4400158 18.3443053 22.195152 18.3443053L19.4176972 18.3582872 16.353402 23.6504515C16.227472 23.8601806 16.0035966 23.9860181 15.7587328 23.9860181L12.2886633 24H12.2396906C12.0158151 23.9860181 11.7989358 23.8601806 11.6869981 23.6644334l-1.490171-2.551704H4.13120166C4.0822289 21.1267113 4.04025225 21.1267113 3.9912795 21.1267113 3.75341183 21.1267113 3.52254028 21.0008739 3.39661034 20.7911448L1.79450165 18.0506845C1.66857171 17.8479464 1.66857171 17.5892805 1.79450165 17.3725604l1.37823324-2.3909117L.0944474553 9.69647539c-.1259299404-.20273813-.1259299404-.46140402.0-.678124089999999L1.80849387 6.02621614c.11193772-.2097291.34280928-.33556656.59466916-.33556656C2.466128 5.67666764 2.51510075 5.69064958 2.56407351 5.70463152H5.40449327L8.44080406.46140402C8.45479628.4194582 8.46179238.38450335 8.48278071.35653947L8.49677292.33556656C8.62270286.12583746 8.84657831.0 9.09144209.0H12.2816672 12.2746711zM9.04246933.72706088 5.74730256 6.41071949H2.3751786L8.93752771 17.6871541H5.59338819l-1.61610091 2.789397H10.5606247l1.6790659 2.8942616 6.5623491-11.3043985 1.6790659 2.8802797L23.7203035 14.9327119 20.4181406 9.24905331l1.6650737-2.8662977L9.00049268 6.39673755 10.6795586 3.51645791 9.04946544.72706088H9.04246933zM16.1435187 9.82930382 12.2187023 16.5755899 8.2938858 9.82930382h7.8496329z" id="_å½¢çŠ¶"/></g></g></svg></a><div class=logo-switches></div></div><ul id=menu><li><a href=/resources title=Resources><span>Resources</span></a></li><li><a href=/blog/ title=Blog><span class=active>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=http://qwenlm.github.io/zh/blog/>ç®€ä½“ä¸­æ–‡</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Qwen2-VL: To See the World More Clearly</h2></header><div class=entry-content><p>DEMO GITHUB HUGGING FACE MODELSCOPE API DISCORD
After a yearâ€™s relentless efforts, today we are thrilled to release Qwen2-VL! Qwen2-VL is the latest version of the vision language models based on Qwen2 in the Qwen model familities. Compared with Qwen-VL, Qwen2-VL has the capabilities of:
SoTA understanding of images of various resolution & ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.
Understanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc....</p></div><footer class=entry-footer><span title='2024-08-29 00:24:00 +0800 +0800'>August 29, 2024</span>&nbsp;Â·&nbsp;17 min&nbsp;Â·&nbsp;3569 words&nbsp;Â·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen2-VL: To See the World More Clearly" href=http://qwenlm.github.io/blog/qwen2-vl/></a></article><article class=post-entry><header class=entry-header><h2>Qwen2-Audio: Chat with Your Voice!</h2></header><div class=entry-content><p>DEMO PAPER GITHUB HUGGING FACE MODELSCOPE DISCORD
To achieve the objective of building an AGI system, the model should be capable of understanding information from different modalities. Thanks to the rapid development of large language models, LLMs are now capable of understanding language and reasoning. Previously we have taken a step forward to extend our LLM, i.e., Qwen, to more modalities, including vision and audio, and built Qwen-VL and Qwen-Audio. Today, we release Qwen2-Audio, the next version of Qwen-Audio, which is capable of accepting audio and text inputs and generating text outputs....</p></div><footer class=entry-footer><span title='2024-08-09 16:18:19 +0800 +0800'>August 9, 2024</span>&nbsp;Â·&nbsp;10 min&nbsp;Â·&nbsp;1999 words&nbsp;Â·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen2-Audio: Chat with Your Voice!" href=http://qwenlm.github.io/blog/qwen2-audio/></a></article><article class=post-entry><header class=entry-header><h2>Introducing Qwen2-Math</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DISCORD
ðŸš¨ This model mainly supports English. We will release bilingual (English and Chinese) math models soon. Introduction Over the past year, we have dedicated significant effort to researching and enhancing the reasoning capabilities of large language models, with a particular focus on their ability to solve arithmetic and mathematical problems. Today, we are delighted to introduce a series of math-specific large language models of our Qwen2 series, Qwen2-Math and Qwen2-Math-Instruct-1....</p></div><footer class=entry-footer><span title='2024-08-08 00:00:00 +0800 +0800'>August 8, 2024</span>&nbsp;Â·&nbsp;28 min&nbsp;Â·&nbsp;5758 words&nbsp;Â·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Introducing Qwen2-Math" href=http://qwenlm.github.io/blog/qwen2-math/></a></article><article class=post-entry><header class=entry-header><h2>Hello Qwen2</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction After months of efforts, we are pleased to announce the evolution from Qwen1.5 to Qwen2. This time, we bring to you:
Pretrained and instruction-tuned models of 5 sizes, including Qwen2-0.5B, Qwen2-1.5B, Qwen2-7B, Qwen2-57B-A14B, and Qwen2-72B; Having been trained on data in 27 additional languages besides English and Chinese; State-of-the-art performance in a large number of benchmark evaluations; Significantly improved performance in coding and mathematics; Extended context length support up to 128K tokens with Qwen2-7B-Instruct and Qwen2-72B-Instruct....</p></div><footer class=entry-footer><span title='2024-06-07 00:00:00 +0800 +0800'>June 7, 2024</span>&nbsp;Â·&nbsp;15 min&nbsp;Â·&nbsp;3119 words&nbsp;Â·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Hello Qwen2" href=http://qwenlm.github.io/blog/qwen2/></a></article><article class=post-entry><header class=entry-header><h2>Generalizing an LLM from 8k to 1M Context using Qwen-Agent</h2></header><div class=entry-content><p>Weâ€™ve created an agent using Qwen2 models with an 8k context size to understand documents with 1M tokens, surpassing RAG and native long-context models. This agent was also used to generate data for training new long-context Qwen models.</p></div><footer class=entry-footer><span title='2024-06-06 11:59:59 +0800 +0800'>June 6, 2024</span>&nbsp;Â·&nbsp;7 min&nbsp;Â·&nbsp;1412 words&nbsp;Â·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Generalizing an LLM from 8k to 1M Context using Qwen-Agent" href=http://qwenlm.github.io/blog/qwen-agent-2405/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=http://qwenlm.github.io/blog/>Â«&nbsp;Prev&nbsp;</a>
<a class=next href=http://qwenlm.github.io/blog/page/3/>Next&nbsp;&nbsp;Â»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=http://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>