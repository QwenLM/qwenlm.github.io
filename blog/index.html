<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | Qwen</title><meta name=keywords content><meta name=description content="Blog - Qwen"><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.4f62259998ff7b98600586086c11b90753ca941d3fefd46d058f5df6a9fa05f4.css integrity="sha256-T2IlmZj/e5hgBYYIbBG5B1PKlB0/79RtBY9d9qn6BfQ=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://qwenlm.github.io/blog/index.xml><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Blog"><meta property="og:description" content="Qwen"><meta property="og:type" content="website"><meta property="og:url" content="https://qwenlm.github.io/blog/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="Qwen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span class=active>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=https://qwenlm.github.io/zh/blog/>简体中文</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Qwen-Image: Crafting with Native Text Rendering</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
We are thrilled to release Qwen-Image, a 20B MMDiT image foundation model that achieves significant advances in complex text rendering and precise image editing. To try the latest model, feel free to visit Qwen Chat and choose “Image Generation”.
The key features include:
Superior Text Rendering: Qwen-Image excels at complex text rendering, including multi-line layouts, paragraph-level semantics, and fine-grained details. It supports both alphabetic languages (e....</p></div><footer class=entry-footer><span title='2025-08-04 22:08:30 +0800 +0800'>August 4, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1229 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen-Image: Crafting with Native Text Rendering" href=https://qwenlm.github.io/blog/qwen-image/></a></article><article class=post-entry><header class=entry-header><h2>GSPO: Towards Scalable Reinforcement Learning for Language Models</h2></header><div class=entry-content><p>PAPER DISCORD
Introduction Reinforcement Learning (RL) has emerged as a pivotal paradigm for scaling language models and enhancing their deep reasoning and problem-solving capabilities. To scale RL, the foremost prerequisite is maintaining stable and robust training dynamics. However, we observe that existing RL algorithms (such as GRPO) exhibit severe instability issues during long training and lead to irreversible model collapse, hindering further performance improvements with increased compute.
To enable successful RL scaling, we propose the Group Sequence Policy Optimization (GSPO) algorithm....</p></div><footer class=entry-footer><span title='2025-07-27 15:00:00 +0800 +0800'>July 27, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;916 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to GSPO: Towards Scalable Reinforcement Learning for Language Models" href=https://qwenlm.github.io/blog/gspo/></a></article><article class=post-entry><header class=entry-header><h2>Qwen-MT: Where Speed Meets Smart Translation</h2></header><div class=entry-content><p>DEMO API DISCORD
Introduction Here we introduce the latest update of Qwen-MT (qwen-mt-turbo) via Qwen API. This update builds upon the powerful Qwen3, leveraging trillions multilingual and translation tokens to comprehensively enhance the model’s multilingual understanding and translation capabilities. By integrating reinforcement learning techniques, the model achieves significant improvements in translation accuracy and linguistic fluency.
Key Features:
Multilingual Support for 92 Languages: Qwen-MT enables high-quality translation across 92 major official languages and prominent dialects, covering over 95% of the global population to meet diverse cross-lingual communication needs....</p></div><footer class=entry-footer><span title='2025-07-24 22:00:00 +0800 +0800'>July 24, 2025</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1220 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen-MT: Where Speed Meets Smart Translation" href=https://qwenlm.github.io/blog/qwen-mt/></a></article><article class=post-entry><header class=entry-header><h2>Qwen3-Coder: Agentic Coding in the World</h2></header><div class=entry-content><p>GITHUB HUGGING FACE MODELSCOPE DISCORD
Today, we’re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we’re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4....</p></div><footer class=entry-footer><span title='2025-07-22 21:00:00 +0800 +0800'>July 22, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1000 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Qwen3-Coder: Agentic Coding in the World" href=https://qwenlm.github.io/blog/qwen3-coder/></a></article><article class=post-entry><header class=entry-header><h2>Time to Speak Some Dialects, Qwen-TTS!</h2></header><div class=entry-content><p>API DISCORD
Introduction Here we introduce the latest update of Qwen-TTS (qwen-tts-latest or qwen-tts-2025-05-22) through Qwen API . Trained on a large-scale dataset encompassing over millions of hours of speech, Qwen-TTS achieves human-level naturalness and expressiveness. Notably, Qwen-TTS automatically adjusts prosody, pacing, and emotional inflections in response to the input text. Notably, Qwen-TTS supports the generation of 3 Chinese dialects, including Pekingese, Shanghainese, and Sichuanese.
As of now, Qwen-TTS supports 7 Chinese-English bilingual voices, including Cherry, Ethan, Chelsie, Serena, Dylan (Pekingese), Jada (Shanghainese) and Sunny (Sichuanese)....</p></div><footer class=entry-footer><span title='2025-06-27 15:01:30 +0800 +0800'>June 27, 2025</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;537 words&nbsp;·&nbsp;Qwen Team</footer><a class=entry-link aria-label="post link to Time to Speak Some Dialects, Qwen-TTS!" href=https://qwenlm.github.io/blog/qwen-tts/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://qwenlm.github.io/blog/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>