<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Qwen3-Coder: Agentic Coding in the World | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE DISCORD
Today, we&rsquo;re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we&rsquo;re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/qwen3-coder/><link crossorigin=anonymous href=/assets/css/stylesheet.4f62259998ff7b98600586086c11b90753ca941d3fefd46d058f5df6a9fa05f4.css integrity="sha256-T2IlmZj/e5hgBYYIbBG5B1PKlB0/79RtBY9d9qn6BfQ=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/qwen3-coder/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/qwen3-coder/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Qwen3-Coder: Agentic Coding in the World"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE DISCORD
Today, we&rsquo;re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we&rsquo;re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/blog/qwen3-coder/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-07-22T21:00:00+08:00"><meta property="article:modified_time" content="2025-07-22T21:00:00+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Qwen3-Coder: Agentic Coding in the World"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE DISCORD
Today, we&rsquo;re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we&rsquo;re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Qwen3-Coder: Agentic Coding in the World","item":"https://qwenlm.github.io/blog/qwen3-coder/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Qwen3-Coder: Agentic Coding in the World","name":"Qwen3-Coder: Agentic Coding in the World","description":"GITHUB HUGGING FACE MODELSCOPE DISCORD\nToday, we\u0026rsquo;re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we\u0026rsquo;re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4.","keywords":[],"articleBody":"GITHUB HUGGING FACE MODELSCOPE DISCORD\nToday, we’re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we’re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4.\nAlongside the model, we’re also open-sourcing a command-line tool for agentic coding: Qwen Code. Forked from Gemini Code, Qwen Code has been adapted with customized prompts and function calling protocols to fully unleash the capabilities of Qwen3-Coder on agentic coding tasks. Qwen3-Coder works seamlessly with the community’s best developer tools. As a foundation model, we hope it can be used anywhere across the digital world — Agentic Coding in the World!\nQwen3-Coder Pre-Training There’s still room to scale in pretraining—and with Qwen3-Coder, we’re advancing along multiple dimensions to strengthen the model’s core capabilities:\nScaling Tokens: 7.5T tokens (70% code ratio), excelling in coding while preserving general and math abilities. Scaling Context: Natively supports 256K context and can be extended up to 1M with YaRN, optimized for repo-scale and dynamic data (e.g., Pull Requests) to empower Agentic Coding. Scaling Synthetic Data: Leveraged Qwen2.5-Coder to clean and rewrite noisy data, significantly improving overall data quality. Post-Training Scaling Code RL: Hard to Solve, Easy to Verify Unlike the prevailing focus on competitive-level code generation in the community, we believe all code tasks are naturally well-suited for execution-driven large-scale reinforcement learning. That’s why we scaled up Code RL training on a broader set of real-world coding tasks. By automatically scaling test cases of diversity coding tasks, we created high-quality training instances and successfully unlocked the full potential of reinforcement learning. It not only significantly boosted code execution success rates, but also brought gains to other tasks. This encourages us to keep exploring hard-to-solve, easy-to-verify tasks as fertile ground for large-scale reinforcement learning. Scaling Long-Horizon RL In real-world software engineering tasks like SWE-Bench, Qwen3-Coder must engage in multi-turn interaction with the environment, involving planning, using tools, receiving feedback, and making decisions. In the post-training phase of Qwen3-Coder, we introduced long-horizon RL (Agent RL) to encourage the model to solve real-world tasks through multi-turn interactions using tools. The key challenge of Agent RL lies in environment scaling. To address this, we built a scalable system capable of running 20,000 independent environments in parallel, leveraging Alibaba Cloud’s infrastructure. The infrastructure provides the necessary feedback for large-scale reinforcement learning and supports evaluation at scale. As a result, Qwen3-Coder achieves state-of-the-art performance among open-source models on SWE-Bench Verified without test-time scaling.\nCode with Qwen3-Coder Qwen Code Qwen Code is a research-purpose CLI tool adapted from Gemini CLI, with enhanced parser and tool support for Qwen-Coder models.\nMake sure you have installed nodejs 20+:\nYou could install it via the following commands:\ncurl -qL https://www.npmjs.com/install.sh | sh Then install Qwen code via npm manager:\nnpm i -g @qwen-code/qwen-code The other way is to install from the source:\ngit clone https://github.com/QwenLM/qwen-code.git cd qwen-code \u0026\u0026 npm install \u0026\u0026 npm install -g Qwen Code supports the OpenAI SDK when calling LLMs, and you can export the following environment variables or simply put them under the .envfile.\nexport OPENAI_API_KEY=\"your_api_key_here\" export OPENAI_BASE_URL=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\" export OPENAI_MODEL=\"qwen3-coder-plus\" Now enjoy your vibe coding with Qwen-Code and Qwen, by simply typing: qwen!\nClaude Code In addition to Qwen Code, you can now use Qwen3‑Coder with Claude Code. Simply request an API key on Alibaba Cloud Model Studio platform and install Claude Code to start coding.\nnpm install -g @anthropic-ai/claude-code We have provided two entrypoints for seamlessly experiencing coding with Qwen3-Coder.\nOptional 1: Claude Code proxy API export ANTHROPIC_BASE_URL=https://dashscope-intl.aliyuncs.com/api/v2/apps/claude-code-proxy export ANTHROPIC_AUTH_TOKEN=your-dashscope-apikey Then you should be able to use Claude Code with Qwen3-Coder!\nOptional 2: claude-code-config npm package for router customization claude-code-router aims for customizing different backend models for Claude Code. The dashscope team also provide a convenient config npm extension, namely claude-code-config, that provides default configuration for claude-code-router with DashScope support. Run installation:\nnpm install -g @musistudio/claude-code-router npm install -g @dashscope-js/claude-code-config and then run configuration:\nccr-dashscope The command will automatically generate the config json files and plugin directories for ccr. (You could also manually adjust these under ~/.claude-code-router/config.json and ~/.claude-code-router/plugins/ ) Start using claude code via ccr:\nccr code Cline Configure the Qwen3-Coder-480B-A35B-Instruct to cline ‒ Go to the Cline configuration settings ‒ For API Provider, select ‘OpenAI Compatible’ ‒ For the OpenAI Compatible API Key, enter the key obtained from Dashscope ‒ Check ‘Use custom base URL’ and enter: https://dashscope-intl.aliyuncs.com/compatible-mode/v1 ‒ Enter qwen3-coder-plus\nUse Cases Example: Physics-Based Chimney Demolition Simulation with Controlled Explosion\rNext\rExample: Qwen with Cline\rNext\rExample: Qwen Chat Web Dev\rNext\rExample: Testing Your WPM with a Famous Quote\rNext\rExample: Bouncing Ball in Rotation Hypercube\rNext\rExample: Solar System Simulation\rNext\rExample: DUET Game\rNext\rAPI You can directly access the API of Qwen3-Coder through Alibaba Cloud Model Studio. Here is a demonstration of how to use this model with the Qwen API.\nimport os from openai import OpenAI # Create client - using intl URL for users outside of China # If you are in mainland China, use the following URL: # \"https://dashscope.aliyuncs.com/compatible-mode/v1\" client = OpenAI( api_key=os.getenv(\"DASHSCOPE_API_KEY\"), base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\", ) prompt = \"Help me create a web page for an online bookstore.\" # Send request to qwen3-coder-plus model completion = client.chat.completions.create( model=\"qwen3-coder-plus\", messages=[ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": prompt} ], ) # Print the response print(completion.choices[0].message.content.strip()) Further Work We are still actively working to improve the performance of our Coding Agent, aiming for it to take on more complex and tedious tasks in software engineering, thereby freeing up human productivity. More model sizes of Qwen3-Coder are on the way, delivering strong performance while reducing deployment costs. Additionally, we are actively exploring whether the Coding Agent can achieve self-improvement—an exciting and inspiring direction.\n","wordCount":"1000","inLanguage":"en","datePublished":"2025-07-22T21:00:00+08:00","dateModified":"2025-07-22T21:00:00+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/blog/qwen3-coder/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://chat.qwen.ai title="Try Qwen Chat"><span>Try Qwen Chat</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Qwen3-Coder: Agentic Coding in the World</h1><div class=post-meta><span title='2025-07-22 21:00:00 +0800 +0800'>July 22, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;1000 words&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://qwenlm.github.io/zh/blog/qwen3-coder/>简体中文</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://github.com/QwenLM/Qwen3-Coder class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/Qwen class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><p>Today, we&rsquo;re announcing Qwen3-Coder, our most agentic code model to date. Qwen3-Coder is available in multiple sizes, but we&rsquo;re excited to introduce its most powerful variant first: Qwen3-Coder-480B-A35B-Instruct — a 480B-parameter Mixture-of-Experts model with 35B active parameters which supports the context length of 256K tokens natively and 1M tokens with extrapolation methods, offering exceptional performance in both coding and agentic tasks. Qwen3-Coder-480B-A35B-Instruct sets new state-of-the-art results among open models on Agentic Coding, Agentic Browser-Use, and Agentic Tool-Use, comparable to Claude Sonnet 4.</p><div align=center><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3-coder-main.jpg alt width=800></div><p>Alongside the model, we&rsquo;re also open-sourcing a command-line tool for agentic coding: Qwen Code. Forked from Gemini Code, Qwen Code has been adapted with customized prompts and function calling protocols to fully unleash the capabilities of Qwen3-Coder on agentic coding tasks. Qwen3-Coder works seamlessly with the community’s best developer tools. As a foundation model, we hope it can be used anywhere across the digital world — Agentic Coding in the World!</p><h2 id=qwen3-coder>Qwen3-Coder<a hidden class=anchor aria-hidden=true href=#qwen3-coder>#</a></h2><h3 id=pre-training>Pre-Training<a hidden class=anchor aria-hidden=true href=#pre-training>#</a></h3><p>There’s still room to scale in pretraining—and with Qwen3-Coder, we’re advancing along multiple dimensions to strengthen the model’s core capabilities:</p><ul><li>Scaling Tokens: 7.5T tokens (70% code ratio), excelling in coding while preserving general and math abilities.</li><li>Scaling Context: Natively supports 256K context and can be extended up to 1M with YaRN, optimized for repo-scale and dynamic data (e.g., Pull Requests) to empower Agentic Coding.</li><li>Scaling Synthetic Data: Leveraged Qwen2.5-Coder to clean and rewrite noisy data, significantly improving overall data quality.</li></ul><h3 id=post-training>Post-Training<a hidden class=anchor aria-hidden=true href=#post-training>#</a></h3><h4 id=scaling-code-rl-hard-to-solve-easy-to-verify>Scaling Code RL: Hard to Solve, Easy to Verify<a hidden class=anchor aria-hidden=true href=#scaling-code-rl-hard-to-solve-easy-to-verify>#</a></h4><div align=center><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/coderl.png alt width=800></div>Unlike the prevailing focus on competitive-level code generation in the community, we believe all code tasks are naturally well-suited for execution-driven large-scale reinforcement learning. That’s why we scaled up Code RL training on a broader set of real-world coding tasks. By automatically scaling test cases of diversity coding tasks, we created high-quality training instances and successfully unlocked the full potential of reinforcement learning. It not only significantly boosted code execution success rates, but also brought gains to other tasks. This encourages us to keep exploring hard-to-solve, easy-to-verify tasks as fertile ground for large-scale reinforcement learning.<h4 id=scaling-long-horizon-rl>Scaling Long-Horizon RL<a hidden class=anchor aria-hidden=true href=#scaling-long-horizon-rl>#</a></h4><div align=center><img src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/swe.jpg alt width=800></div><p>In real-world software engineering tasks like SWE-Bench, Qwen3-Coder must engage in multi-turn interaction with the environment, involving planning, using tools, receiving feedback, and making decisions. In the post-training phase of Qwen3-Coder, we introduced long-horizon RL (Agent RL) to encourage the model to solve real-world tasks through multi-turn interactions using tools. The key challenge of Agent RL lies in environment scaling. To address this, we built a scalable system capable of running 20,000 independent environments in parallel, leveraging Alibaba Cloud&rsquo;s infrastructure. The infrastructure provides the necessary feedback for large-scale reinforcement learning and supports evaluation at scale. As a result, Qwen3-Coder achieves state-of-the-art performance among open-source models on SWE-Bench Verified without test-time scaling.</p><h2 id=code-with-qwen3-coder>Code with Qwen3-Coder<a hidden class=anchor aria-hidden=true href=#code-with-qwen3-coder>#</a></h2><h3 id=qwen-code>Qwen Code<a hidden class=anchor aria-hidden=true href=#qwen-code>#</a></h3><p>Qwen Code is a research-purpose CLI tool adapted from Gemini CLI, with enhanced parser and tool support for Qwen-Coder models.</p><p>Make sure you have installed nodejs 20+:</p><p>You could install it via the following commands:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>curl -qL https://www.npmjs.com/install.sh <span class=p>|</span> sh
</span></span></code></pre></div><p>Then install Qwen code via npm manager:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>npm i -g @qwen-code/qwen-code
</span></span></code></pre></div><blockquote><p>The other way is to install from the source:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/QwenLM/qwen-code.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> qwen-code <span class=o>&amp;&amp;</span> npm install <span class=o>&amp;&amp;</span> npm install -g
</span></span></code></pre></div></blockquote><p>Qwen Code supports the OpenAI SDK when calling LLMs, and you can export the following environment variables or simply put them under the <code>.envfile</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>OPENAI_API_KEY</span><span class=o>=</span><span class=s2>&#34;your_api_key_here&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>OPENAI_BASE_URL</span><span class=o>=</span><span class=s2>&#34;https://dashscope-intl.aliyuncs.com/compatible-mode/v1&#34;</span>
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>OPENAI_MODEL</span><span class=o>=</span><span class=s2>&#34;qwen3-coder-plus&#34;</span>
</span></span></code></pre></div><p>Now enjoy your vibe coding with Qwen-Code and Qwen, by simply typing: qwen!</p><h3 id=claude-code>Claude Code<a hidden class=anchor aria-hidden=true href=#claude-code>#</a></h3><p>In addition to Qwen Code, you can now use Qwen3‑Coder with Claude Code. Simply request an API key on <a href=https://modelstudio.console.alibabacloud.com/>Alibaba Cloud Model Studio</a> platform and install Claude Code to start coding.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>npm install -g @anthropic-ai/claude-code
</span></span></code></pre></div><p>We have provided two entrypoints for seamlessly experiencing coding with Qwen3-Coder.</p><h4 id=optional-1-claude-code-proxy-api>Optional 1: Claude Code proxy API<a hidden class=anchor aria-hidden=true href=#optional-1-claude-code-proxy-api>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>export</span> <span class=nv>ANTHROPIC_BASE_URL</span><span class=o>=</span>https://dashscope-intl.aliyuncs.com/api/v2/apps/claude-code-proxy
</span></span><span class=line><span class=cl><span class=nb>export</span> <span class=nv>ANTHROPIC_AUTH_TOKEN</span><span class=o>=</span>your-dashscope-apikey
</span></span></code></pre></div><p>Then you should be able to use Claude Code with Qwen3-Coder!</p><h4 id=optional-2-claude-code-config-npm-package-for-router-customization>Optional 2: claude-code-config npm package for router customization<a hidden class=anchor aria-hidden=true href=#optional-2-claude-code-config-npm-package-for-router-customization>#</a></h4><p>claude-code-router aims for customizing different backend models for Claude Code. The dashscope team also provide a convenient config npm extension, namely claude-code-config, that provides default configuration for claude-code-router with DashScope support.
Run installation:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>npm install -g @musistudio/claude-code-router
</span></span><span class=line><span class=cl>npm install -g @dashscope-js/claude-code-config
</span></span></code></pre></div><p>and then run configuration:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ccr-dashscope
</span></span></code></pre></div><p>The command will automatically generate the config json files and plugin directories for ccr. (You could also manually adjust these under ~/.claude-code-router/config.json and ~/.claude-code-router/plugins/ )
Start using claude code via ccr:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>ccr code
</span></span></code></pre></div><h3 id=cline>Cline<a hidden class=anchor aria-hidden=true href=#cline>#</a></h3><p>Configure the Qwen3-Coder-480B-A35B-Instruct to cline
‒ Go to the Cline configuration settings
‒ For API Provider, select &lsquo;OpenAI Compatible&rsquo;
‒ For the OpenAI Compatible API Key, enter the key obtained from Dashscope
‒ Check &lsquo;Use custom base URL&rsquo; and enter: <code>https://dashscope-intl.aliyuncs.com/compatible-mode/v1</code>
‒ Enter <code>qwen3-coder-plus</code></p><video width=100% muted controls>
<source src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3_coder_plus_with_cline.mp4 type=video/mp4></video><h2 id=use-cases>Use Cases<a hidden class=anchor aria-hidden=true href=#use-cases>#</a></h2><div class="full-width-container example-container"><div class=example-content><div class=title><span>Example: Physics-Based Chimney Demolition Simulation with Controlled Explosion</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo1.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Qwen with Cline</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo2.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Qwen Chat Web Dev</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo3.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Testing Your WPM with a Famous Quote</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo4.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Bouncing Ball in Rotation Hypercube</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo5.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: Solar System Simulation</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo6.mp4 autoplay></video></figure></div></div></div><div class=example-content style=display:none><div class=title><span>Example: DUET Game</span>
<a class=next-button>Next</a></div><div class=grid-layout><div class=role></div><div class=content><figure><video controls loop src=https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/demo7.mp4 autoplay></video></figure></div></div></div></div><h2 id=api>API<a hidden class=anchor aria-hidden=true href=#api>#</a></h2><p>You can directly access the API of Qwen3-Coder through <a href=https://modelstudio.console.alibabacloud.com/>Alibaba Cloud Model Studio</a>. Here is a demonstration of how to use this model with the Qwen API.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create client - using intl URL for users outside of China</span>
</span></span><span class=line><span class=cl><span class=c1># If you are in mainland China, use the following URL:</span>
</span></span><span class=line><span class=cl><span class=c1># &#34;https://dashscope.aliyuncs.com/compatible-mode/v1&#34;</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;DASHSCOPE_API_KEY&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>base_url</span><span class=o>=</span><span class=s2>&#34;https://dashscope-intl.aliyuncs.com/compatible-mode/v1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;Help me create a web page for an online bookstore.&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Send request to qwen3-coder-plus model</span>
</span></span><span class=line><span class=cl><span class=n>completion</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;qwen3-coder-plus&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;You are a helpful assistant.&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Print the response</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>completion</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=o>.</span><span class=n>strip</span><span class=p>())</span>
</span></span></code></pre></div><h2 id=further-work>Further Work<a hidden class=anchor aria-hidden=true href=#further-work>#</a></h2><p>We are still actively working to improve the performance of our Coding Agent, aiming for it to take on more complex and tedious tasks in software engineering, thereby freeing up human productivity. More model sizes of Qwen3-Coder are on the way, delivering strong performance while reducing deployment costs. Additionally, we are actively exploring whether the Coding Agent can achieve self-improvement—an exciting and inspiring direction.</p></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>