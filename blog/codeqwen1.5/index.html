<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Code with CodeQwen1.5 | Qwen</title><meta name=keywords content><meta name=description content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs."><meta name=author content="Qwen Team"><link rel=canonical href=https://qwenlm.github.io/blog/codeqwen1.5/><link crossorigin=anonymous href=/assets/css/stylesheet.012512d6f1d6f320d85cff7ae2b89d136cc19960a4aa00adf35aaae57e557162.css integrity="sha256-ASUS1vHW8yDYXP964ridE2zBmWCkqgCt81qq5X5VcWI=" rel="preload stylesheet" as=style><link rel=icon href=https://qwenlm.github.io/favicon.png><link rel=apple-touch-icon href=https://qwenlm.github.io/favicon.png><link rel=manifest href=https://qwenlm.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://qwenlm.github.io/blog/codeqwen1.5/><link rel=alternate hreflang=zh href=https://qwenlm.github.io/zh/blog/codeqwen1.5/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.df2a5734071a3a99040f5e88e6d16d78358fbdef9a5e7389874ac5f2aa2ca86f.js integrity="sha256-3ypXNAcaOpkED16I5tFteDWPve+aXnOJh0rF8qosqG8="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Code with CodeQwen1.5"><meta property="og:description" content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs."><meta property="og:type" content="article"><meta property="og:url" content="https://qwenlm.github.io/blog/codeqwen1.5/"><meta property="og:image" content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-04-16T13:33:00+08:00"><meta property="article:modified_time" content="2024-04-16T13:33:00+08:00"><meta property="og:site_name" content="Qwen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://qwenlm.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Code with CodeQwen1.5"><meta name=twitter:description content="GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD
Introduction The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://qwenlm.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Code with CodeQwen1.5","item":"https://qwenlm.github.io/blog/codeqwen1.5/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Code with CodeQwen1.5","name":"Code with CodeQwen1.5","description":"GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\nIntroduction The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs.","keywords":[],"articleBody":"GITHUB HUGGING FACE MODELSCOPE DEMO DISCORD\nIntroduction The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs. This initiative has already given rise to several promising open-source models, including StarCoder2, CodeLlama, and DeepSeek-Coder, offering a path forward, albeit one that necessitates continued refinement.\nToday, we are delighted to introduce a new member of the Qwen1.5 open-source family, the CodeQwen1.5-7B, a specialized codeLLM built upon the Qwen1.5 language model. CodeQwen1.5-7B has been pretrained with around 3 trillion tokens of code-related data. It supports an extensive repertoire of 92 programming languages, and it exhibits exceptional capacity in long-context understanding and generation with the ability to process information of 64K tokens. In terms of performance, CodeQwen1.5 demonstrates impressive capabilities in basic code generation, long-context modeliing, code editation and SQL. We believe this model can significantly enhance developer productivity and streamline software development workflows within diverse technological environments.\nCodeQwen is a Basic Coder Code generation is a key competence for large language models, as they are tasked with translating natural language instructions into executable code with unwavering precision. CodeQwen1.5, with only 7 billion parameters, has surpassed larger models in basic code generation capabilities, further narrowing the gap in coding proficiency between GPT-4 and opensource code LLMs. We conducted a thorough evaluation on HumanEval and MBPP to provide a clear and fair comparison as follows.\nModel Size HumanEval 0-shot HumanEval+ 0-shot MBPP 0-shot MBPP+ 0-shot MBPP 3-shot Base Model CodeLlama-Base 7B 33.5 25.6 52.1 41.6 38.6 StarCoder2 7B 35.4 29.9 54.4 45.6 51.0 DeepSeek-Coder-Base 6.7B 47.6 39.6 70.2 56.6 60.6 CodeQwen1.5 7B 51.8 45.7 72.2 60.2 61.8 Chat Model GPT-3.5-Turbo - 76.8 70.7 82.5 69.7 70.8 GPT-4-Turbo (Nov 2023) - 85.4 81.7 83.5 70.7 80.0 DeepSeek-Coder-Instruct 6.7B 78.6 70.1 73.2 63.4 65.4 CodeQwen1.5-Chat 7B 83.5 78.7 77.7 67.2 70.6 In addition to the widely recognized HumanEval and MBPP benchmarks, we explored LiveCodeBench. This benchmark assesses code performance by introducing fresh challenges sourced from coding competitions such as LeetCode, AtCoder, and CodeForces over time. Our evaluation of CodeQwen1.5 on LiveCodeBench spanned from September 1, 2023, to April 1, 2024. The findings indicate that CodeQwen1.5 ranks among the top open-access models currently available. Note: it is possible that the inclusion of LeetCode data in our pretraining corpus may contribute to the performance in LiveCodeBench.\nThe evaluations mentioned primarily revolve around Python capabilities; however, CodeQwen1.5 is not merely a Python specialist but also an expert across multiple programming languages. We conducted a comprehensive evaluation of CodeQwen1.5 in the eight mainstream languages featured in MultiPL-E, including Python, C++, Java, PHP, TypeScript, C#, Bash, and JavaScript. The results highlight the exceptional programming capabilities of CodeQwen1.5.\nCodeQwen is a Long Context Coder Long context capability is crucial for code LLMs, serving as the core skill for understanding repository-level code and becoming a code agent. However, current code models still have very limited support for length, which hinders their potential for practical application. CodeQwen1.5 aims to further advance the progress of open-source code models in long context modeling. To achieve this, we have collected and constructed long sequence code data at the repository level for pre-training. Through careful data proportioning and organization, we have enabled it to support input lengths of up to 64K tokens.\nEvaluation 1: We collected high-quality repo from GitHub Trending repositories on 2024-3-28 that were not included in CodeQwen1.5’s training data to observe the effectiveness of long context modeling. The following figure demonstrates that as the sequence length increases, CodeQwen1.5’s Perplexity (PPL) still manages to maintain a downward trend.\nEvaluation 2: We created a synthetic task called Needle in the Code, inspired by popular long-context evaluations in the text domain. In this task, we inserted a very simple custom function at various positions within a longer codebase (we chose Megatron to honor its contributions to open-source LLMs!) and tested whether the model could replicate this function at the end of the codebase. The figure below shows that CodeQwen is capable of successfully completing this task within a 64k length range.\nBoth Evaluation 1 and Evaluation 2 serve as initial and foundational assessments. For the Chat model, we aim to evaluate its long context capabilities with more practical tasks. However, our objective is to examine the Chat model’s capability to handle long contexts through more pragmatic, real-world evaluation tasks.\nEvaluation 3: SWE Bench is a benchmark designed to assess the ability of Large Language Models (LLMs) or agents to tackle practical software development challenges. It presents contestants with a code repository and an associated issue, tasking them with generating a commit patch that resolves the issue effectively. The benchmark uniquely emphasizes the long-context processing capabilities of code LLMs, necessitating both deep comprehension of the given codebase and the generation of extensive, unit-test-passing code.\nCurrently, participants in the SWE Bench competition predominantly are proprietary models. We introduce CodeQwen1.5 as an open-source model entry. Despite achieving a score of 0.89, CodeQwen1.5 surpasses ChatGPT-3.5, demonstrating the nascent yet promising competitiveness of open-source code models against their proprietary counterparts.\nCodeQwen is a Debugger An effective code assistant must demonstrate proficiency in both generating code in response to given specifications and adeptly modifying or debugging existing code to accommodate evolving requirements or rectify errors. In assessing CodeQwen1.5’s proficiency in code modification tasks, we concentrated our evaluation on the CodeEditorBench suite, encompassing four distinct dimensions: Debugging, Translation, Language Switching, and Code Polishing. The results indicate that CodeQwen1.5 achieves the SOTA performance at the 7 billion parameter scale.\nCodeQwen is a SQLer CodeQwen1.5 serves as a solution to bridge the gap between non-programming professionals and efficient data interaction. It alleviates the steep learning curve associated with SQL by enabling users without coding expertise to query databases through natural language. We evaluated CodeQwen1.5-Chat’s performance on two popular Text-to-SQL benchmarks, Spider and Bird. Experimental results pose CodeQwen1.5 a second position close to GPT-4 (results come from DIN-SQL, a SOTA prompting method). This outstanding performance is attributed to the utilization of synthetic data throughout both pre-training and fine-tuning stages. Synthetic data, characterized by its scalability, verifiability, and variety, emerges as a compelling area for future research due to its proven effectiveness in enhancing CodeQwen1.5’s SQL capabilities.\nDevelop with CodeQwen1.5 CodeQwen1.5 is part of the Qwen1.5 open-source family. We advise you to read our blog for Qwen1.5 to figure out the usages with Transformers, vLLM, llama.cpp, Ollama, etc.\nConclusion We have released CodeQwen1.5-7B and CodeQwen1.5-7B-Chat, an open and versatile code LLM. The models are intended to aid progress in code assistance and code agents, benefiting the research community. We’ll keep investing heavily in smart code development, with the ultimate goal of creating AI programmers.\nCitation @misc{codeqwen1.5, title = {Code with CodeQwen1.5}, url = {https://qwenlm.github.io/blog/codeqwen1.5/}, author = {Qwen Team}, month = {April}, year = {2024} } ","wordCount":"1176","inLanguage":"en","datePublished":"2024-04-16T13:33:00+08:00","dateModified":"2024-04-16T13:33:00+08:00","author":{"@type":"Person","name":"Qwen Team"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://qwenlm.github.io/blog/codeqwen1.5/"},"publisher":{"@type":"Organization","name":"Qwen","logo":{"@type":"ImageObject","url":"https://qwenlm.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="Qwen (Alt + H)"><img src=https://qwenlm.github.io/img/logo.png alt aria-label=logo height=30></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Code with CodeQwen1.5</h1><div class=post-meta><span title='2024-04-16 13:33:00 +0800 +0800'>April 16, 2024</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;1176 words&nbsp;·&nbsp;Qwen Team&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://qwenlm.github.io/zh/blog/codeqwen1.5/>简体中文</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://github.com/QwenLM/CodeQwen1.5 class="btn external" target=_blank>GITHUB</a>
<a href=https://huggingface.co/Qwen class="btn external" target=_blank>HUGGING FACE</a>
<a href=https://modelscope.cn/organization/qwen class="btn external" target=_blank>MODELSCOPE</a>
<a href=https://huggingface.co/spaces/Qwen/CodeQwen1.5-7b-Chat-demo class="btn external" target=_blank>DEMO</a>
<a href=https://discord.gg/yPEP2vHTu4 class="btn external" target=_blank>DISCORD</a></p><h1 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h1><p>The advent of advanced programming tools, which harnesses the power of large language models (LLMs), has significantly enhanced programmer productivity and accuracy. Notwithstanding these advancements, dominant coding assistants like Github Copilot, built upon proprietary LLMs, pose notable challenges in terms of cost, privacy, security, and potential copyright infringement. Recognizing the imperative for a more transparent and accessible alternative, the open-source community has embarked on a concerted endeavor to develop open codeLLMs. This initiative has already given rise to several promising open-source models, including StarCoder2, CodeLlama, and DeepSeek-Coder, offering a path forward, albeit one that necessitates continued refinement.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/intro.png#center width=100%></figure><p>Today, we are delighted to introduce a new member of the Qwen1.5 open-source family, the CodeQwen1.5-7B, a specialized codeLLM built upon the Qwen1.5 language model. CodeQwen1.5-7B has been pretrained with around 3 trillion tokens of code-related data. It supports an extensive repertoire of 92 programming languages, and it exhibits exceptional capacity in long-context understanding and generation with the ability to process information of 64K tokens. In terms of performance, CodeQwen1.5 demonstrates impressive capabilities in basic code generation, long-context modeliing, code editation and SQL. We believe this model can significantly enhance developer productivity and streamline software development workflows within diverse technological environments.</p><h1 id=codeqwen-is-a-basic-coder>CodeQwen is a Basic Coder<a hidden class=anchor aria-hidden=true href=#codeqwen-is-a-basic-coder>#</a></h1><p>Code generation is a key competence for large language models, as they are tasked with translating natural language instructions into executable code with unwavering precision. CodeQwen1.5, with only 7 billion parameters, has surpassed larger models in basic code generation capabilities, further narrowing the gap in coding proficiency between GPT-4 and opensource code LLMs. We conducted a thorough evaluation on HumanEval and MBPP to provide a clear and fair comparison as follows.</p><style>.cell-aux{font-size:.9rem;font-weight:400;font-style:italic;color:#888}</style><table style=text-align:center><tr style=font-weight:700><td style=text-align:left>Model</td><td style=text-align:left>Size</td><td><div>HumanEval</div><div class=cell-aux>0-shot</div></td><td><div>HumanEval+</div><div class=cell-aux>0-shot</div></td><td><div>MBPP</div><div class=cell-aux>0-shot</div></td><td><div>MBPP+</div><div class=cell-aux>0-shot</div></td><td><div>MBPP</div><div class=cell-aux>3-shot</div></td></tr><tr><td colspan=7><b>Base Model</b></td></tr><tr><td style=text-align:left>CodeLlama-Base</td><td style=text-align:left>7B</td><td>33.5</td><td>25.6</td><td>52.1</td><td>41.6</td><td>38.6</td></tr><tr><td style=text-align:left>StarCoder2</td><td style=text-align:left>7B</td><td>35.4</td><td>29.9</td><td>54.4</td><td>45.6</td><td>51.0</td></tr><tr><td style=text-align:left>DeepSeek-Coder-Base</td><td style=text-align:left>6.7B</td><td>47.6</td><td>39.6</td><td>70.2</td><td>56.6</td><td>60.6</td></tr><tr><td style=text-align:left><b>CodeQwen1.5</b></td><td style=text-align:left>7B</td><td>51.8</td><td>45.7</td><td>72.2</td><td>60.2</td><td>61.8</td></tr><tr><td colspan=7><b>Chat Model</b></td></tr><tr><td style=text-align:left>GPT-3.5-Turbo</td><td style=text-align:left>-</td><td>76.8</td><td>70.7</td><td>82.5</td><td>69.7</td><td>70.8</td></tr><tr><td style=text-align:left>GPT-4-Turbo (Nov 2023)</td><td style=text-align:left>-</td><td>85.4</td><td>81.7</td><td>83.5</td><td>70.7</td><td>80.0</td></tr><tr><td style=text-align:left>DeepSeek-Coder-Instruct</td><td style=text-align:left>6.7B</td><td>78.6</td><td>70.1</td><td>73.2</td><td>63.4</td><td>65.4</td></tr><tr><td style=text-align:left><b>CodeQwen1.5-Chat</b></td><td style=text-align:left>7B</td><td>83.5</td><td>78.7</td><td>77.7</td><td>67.2</td><td>70.6</td></tr></table><p>In addition to the widely recognized HumanEval and MBPP benchmarks, we explored LiveCodeBench. This benchmark assesses code performance by introducing fresh challenges sourced from coding competitions such as LeetCode, AtCoder, and CodeForces over time. Our evaluation of CodeQwen1.5 on LiveCodeBench spanned from September 1, 2023, to April 1, 2024. The findings indicate that CodeQwen1.5 ranks among the top open-access models currently available. Note: it is possible that the inclusion of LeetCode data in our pretraining corpus may contribute to the performance in LiveCodeBench.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/livecode.png#center width=75%></figure><p>The evaluations mentioned primarily revolve around Python capabilities; however, CodeQwen1.5 is not merely a Python specialist but also an expert across multiple programming languages. We conducted a comprehensive evaluation of CodeQwen1.5 in the eight mainstream languages featured in MultiPL-E, including Python, C++, Java, PHP, TypeScript, C#, Bash, and JavaScript. The results highlight the exceptional programming capabilities of CodeQwen1.5.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/radar-vertical.png#center width=40%></figure><h1 id=codeqwen-is-a-long-context-coder>CodeQwen is a Long Context Coder<a hidden class=anchor aria-hidden=true href=#codeqwen-is-a-long-context-coder>#</a></h1><p>Long context capability is crucial for code LLMs, serving as the core skill for understanding repository-level code and becoming a code agent. However, current code models still have very limited support for length, which hinders their potential for practical application. CodeQwen1.5 aims to further advance the progress of open-source code models in long context modeling. To achieve this, we have collected and constructed long sequence code data at the repository level for pre-training. Through careful data proportioning and organization, we have enabled it to support input lengths of up to 64K tokens.</p><p><strong>Evaluation 1</strong>: We collected high-quality repo from GitHub Trending repositories on 2024-3-28 that were not included in CodeQwen1.5&rsquo;s training data to observe the effectiveness of long context modeling. The following figure demonstrates that as the sequence length increases, CodeQwen1.5&rsquo;s Perplexity (PPL) still manages to maintain a downward trend.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/longcontext-ppl.png#center width=90%></figure><p><strong>Evaluation 2</strong>: We created a synthetic task called <code>Needle in the Code</code>, inspired by popular long-context evaluations in the text domain. In this task, we inserted a very simple custom function at various positions within a longer codebase (we chose Megatron to honor its contributions to open-source LLMs!) and tested whether the model could replicate this function at the end of the codebase. The figure below shows that CodeQwen is capable of successfully completing this task within a 64k length range.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/longcontext-needle.png#center width=90%></figure><p>Both Evaluation 1 and Evaluation 2 serve as initial and foundational assessments. For the Chat model, we aim to evaluate its long context capabilities with more practical tasks. However, our objective is to examine the Chat model&rsquo;s capability to handle long contexts through more pragmatic, real-world evaluation tasks.</p><p><strong>Evaluation 3</strong>: SWE Bench is a benchmark designed to assess the ability of Large Language Models (LLMs) or agents to tackle practical software development challenges. It presents contestants with a code repository and an associated issue, tasking them with generating a commit patch that resolves the issue effectively. The benchmark uniquely emphasizes the long-context processing capabilities of code LLMs, necessitating both deep comprehension of the given codebase and the generation of extensive, unit-test-passing code.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/swe-bench.png#center width=95%></figure><p>Currently, participants in the SWE Bench competition predominantly are proprietary models. We introduce CodeQwen1.5 as an open-source model entry. Despite achieving a score of 0.89, CodeQwen1.5 surpasses ChatGPT-3.5, demonstrating the nascent yet promising competitiveness of open-source code models against their proprietary counterparts.</p><h1 id=codeqwen-is-a-debugger>CodeQwen is a Debugger<a hidden class=anchor aria-hidden=true href=#codeqwen-is-a-debugger>#</a></h1><p>An effective code assistant must demonstrate proficiency in both generating code in response to given specifications and adeptly modifying or debugging existing code to accommodate evolving requirements or rectify errors. In assessing CodeQwen1.5&rsquo;s proficiency in code modification tasks, we concentrated our evaluation on the CodeEditorBench suite, encompassing four distinct dimensions: Debugging, Translation, Language Switching, and Code Polishing. The results indicate that CodeQwen1.5 achieves the SOTA performance at the 7 billion parameter scale.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/codeedit.jpeg#center width=90%></figure><h1 id=codeqwen-is-a-sqler>CodeQwen is a SQLer<a hidden class=anchor aria-hidden=true href=#codeqwen-is-a-sqler>#</a></h1><p>CodeQwen1.5 serves as a solution to bridge the gap between non-programming professionals and efficient data interaction. It alleviates the steep learning curve associated with SQL by enabling users without coding expertise to query databases through natural language. We evaluated CodeQwen1.5-Chat&rsquo;s performance on two popular Text-to-SQL benchmarks, Spider and Bird. Experimental results pose CodeQwen1.5 a second position close to GPT-4 (results come from DIN-SQL, a SOTA prompting method). This outstanding performance is attributed to the utilization of synthetic data throughout both pre-training and fine-tuning stages. Synthetic data, characterized by its scalability, verifiability, and variety, emerges as a compelling area for future research due to its proven effectiveness in enhancing CodeQwen1.5&rsquo;s SQL capabilities.</p><figure><img src=https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/assets/blog/codeqwen1.5/sql-score.png#center width=90%></figure><h1 id=develop-with-codeqwen15>Develop with CodeQwen1.5<a hidden class=anchor aria-hidden=true href=#develop-with-codeqwen15>#</a></h1><p>CodeQwen1.5 is part of the Qwen1.5 open-source family. We advise you to read our blog for <a href=https://qwenlm.github.io/blog/qwen1.5/>Qwen1.5</a> to figure out the usages with Transformers, vLLM, llama.cpp, Ollama, etc.</p><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>We have released CodeQwen1.5-7B and CodeQwen1.5-7B-Chat, an open and versatile code LLM. The models are intended to aid progress in code assistance and code agents, benefiting the research community. We&rsquo;ll keep investing heavily in smart code development, with the ultimate goal of creating AI programmers.</p><h1 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h1><pre tabindex=0><code>@misc{codeqwen1.5,
    title = {Code with CodeQwen1.5},
    url = {https://qwenlm.github.io/blog/codeqwen1.5/},
    author = {Qwen Team},
    month = {April},
    year = {2024}
}
</code></pre></div></article></main><footer class=footer><span>&copy; 2024 <a href=https://qwenlm.github.io/>Qwen</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)"}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>